<!DOCTYPE html>
<html lang="vi">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AWS AI Practitioner - Q&A Practice</title>
    <link rel="icon"
        href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><defs><linearGradient id='grad' x1='0%' y1='0%' x2='100%' y2='100%'><stop offset='0%' style='stop-color:%236366f1;stop-opacity:1'/><stop offset='100%' style='stop-color:%238b5cf6;stop-opacity:1'/></linearGradient></defs><circle cx='50' cy='50' r='45' fill='url(%23grad)'/><path d='M35 40 Q50 25 65 40 M35 50 L65 50 M35 60 Q50 75 65 60' stroke='white' stroke-width='4' fill='none' stroke-linecap='round'/><circle cx='35' cy='40' r='3' fill='white'/><circle cx='50' cy='30' r='3' fill='white'/><circle cx='65' cy='40' r='3' fill='white'/><circle cx='35' cy='60' r='3' fill='white'/><circle cx='50' cy='70' r='3' fill='white'/><circle cx='65' cy='60' r='3' fill='white'/></svg>">
    <link
        href="https://fonts.googleapis.com/css2?family=Outfit:wght@300;400;600;700&family=Inter:wght@300;400;500;600&display=swap"
        rel="stylesheet">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        :root {
            --primary: #6366f1;
            --primary-light: #818cf8;
            --secondary: #64748b;
            --secondary-light: #94a3b8;
            --bg-dark: #0f172a;
            --bg-card: rgba(30, 41, 59, 0.7);
            --text-main: #f8fafc;
            --text-dim: #94a3b8;
            --accent: #10b981;
            --glass-border: rgba(255, 255, 255, 0.1);
            --danger: #ef4444;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            transition: all 0.3s ease;
        }

        body {
            font-family: 'Inter', sans-serif;
            background-color: var(--bg-dark);
            color: var(--text-main);
            min-height: 100vh;
            padding: 40px 20px;
            background-image:
                radial-gradient(at 0% 0%, rgba(99, 102, 241, 0.15) 0px, transparent 50%),
                radial-gradient(at 100% 100%, rgba(16, 185, 129, 0.1) 0px, transparent 50%);
            background-attachment: fixed;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
        }

        header {
            text-align: center;
            margin-bottom: 50px;
        }

        h1 {
            font-family: 'Outfit', sans-serif;
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(to right, #fff, var(--primary-light));
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .subtitle {
            color: var(--text-dim);
            font-size: 1.1rem;
        }

        .qa-card {
            background: var(--bg-card);
            backdrop-filter: blur(12px);
            border: 1px solid var(--glass-border);
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 25px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        .domain-tag {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 50px;
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 15px;
            background: rgba(99, 102, 241, 0.2);
            color: var(--primary-light);
            border: 1px solid rgba(99, 102, 241, 0.3);
        }

        .question {
            font-size: 1.2rem;
            font-weight: 500;
            line-height: 1.6;
            margin-bottom: 20px;
        }

        .options {
            display: grid;
            gap: 12px;
        }

        .option {
            background: rgba(255, 255, 255, 0.03);
            border: 1px solid var(--glass-border);
            padding: 15px 20px;
            border-radius: 12px;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 15px;
        }

        .option:hover {
            background: rgba(255, 255, 255, 0.08);
            border-color: var(--primary);
            transform: translateX(5px);
        }

        .option.correct {
            background: rgba(16, 185, 129, 0.15);
            border-color: var(--accent);
            color: var(--accent);
        }

        .option.wrong {
            background: rgba(239, 68, 68, 0.15);
            border-color: var(--danger);
            color: var(--danger);
        }

        .answer-box {
            margin-top: 25px;
            padding-top: 20px;
            border-top: 1px solid var(--glass-border);
            display: none;
        }

        .answer-box.visible {
            display: block;
            animation: fadeIn 0.5s ease;
        }

        .ans-label {
            font-weight: 700;
            color: var(--accent);
            margin-bottom: 8px;
            display: block;
        }

        .explanation {
            color: var(--text-dim);
            line-height: 1.6;
            font-size: 0.95rem;
        }

        .explanation p {
            margin-bottom: 12px;
        }

        .explanation ul,
        .explanation ol {
            margin-bottom: 15px;
            padding-left: 20px;
        }

        .explanation li {
            margin-bottom: 8px;
        }

        .explanation strong {
            color: var(--text-main);
            font-weight: 600;
        }

        .explanation blockquote {
            border-left: 3px solid var(--primary);
            padding-left: 15px;
            margin: 15px 0;
            font-style: italic;
        }

        button.show-btn,
        button.check-btn {
            background: var(--primary);
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 10px;
            font-weight: 600;
            cursor: pointer;
            margin-top: 15px;
        }

        button.show-btn {
            background: var(--secondary);
        }

        button.show-btn:hover,
        button.check-btn:hover {
            background: var(--primary-light);
            box-shadow: 0 0 15px rgba(99, 102, 241, 0.4);
        }

        button.show-btn:hover {
            background: var(--secondary-light);
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        footer {
            text-align: center;
            margin-top: 60px;
            color: var(--text-dim);
            font-size: 0.9rem;
        }

        /* Top Right Menu */
        .top-right-menu {
            position: absolute;
            top: 20px;
            /* Adjust as needed */
            right: 20px;
            /* Adjust as needed */
            z-index: 10;
            /* Ensure it's above other content */
            background-color: var(--primary);
            padding: 8px 15px;
            border-radius: 10px;
            /* Matching the qa-card radius */
            font-size: 0.9rem;
            color: white;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.2);
        }

        .top-right-menu a {
            color: white;
            text-decoration: none;
            font-weight: 600;
        }

        .top-right-menu a:hover {
            text-decoration: underline;
        }

        /* Responsive Design */
        @media (max-width: 1024px) {
            .container {
                max-width: 100%;
                padding: 30px 15px;
            }

            h1 {
                font-size: 2.2rem;
            }

            .qa-card {
                padding: 25px;
                margin-bottom: 20px;
            }
        }

        @media (max-width: 768px) {
            body {
                padding: 20px 10px;
            }

            .container {
                padding: 20px 10px;
            }

            header {
                margin-bottom: 35px;
            }

            h1 {
                font-size: 1.8rem;
                margin-bottom: 8px;
            }

            .subtitle {
                font-size: 1rem;
            }

            .qa-card {
                padding: 20px;
                margin-bottom: 18px;
                border-radius: 15px;
            }

            .domain-tag {
                font-size: 0.7rem;
                padding: 3px 10px;
            }

            .question {
                font-size: 1.05rem;
                line-height: 1.5;
                margin-bottom: 18px;
            }

            .option {
                padding: 12px 15px;
                gap: 12px;
                font-size: 0.95rem;
            }

            .option input[type="checkbox"],
            .option input[type="radio"] {
                margin-right: 6px;
            }

            button.show-btn,
            button.check-btn {
                padding: 8px 16px;
                font-size: 0.9rem;
                margin-top: 12px;
                margin-right: 8px;
            }

            .answer-box {
                margin-top: 20px;
                padding-top: 18px;
            }

            .explanation {
                font-size: 0.9rem;
            }

            .explanation p {
                margin-bottom: 10px;
            }

            .explanation ul,
            .explanation ol {
                margin-bottom: 12px;
                padding-left: 18px;
            }

            .explanation li {
                margin-bottom: 6px;
            }

            footer {
                margin-top: 40px;
                font-size: 0.85rem;
            }
        }

        @media (max-width: 480px) {
            body {
                padding: 15px 8px;
            }

            .container {
                padding: 15px 8px;
            }

            h1 {
                font-size: 1.5rem;
            }

            .subtitle {
                font-size: 0.95rem;
            }

            .qa-card {
                padding: 16px;
                margin-bottom: 15px;
                border-radius: 12px;
            }

            .domain-tag {
                font-size: 0.65rem;
                padding: 2px 8px;
            }

            .question {
                font-size: 1rem;
                margin-bottom: 15px;
            }

            .option {
                padding: 10px 12px;
                gap: 10px;
                font-size: 0.9rem;
            }

            .option strong {
                font-size: 0.85rem;
            }

            button.show-btn,
            button.check-btn {
                padding: 7px 14px;
                font-size: 0.85rem;
                margin-top: 10px;
                width: 100%;
                margin-right: 0;
                margin-bottom: 8px;
            }

            .answer-box {
                margin-top: 15px;
                padding-top: 15px;
            }

            .ans-label {
                font-size: 0.9rem;
            }

            .explanation {
                font-size: 0.85rem;
                line-height: 1.5;
            }

            .explanation p {
                margin-bottom: 8px;
            }

            .explanation ul,
            .explanation ol {
                margin-bottom: 10px;
                padding-left: 15px;
            }

            .explanation li {
                margin-bottom: 5px;
                font-size: 0.85rem;
            }

            .explanation strong {
                font-size: 0.85rem;
            }

            footer {
                margin-top: 30px;
                font-size: 0.8rem;
            }
        }

        /* Landscape mobile optimization */
        @media (max-width: 768px) and (orientation: landscape) {
            body {
                padding: 15px 20px;
            }

            .qa-card {
                padding: 18px;
            }

            .question {
                font-size: 1rem;
            }
        }
    </style>
</head>

<body>
    <div class="top-right-menu">
        <a href="index.html">Switch to Home</a>
    </div>
    <div class="container">
        <header>
            <h1>AWS AI Practitioner Practice</h1>
            <p class="subtitle">Trắc nghiệm tổng hợp 35 câu hỏi (Vietnamese & English) từ 5 Domain kiến thức</p>
        </header>

        <div id="qa-container">
            <!-- Questions will be injected here -->
        </div>

        <footer>
            <p>&copy; 2025 AWS AI Practitioner Hub - Prepared for er_macbook_310</p>
        </footer>
    </div>

    <script>
        const questions = [
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "Select the correct model evaluation type from the following list for each use case. Each model evaluation type should be selected one or more times. (Select FOUR.)\nAccuracy of the text summarization on the built-in dataset",
                "options": [
                    "Automatic model evaluation",
                    "Human-in-the-loop model evaluation"
                ],
                "correct": [0],
                "explanation": "Yêu cầu là đánh giá **độ chính xác của tóm tắt văn bản (text summarization)** trên **built-in dataset** (tập dữ liệu có sẵn trong Amazon Bedrock).\n\n**Automatic model evaluation** là loại phù hợp nhất cho trường hợp này:\n\n• **Automatic model evaluation** trong Amazon Bedrock:\n  - Sử dụng các **built-in datasets** (tập dữ liệu chuẩn có sẵn) để tự động đánh giá hiệu suất mô hình trên các task như text summarization, question answering, text generation, classification, v.v.\n  - Tự động tính toán các metric định lượng (ví dụ: ROUGE, BLEU cho summarization, accuracy, F1-score, v.v.) mà không cần can thiệp thủ công.\n  - Nhanh chóng, khách quan, có thể so sánh nhiều mô hình (Claude, Llama, Titan, v.v.) trên cùng dataset.\n  - Lý tưởng để kiểm tra **độ chính xác tóm tắt** trên dữ liệu chuẩn.\n\n**Human-in-the-loop model evaluation** (A2I) không phù hợp ở đây vì:\n  - Dùng khi cần **con người đánh giá** (human judgment) cho các trường hợp chủ quan, phức tạp, hoặc không có metric tự động tốt (ví dụ: đánh giá chất lượng tóm tắt về tính mạch lạc, tự nhiên, phù hợp ngữ cảnh).\n  - Không dùng cho built-in dataset với metric định lượng như accuracy của summarization.\n\nVì câu hỏi chỉ liệt kê **một use case** nhưng yêu cầu \"Select FOUR\" (có thể do lỗi đề bài hoặc cần chọn nhiều lần), đáp án chính xác cho use case này là **Automatic model evaluation**.\n\nNguồn tham khảo: Amazon Bedrock Model Evaluation documentation – Automatic evaluation dùng built-in datasets để đo accuracy, ROUGE, BLEU cho text summarization một cách tự động."
            }, {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "Select the correct model evaluation type from the following list for each use case. Each model evaluation type should be selected one or more times. (Select FOUR.)\nToxicity of the text generation on the built-in dataset",
                "options": [
                    "Automatic model evaluation",
                    "Human-in-the-loop model evaluation"
                ],
                "correct": [0],
                "explanation": "Yêu cầu là đánh giá **mức độ độc hại (toxicity)** của văn bản được sinh ra (text generation) trên **built-in dataset** (tập dữ liệu chuẩn có sẵn trong Amazon Bedrock).\n\n**Automatic model evaluation** là loại phù hợp nhất cho trường hợp này:\n\n• **Automatic model evaluation** trong Amazon Bedrock:\n  - Sử dụng các **built-in datasets** để tự động chạy đánh giá trên nhiều task, bao gồm **toxicity detection** cho text generation.\n  - Tự động áp dụng các metric định lượng như **toxicity score** (từ 0–1, càng thấp càng tốt) hoặc các bộ lọc độc hại (hate, insults, sexual, violence, misconduct).\n  - Không cần can thiệp thủ công, nhanh chóng, khách quan, và cho phép so sánh toxicity giữa các mô hình (Claude, Titan, Llama, v.v.) trên cùng dataset.\n  - Đây là cách tiêu chuẩn để kiểm tra mức độ an toàn (safety) của text generation trên dữ liệu chuẩn.\n\n**Human-in-the-loop model evaluation** (A2I) không phù hợp ở đây vì:\n  - Dùng khi cần **con người đánh giá** các trường hợp chủ quan, phức tạp, hoặc khi metric tự động chưa đủ (ví dụ: đánh giá toxicity trong ngữ cảnh văn hóa, sarcasm, hoặc nội dung nhạy cảm cao).\n  - Không dùng cho built-in dataset với metric định lượng như toxicity score.\n\nVì câu hỏi chỉ liệt kê **một use case** nhưng yêu cầu \"Select FOUR\" (có thể do lỗi đề bài hoặc cần áp dụng cho nhiều trường hợp tương tự), đáp án chính xác cho use case này là **Automatic model evaluation**.\n\nNguồn tham khảo: Amazon Bedrock Model Evaluation documentation – Automatic evaluation dùng built-in datasets để đo toxicity, safety metrics cho text generation một cách tự động."
            }, {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "Select the correct model evaluation type from the following list for each use case. Each model evaluation type should be selected one or more times. (Select FOUR.)\nFactual correctness of the generated response on the company-provided dataset",
                "options": [
                    "Automatic model evaluation",
                    "Human-in-the-loop model evaluation"
                ],
                "correct": [1],
                "explanation": "Yêu cầu là đánh giá **độ chính xác thực tế (factual correctness)** của phản hồi được sinh ra (generated response) trên **dataset do công ty cung cấp** (company-provided dataset).\n\n**Human-in-the-loop model evaluation** là loại phù hợp nhất cho trường hợp này:\n\n• **Human-in-the-loop model evaluation** (A2I - Amazon Augmented AI) trong Amazon Bedrock:\n  - Sử dụng **con người** (human reviewers) để đánh giá chất lượng phản hồi, đặc biệt khi cần kiểm tra **factual correctness** (thông tin có đúng sự thật, không hallucination, có dựa trên nguồn công ty cung cấp hay không).\n  - Dataset do công ty cung cấp thường chứa thông tin **domain-specific** (chính sách nội bộ, tài liệu kỹ thuật, quy trình công ty), không có metric tự động chuẩn (như ROUGE/BLEU) để đo factual accuracy.\n  - Human reviewers có thể so sánh output với dataset gốc, đánh giá tính chính xác, tính phù hợp, và phát hiện lỗi tinh tế mà metric tự động bỏ qua.\n  - Đây là cách **chính xác và đáng tin cậy** nhất để đánh giá factual correctness trên dữ liệu tùy chỉnh của công ty.\n\n**Automatic model evaluation** không phù hợp ở đây vì:\n  - Chỉ hoạt động tốt trên **built-in datasets** (tập dữ liệu chuẩn có sẵn) với các metric định lượng (ROUGE, BLEU, accuracy, v.v.).\n  - Không có metric tự động hiệu quả để đo factual correctness trên dataset tùy chỉnh của công ty (không có reference chuẩn hoặc ground truth tự động).\n\nVì câu hỏi chỉ liệt kê **một use case** nhưng yêu cầu \"Select FOUR\" (có thể do lỗi đề bài hoặc cần áp dụng cho nhiều trường hợp tương tự), đáp án chính xác cho use case này là **Human-in-the-loop model evaluation**.\n\nNguồn tham khảo: Amazon Bedrock Model Evaluation documentation – Human-in-the-loop (A2I) được khuyến nghị cho đánh giá factual correctness, quality, và domain-specific accuracy trên dữ liệu tùy chỉnh."
            }, {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "Select the correct model evaluation type from the following list for each use case. Each model evaluation type should be selected one or more times. (Select FOUR.)\nLinguistic quality of the text generation on the company-provided dataset",
                "options": [
                    "Automatic model evaluation",
                    "Human-in-the-loop model evaluation"
                ],
                "correct": [1],
                "explanation": "Yêu cầu là đánh giá **chất lượng ngôn ngữ (linguistic quality)** của văn bản được sinh ra (text generation) trên **dataset do công ty cung cấp** (company-provided dataset).\n\n**Human-in-the-loop model evaluation** là loại phù hợp nhất cho trường hợp này:\n\n• **Human-in-the-loop model evaluation** (A2I - Amazon Augmented AI) trong Amazon Bedrock:\n  - Sử dụng **con người** (human reviewers) để đánh giá các khía cạnh **chủ quan** và **ngôn ngữ** như: tính mạch lạc (coherence), tự nhiên (naturalness), ngữ pháp, phong cách viết, tính phù hợp văn hóa, độ mượt mà, hoặc chất lượng tổng thể của văn bản sinh ra.\n  - Dataset do công ty cung cấp thường chứa nội dung **domain-specific** (chính sách, tài liệu nội bộ, hướng dẫn chuyên ngành), nơi **linguistic quality** (ngôn ngữ chuyên nghiệp, phù hợp ngữ cảnh công ty) không thể đo lường chính xác bằng metric tự động.\n  - Human reviewers có thể chấm điểm, so sánh output với tiêu chuẩn công ty, và phát hiện lỗi tinh tế (awkward phrasing, tone không phù hợp) mà metric tự động bỏ qua.\n  - Đây là cách **chính xác và đáng tin cậy** nhất để đánh giá linguistic quality trên dữ liệu tùy chỉnh.\n\n**Automatic model evaluation** không phù hợp ở đây vì:\n  - Chỉ hoạt động tốt trên **built-in datasets** (tập dữ liệu chuẩn có sẵn) với các metric định lượng (ROUGE, BLEU, perplexity, v.v.).\n  - Không có metric tự động hiệu quả để đo linguistic quality (tính tự nhiên, mạch lạc, phong cách) trên dataset tùy chỉnh của công ty.\n\nVì câu hỏi chỉ liệt kê **một use case** nhưng yêu cầu \"Select FOUR\" (có thể do lỗi đề bài hoặc cần áp dụng cho nhiều trường hợp tương tự), đáp án chính xác cho use case này là **Human-in-the-loop model evaluation**.\n\nNguồn tham khảo: Amazon Bedrock Model Evaluation documentation – Human-in-the-loop (A2I) được khuyến nghị cho đánh giá subjective quality (linguistic quality, coherence, fluency) trên dữ liệu tùy chỉnh."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "Which components of the ML pipeline are performed during or after model training? (Select TWO.)",
                "options": [
                    "Data collection",
                    "Feature engineering",
                    "Hyperparameter tuning",
                    "Evaluation",
                    "Exploratory data analysis (EDA)"
                ],
                "correct": [2, 3],
                "explanation": "Yêu cầu chính là xác định hai thành phần trong pipeline machine learning được thực hiện **trong hoặc sau giai đoạn huấn luyện mô hình** (during or after model training).\n\nHai thành phần đúng là:\n\n• **Hyperparameter tuning** — Được thực hiện **trong giai đoạn huấn luyện mô hình** (model training).\n  - Mục tiêu: Tìm ra bộ siêu tham số (hyperparameters) tốt nhất (learning rate, số layer, batch size, regularization strength, v.v.) để tạo ra mô hình tốt hơn.\n  - Thường dùng các phương pháp như Grid Search, Random Search, Bayesian Optimization.\n  - Trong AWS SageMaker, hyperparameter tuning job chạy song song nhiều trial training để chọn cấu hình tốt nhất.\n\n• **Evaluation** — Được thực hiện **sau huấn luyện mô hình** (sau training và tuning).\n  - Đánh giá hiệu suất mô hình trên tập validation/test (accuracy, precision, recall, F1, AUC, v.v.).\n  - So sánh các phiên bản mô hình khác nhau (từ tuning) để chọn mô hình cuối cùng.\n  - Trong SageMaker, evaluation metrics được báo cáo sau mỗi training job và dùng để quyết định deploy.\n\nCác thành phần khác diễn ra **trước huấn luyện**:\n• **Data collection** — Thu thập dữ liệu ban đầu, trước training.\n• **Feature engineering** — Tạo/chọn đặc trưng từ dữ liệu thô, trước training.\n• **Exploratory data analysis (EDA)** — Phân tích dữ liệu ban đầu (visualization, imbalance check), trước feature engineering và training.\n\nDo đó, **Hyperparameter tuning** và **Evaluation** là hai thành phần diễn ra **trong hoặc sau model training**.\n\nNguồn tham khảo: AWS Machine Learning Lifecycle – Hyperparameter tuning thuộc giai đoạn Model Development (training & tuning), Evaluation là bước sau training để đánh giá và chọn mô hình."
            },
            {
                "domain": "AIF – Guidelines for Responsible AI",
                "q": "An online gaming company wants to introduce a new AI character in its fantasy game. The company wants to base the character on a well-known actor's voice and likeness.\nWhich issue should concern the company?",
                "options": [
                    "The actor did not consent for the company to use their likeness in the game.",
                    "The actor also appears in TV advertisements.",
                    "The actor is known for making comedies.",
                    "The actor changes their hairstyle frequently and speaks multiple languages."
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là xác định **vấn đề** mà công ty cần quan tâm nhất khi sử dụng **giọng nói** (voice) và **ngoại hình** (likeness) của một diễn viên nổi tiếng để tạo nhân vật AI trong game mà **không có sự đồng ý** của diễn viên.\n\n**The actor did not consent for the company to use their likeness in the game** là vấn đề nghiêm trọng nhất:\n\n• Theo **AWS Responsible AI Policy**, việc **mô phỏng hoặc sử dụng giọng nói/ngoại hình** của một cá nhân mà **không có sự đồng ý** hoặc quyền hợp pháp (consent hoặc appropriate rights) là **cấm**.\n  - Điều này bao gồm **unauthorized impersonation** (mạo danh trái phép).\n  - Rủi ro: vi phạm quyền riêng tư, quyền sở hữu trí tuệ (right of publicity), và có thể dẫn đến kiện tụng (deepfake laws, likeness rights ở nhiều quốc gia).\n  - Trong generative AI (như Bedrock, Stable Diffusion, voice cloning), việc sử dụng voice/likeness mà không xin phép là rủi ro đạo đức và pháp lý lớn.\n\nCác lựa chọn khác không liên quan:\n• **The actor also appears in TV advertisements** — Không ảnh hưởng đến vấn đề consent.\n• **The actor is known for making comedies** — Thể loại phim không liên quan đến việc xin phép sử dụng likeness.\n• **The actor changes their hairstyle frequently and speaks multiple languages** — Đặc điểm cá nhân không liên quan đến vấn đề pháp lý/đạo đức.\n\nDo đó, vấn đề lớn nhất mà công ty cần lo ngại là **diễn viên không đồng ý** cho sử dụng giọng nói và ngoại hình của họ.\n\nNguồn tham khảo: AWS Responsible AI Policy – Cấm sử dụng voice/likeness của cá nhân mà không có consent hoặc quyền hợp pháp."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A company wants to improve the performance of a foundation model (FM) on Amazon Bedrock for frequent summarization tasks. The company has a labeled dataset with sample texts specific to the summarization tasks.\nWhich solution will meet these requirements?",
                "options": [
                    "Continued pre-training",
                    "Fine-tuning",
                    "Retrieval augmented generation (RAG)",
                    "Prompt engineering"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là cải thiện hiệu suất foundation model (FM) trên Amazon Bedrock cho **nhiệm vụ tóm tắt văn bản** (summarization tasks) thường xuyên, khi công ty đã có **dataset có nhãn** (labeled dataset) cụ thể cho nhiệm vụ này.\n\n**Fine-tuning** là giải pháp phù hợp nhất:\n\n• **Fine-tuning** trên Amazon Bedrock cho phép tùy chỉnh FM bằng cách huấn luyện tiếp trên dataset **có nhãn** (labeled data) nhỏ hơn nhiều so với pre-training ban đầu.\n  - Mô hình học được các pattern đặc thù của nhiệm vụ tóm tắt (summarization) từ các cặp text + tóm tắt mẫu.\n  - Kết quả là tạo ra một **custom model** mới, chuyên biệt cho summarization, giữ nguyên kiến thức tổng quát từ FM gốc nhưng cải thiện đáng kể độ chính xác, tính mạch lạc và phù hợp với domain.\n  - Hỗ trợ frequent summarization tasks hiệu quả, chi phí thấp hơn so với continued pre-training, và dễ triển khai qua Bedrock Custom Models.\n\nCác giải pháp khác không đáp ứng tốt:\n• **Continued pre-training** — Dùng cho unlabeled data để mở rộng kiến thức chung (domain adaptation), không tận dụng được labeled dataset cho task-specific như summarization.\n• **Retrieval augmented generation (RAG)** — Dùng để ground response vào dữ liệu bên ngoài (knowledge base), không cải thiện khả năng tóm tắt tổng quát của mô hình.\n• **Prompt engineering** — Chỉ tinh chỉnh cách đặt câu hỏi (prompt), không huấn luyện mô hình học từ dataset labeled → hiệu quả hạn chế và không bền vững cho frequent tasks.\n\nDo đó, **Fine-tuning** là giải pháp **phù hợp nhất** để tận dụng labeled dataset và cải thiện hiệu suất FM cho summarization tasks.\n\nNguồn tham khảo: Amazon Bedrock documentation – Fine-tuning (custom models) yêu cầu labeled data và được thiết kế để cải thiện performance trên task-specific như summarization."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A company has an ML model that was trained with custom libraries dependencies. The model performs well on training data. However, the model does not perform as well when the model is tested on new datasets.\nWhat should the company do to improve the model's performance on the new datasets?",
                "options": [
                    "Train the model with smaller datasets.",
                    "Establish reliable packaging patterns for software libraries.",
                    "Automate model training by using MLOps and continuous integration and continuous delivery (CI/CD).",
                    "Perform a bias and variance tradeoff analysis."
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là cải thiện hiệu suất mô hình trên **dữ liệu mới** (new datasets) khi mô hình **học tốt trên training data** nhưng **kém trên test/unseen data** – đây là dấu hiệu điển hình của **overfitting** (high variance).\n\n**Perform a bias and variance tradeoff analysis** là giải pháp phù hợp nhất:\n\n• **Bias-variance tradeoff analysis** — Phân tích này giúp xác định nguyên nhân gốc rễ của vấn đề:\n  - **High variance** (overfitting): Mô hình học quá kỹ trên training data (bao gồm nhiễu), dẫn đến kém tổng quát hóa trên dữ liệu mới.\n  - **High bias** (underfitting): Mô hình quá đơn giản, không học được pattern.\n\nTrong trường hợp này (tốt trên train, kém trên new data) → **high variance**.\n  - Sau phân tích, công ty có thể áp dụng các biện pháp giảm variance như:\n    - Thêm dữ liệu huấn luyện\n    - Tăng regularization (L1/L2, dropout)\n    - Giảm độ phức tạp mô hình\n    - Early stopping\n    - Cross-validation\n\nĐây là bước **cốt lõi** để chẩn đoán và cải thiện generalization ability của mô hình ML.\n\nCác lựa chọn khác không giải quyết trực tiếp:\n• **Train the model with smaller datasets** — Làm overfitting nặng hơn, tăng variance.\n• **Establish reliable packaging patterns** — Đảm bảo reproducibility và consistency, nhưng không cải thiện khả năng tổng quát hóa của mô hình.\n• **Automate model training by using MLOps and CI/CD** — Tăng hiệu quả pipeline, nhưng không giải quyết overfitting nếu mô hình vẫn overfit.\n\nDo đó, **Perform a bias and variance tradeoff analysis** là hành động **hiệu quả nhất** để cải thiện hiệu suất trên dữ liệu mới.\n\nNguồn tham khảo: AWS Machine Learning Specialty & ML fundamentals – Bias-variance tradeoff là kỹ thuật chẩn đoán chính cho overfitting/underfitting, dẫn đến các giải pháp tối ưu hóa generalization."
            }, {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "How do embeddings help improve the accuracy of large language models (LLMs)?",
                "options": [
                    "Embeddings influence the likelihood of the model returning results with lower latency.",
                    "Embeddings influence the likelihood of the model selecting lower-probability outputs.",
                    "Embeddings create different contextual meanings of words when applied to different phrases.",
                    "Embeddings can improve the accuracy of LLMs by encoding words into dense vectors that capture semantic meaning and relationships."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là xác định cách **embeddings** giúp **cải thiện độ chính xác** của các large language models (LLMs).\n\n**Embeddings create different contextual meanings of words when applied to different phrases** là phát biểu chính xác nhất:\n\n• Trong các LLM hiện đại (dựa trên transformer), **embeddings** là **contextual** (ngữ cảnh hóa): vector biểu diễn của một từ **thay đổi** tùy thuộc vào các từ xung quanh trong câu/phrase.\n  - Ví dụ: từ \"bank\" trong \"I went to the bank to deposit money\" → vector gần với \"ngân hàng\".\n  - Từ \"bank\" trong \"The boat was tied to the river bank\" → vector gần với \"bờ sông\".\n\nSự **thay đổi ý nghĩa theo ngữ cảnh** (contextual meaning) này giúp mô hình hiểu chính xác ý nghĩa của từ trong từng tình huống, giảm nhầm lẫn, giảm hallucinations, và cải thiện đáng kể độ chính xác khi diễn giải (understanding) và sinh ngôn ngữ (generation).\n\nĐây là một trong những lý do cốt lõi khiến transformer-based LLMs (như GPT, Claude, Llama) vượt trội hơn các mô hình trước đó (dùng static embeddings).\n\nCác lựa chọn khác sai:\n• **A** — Embeddings không ảnh hưởng trực tiếp đến latency (độ trễ); latency phụ thuộc vào kích thước mô hình, phần cứng, batch size, v.v.\n• **B** — Embeddings không làm mô hình ưu tiên chọn output có xác suất thấp; ngược lại, chúng giúp tăng xác suất cho các output hợp lý theo ngữ cảnh.\n• **D** — Mặc dù đúng về việc embeddings mã hóa ý nghĩa ngữ nghĩa, nhưng phát biểu này **không nhấn mạnh** yếu tố **contextual** (thay đổi theo ngữ cảnh) – đây là điểm cốt lõi giúp cải thiện accuracy trong LLM.\n\nDo đó, **Embeddings create different contextual meanings of words when applied to different phrases** là câu trả lời **chính xác nhất**.\n\nNguồn tham khảo: Transformer architecture & BERT/GPT papers – Contextual embeddings là bước đột phá giúp LLMs hiểu ngữ nghĩa theo ngữ cảnh, cải thiện accuracy đáng kể so với static embeddings."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "An educational institute is converting textbook content into audio format. The institute wants to produce natural-sounding audiobooks that include a range of voices and languages.\nWhich solution will meet these requirements?",
                "options": [
                    "Use Amazon Lex to engage students with interactive voice responses. Give the students the ability to ask questions about textbook content and receive spoken answers.",
                    "Use Amazon Transcribe to convert pre-recorded lectures into text and create additional textual resources for students.",
                    "Use Amazon Polly to convert textbook content into natural-sounding speech and offer a range of voices and languages for accessible audiobooks.",
                    "Use Amazon Translate to automatically translate textbook content into multiple languages and ensure that all text is available in students' preferred languages before conversion to speech."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm giải pháp để **chuyển đổi nội dung sách giáo khoa (textbook content)** thành **định dạng âm thanh** (audio format), tạo ra **audiobooks** nghe **tự nhiên** (natural-sounding) với **nhiều giọng nói** (range of voices) và **nhiều ngôn ngữ** (languages).\n\n**Use Amazon Polly to convert textbook content into natural-sounding speech and offer a range of voices and languages for accessible audiobooks** là giải pháp phù hợp nhất:\n\n• **Amazon Polly** — Là dịch vụ **text-to-speech** (TTS) của AWS, chuyên chuyển đổi văn bản thành giọng nói tự nhiên, chất lượng cao.\n  - Hỗ trợ **hàng chục giọng nói** (neural voices) đa dạng (nam/nữ, phong cách, accent).\n  - Hỗ trợ **hơn 30 ngôn ngữ** và nhiều biến thể (ví dụ: English US/UK/AU, Spanish, French, German, Hindi, v.v.).\n  - Sử dụng công nghệ neural TTS để tạo giọng nói rất giống người thật (natural-sounding), lý tưởng cho audiobooks giáo dục.\n  - Dễ tích hợp: upload text từ sách giáo khoa → Polly sinh audio → lưu vào S3 hoặc stream trực tiếp.\n\nPolly đáp ứng đầy đủ yêu cầu: chuyển text → audio tự nhiên, nhiều giọng, nhiều ngôn ngữ, phù hợp cho accessible audiobooks.\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Lex** — Xây dựng chatbot hội thoại (voice/text), không chuyển text thành audio toàn bộ sách.\n• **Amazon Transcribe** — Chuyển speech → text (speech-to-text), ngược lại với yêu cầu.\n• **Amazon Translate** — Dịch text giữa các ngôn ngữ, không chuyển text thành speech.\n\nDo đó, **Amazon Polly** là giải pháp **phù hợp nhất** để tạo audiobooks từ nội dung sách giáo khoa với giọng nói tự nhiên, đa dạng giọng và ngôn ngữ.\n\nNguồn tham khảo: Amazon Polly documentation – Dịch vụ TTS với neural voices, hỗ trợ multiple languages và voices, lý tưởng cho audiobook production."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A company released a generative AI chatbot for its internal users. The chatbot uses Amazon Bedrock. The company wants to collect metrics and display the metrics on a dashboard that shows the input and output tokens generated for each interaction with the chatbot.\nWhich service should the company use to build a metric dashboard?",
                "options": [
                    "Amazon CloudWatch",
                    "AWS CloudTrail",
                    "AWS Trusted Advisor",
                    "AWS Config"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là thu thập **metrics** (như input/output tokens cho mỗi tương tác) từ chatbot generative AI trên **Amazon Bedrock**, sau đó **hiển thị** trên **dashboard** để theo dõi và phân tích.\n\n**Amazon CloudWatch** là dịch vụ phù hợp nhất:\n\n• **Amazon CloudWatch** — Là dịch vụ giám sát và quan sát (monitoring & observability) của AWS, tích hợp **native** với Amazon Bedrock.\n  - Tự động thu thập metrics Bedrock như:\n    - InputTokens\n    - OutputTokens\n    - InvocationCount\n    - Throttle, Errors, Latency, v.v.\n  - Hỗ trợ **CloudWatch Dashboards** tùy chỉnh để hiển thị metrics theo thời gian thực (near real-time), với biểu đồ, số liệu, và alarm.\n  - Cho phép tạo dashboard tổng hợp input/output tokens theo interaction, theo user, theo model, hoặc theo thời gian.\n  - Có thể đặt alarm khi token usage vượt ngưỡng (giúp kiểm soát chi phí).\n\nCloudWatch là giải pháp **tiêu chuẩn** và **dễ sử dụng** để visualize Bedrock metrics, đặc biệt cho generative AI chatbot.\n\nCác lựa chọn khác không phù hợp:\n• **AWS CloudTrail** — Ghi log API calls (audit trail), không thu thập metrics token usage hay hỗ trợ dashboard metrics.\n• **AWS Trusted Advisor** — Đưa ra khuyến nghị best practices (cost, security), không thu thập/display metrics token.\n• **AWS Config** — Theo dõi thay đổi cấu hình tài nguyên, không liên quan đến metrics Bedrock usage.\n\nDo đó, **Amazon CloudWatch** là dịch vụ **phù hợp nhất** để thu thập và xây dựng dashboard metrics input/output tokens cho chatbot Bedrock.\n\nNguồn tham khảo: Amazon Bedrock monitoring documentation – Bedrock metrics (InputTokens, OutputTokens, v.v.) được gửi trực tiếp đến CloudWatch và hiển thị trên CloudWatch Dashboards."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A company wants to deploy a generative AI application to help employees create images from text inputs.\nWhich type of generative AI model will meet this requirement?",
                "options": [
                    "Transformer-based model",
                    "Multi-class classification model",
                    "Regression model",
                    "Diffusion model"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là xây dựng ứng dụng generative AI **tạo hình ảnh từ mô tả văn bản** (text-to-image generation) để hỗ trợ nhân viên.\n\n**Diffusion model** là loại mô hình phù hợp nhất:\n\n• **Diffusion model** — Là kiến trúc generative AI hiện đại và mạnh mẽ nhất hiện nay cho nhiệm vụ **text-to-image**.\n  - Hoạt động bằng cách bắt đầu từ nhiễu ngẫu nhiên (random noise) và dần dần \"khử nhiễu\" (denoising) qua nhiều bước để tạo ra hình ảnh rõ nét, phù hợp với prompt văn bản.\n  - Các mô hình nổi tiếng: Stable Diffusion, DALL·E 2/3, Midjourney, Imagen, Amazon Titan Image Generator trên Bedrock đều dựa trên nguyên lý diffusion (hoặc hybrid với transformer).\n  - Ưu điểm: chất lượng hình ảnh cao, kiểm soát tốt qua prompt, hỗ trợ tùy chỉnh (fine-tune, LoRA), và khả năng tạo hình ảnh đa dạng, chi tiết.\n\nTrong AWS, **Amazon Bedrock** cung cấp Titan Image Generator (dựa trên diffusion) và hỗ trợ Stable Diffusion – lý tưởng để triển khai text-to-image enterprise.\n\nCác lựa chọn khác không phù hợp:\n• **Transformer-based model** — Chủ yếu dùng cho NLP (text generation, translation). Một số mô hình text-to-image (như DALL·E) dùng transformer cho phần text encoder, nhưng phần sinh hình ảnh chính vẫn là diffusion.\n• **Multi-class classification model** — Chỉ phân loại (ví dụ: nhận diện vật thể trong ảnh), không tạo ảnh mới.\n• **Regression model** — Dự đoán giá trị số liên tục, không liên quan đến sinh ảnh.\n\nDo đó, **Diffusion model** là loại generative AI model **phù hợp nhất** để tạo hình ảnh từ text inputs.\n\nNguồn tham khảo: AWS Bedrock Titan Image Generator & Stable Diffusion documentation – Diffusion models là kiến trúc cốt lõi cho text-to-image generation."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A data scientist wants to fine-tune a foundation model (FM) on Amazon Bedrock to improve the model's performance in a specific industry domain.\nWhich statements accurately describe fine-tuning on Amazon Bedrock? (Select TWO.)",
                "options": [
                    "Fine-tuning requires unlabeled data.",
                    "Fine-tuning can be achieved with a small amount of data compared to pre-training.",
                    "A vector store is necessary to retain data throughout training.",
                    "Any FM on Amazon Bedrock is capable of fine-tuning.",
                    "Fine-tuning an FM results in the creation of a new custom model."
                ],
                "correct": [1, 4],
                "explanation": "Yêu cầu là xác định hai phát biểu **chính xác** về quá trình **fine-tuning** foundation model (FM) trên Amazon Bedrock để cải thiện hiệu suất trong một domain ngành cụ thể.\n\nHai phát biểu đúng là:\n\n• **Fine-tuning can be achieved with a small amount of data compared to pre-training** — Đúng.\n  - Fine-tuning trên Bedrock chỉ cần **một lượng dữ liệu nhỏ** (thường vài trăm đến vài nghìn mẫu labeled) so với pre-training ban đầu (hàng tỷ token).\n  - Điều này giúp tiết kiệm chi phí, thời gian và tài nguyên tính toán, đồng thời vẫn cải thiện đáng kể hiệu suất mô hình cho domain cụ thể (ví dụ: y tế, tài chính, pháp lý).\n\n• **Fine-tuning an FM results in the creation of a new custom model** — Đúng.\n  - Khi fine-tune một FM trên Bedrock, bạn tạo ra một **custom model** mới (riêng biệt) dựa trên mô hình gốc.\n  - Custom model này được lưu trữ và quản lý riêng, có thể deploy độc lập, và giữ nguyên khả năng của mô hình gốc nhưng được tinh chỉnh cho domain/task cụ thể.\n\nCác phát biểu sai:\n• **Fine-tuning requires unlabeled data** — Sai. Fine-tuning trên Bedrock **yêu cầu dữ liệu có nhãn** (labeled data) để học task-specific. Unlabeled data dùng cho continued pre-training.\n• **A vector store is necessary to retain data throughout training** — Sai. Fine-tuning không yêu cầu vector store (như trong RAG). Dữ liệu huấn luyện được upload trực tiếp (S3) và xử lý trong job.\n• **Any FM on Amazon Bedrock is capable of fine-tuning** — Sai. Chỉ một số mô hình hỗ trợ fine-tuning (ví dụ: Titan, Llama, Cohere), không phải tất cả.\n\nDo đó, hai phát biểu chính xác là **B** và **E**.\n\nNguồn tham khảo: Amazon Bedrock documentation – Custom models (fine-tuning) yêu cầu labeled data nhỏ, tạo custom model mới, và chỉ hỗ trợ một số FM."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A startup company is using AWS services for its software development lifecycle. The company wants to use generative AI services to optimize programming productivity and to decrease time to market for the company's applications.\nWhich combination of steps will meet these requirements? (Select TWO.)",
                "options": [
                    "Use Amazon Comprehend for real-time code suggestions.",
                    "Use Amazon Q Developer for real-time code suggestions.",
                    "Use Amazon Fraud Detector for built-in security scans.",
                    "Use Amazon Q Developer for built-in security scans.",
                    "Use Amazon Rekognition for real-time code suggestions."
                ],
                "correct": [1, 3],
                "explanation": "Yêu cầu chính là sử dụng **generative AI** trên AWS để **tăng năng suất lập trình** (programming productivity) và **rút ngắn thời gian đưa sản phẩm ra thị trường** (time to market) trong vòng đời phát triển phần mềm.\n\nHai bước phù hợp nhất là:\n\n• **Use Amazon Q Developer for real-time code suggestions** — Amazon Q Developer là trợ lý generative AI chuyên biệt cho developer:\n  - Sinh gợi ý code thời gian thực (real-time code suggestions) dựa trên comment ngôn ngữ tự nhiên.\n  - Tự động hoàn thiện code, refactor, tạo hàm mới, debug.\n  - Giúp tăng tốc độ viết code, giảm lỗi, rút ngắn thời gian phát triển.\n\n• **Use Amazon Q Developer for built-in security scans** — Ngoài gợi ý code, Amazon Q Developer còn có tính năng **quét bảo mật tích hợp** (built-in security scans):\n  - Tự động phát hiện lỗ hổng bảo mật, vấn đề chất lượng code.\n  - Đề xuất cách sửa ngay trong IDE (như VS Code, JetBrains).\n  - Không cần cấu hình thêm, giúp đảm bảo code an toàn, giảm thời gian review bảo mật thủ công → đẩy nhanh time to market.\n\nAmazon Q Developer là giải pháp **toàn diện** (code generation + security scanning) sử dụng generative AI, đáp ứng cả hai mục tiêu của công ty.\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Comprehend** — NLP cho phân tích văn bản, không hỗ trợ code suggestions.\n• **Amazon Fraud Detector** — Phát hiện gian lận, không liên quan đến code hoặc productivity.\n• **Amazon Rekognition** — Computer vision cho hình ảnh/video, không dùng cho lập trình.\n\nDo đó, **Use Amazon Q Developer for real-time code suggestions** và **Use Amazon Q Developer for built-in security scans** là hai bước **phù hợp nhất**.\n\nNguồn tham khảo: AWS Amazon Q Developer documentation – Hỗ trợ code generation, suggestions, và built-in security scanning để tăng productivity và giảm time to market."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A company has deployed its generative AI model to production. The company wants to know how the model adjusts to unexpected data patterns and user inputs over time.\nWhich stage of the generative AI foundation model (FM) lifecycle does this represent?",
                "options": [
                    "Model evaluation",
                    "Model monitoring",
                    "Model deployment",
                    "Model data preparation"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là xác định **giai đoạn** trong lifecycle của foundation model (FM) generative AI mà công ty quan tâm đến việc **theo dõi cách mô hình thích nghi** với **dữ liệu bất ngờ** và **input người dùng mới** sau khi đã **triển khai vào production**.\n\n**Model monitoring** là giai đoạn phù hợp nhất:\n\n• **Model monitoring** (hay Continuous Monitoring / Post-Deployment Monitoring) — Đây là giai đoạn sau khi mô hình được deploy vào production.\n  - Tập trung vào việc **liên tục theo dõi** hiệu suất, hành vi và độ tin cậy của mô hình khi tương tác với dữ liệu thực tế.\n  - Phát hiện các vấn đề như **data drift** (thay đổi phân phối dữ liệu), **concept drift** (thay đổi mối quan hệ giữa input-output), hoặc **model degradation** (hiệu suất giảm dần theo thời gian).\n  - Quan sát cách mô hình **điều chỉnh** (adapt) với **dữ liệu bất ngờ** và **input người dùng mới**.\n  - Trong generative AI (như Bedrock LLMs), monitoring giúp phát hiện hallucinations tăng, chất lượng response giảm, hoặc bias xuất hiện khi dữ liệu production thay đổi.\n\nTrong AWS, **SageMaker Model Monitor** hoặc **Bedrock monitoring** được sử dụng để thực hiện continuous monitoring sau deploy.\n\nCác giai đoạn khác không phù hợp:\n• **Model evaluation** — Đánh giá hiệu suất trên test set **trước khi deploy**, không theo dõi sau production.\n• **Model deployment** — Chỉ là bước đưa mô hình vào production, không theo dõi thích nghi theo thời gian.\n• **Model data preparation** — Xử lý dữ liệu ban đầu **trước training**, không liên quan đến theo dõi sau deploy.\n\nDo đó, **Model monitoring** là giai đoạn **đại diện** cho việc quan sát cách mô hình generative AI thích nghi với dữ liệu và input bất ngờ theo thời gian.\n\nNguồn tham khảo: AWS Machine Learning Lifecycle & Bedrock documentation – Model monitoring là giai đoạn post-deployment để theo dõi drift và adaptability của FM trong production."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "An AI practitioner has built various models by using Amazon SageMaker AI. The AI practitioner needs to present a governance audit for model risks to senior leadership.\nWhat can the AI practitioner do to present the governance information?",
                "options": [
                    "Use SageMaker Model Cards to build model cards for the models.",
                    "Create an Amazon QuickSight dashboard to visualize key metrics across all models.",
                    "Use SageMaker Model Dashboard for the models that are running.",
                    "Use SageMaker AI endpoints to deploy the models."
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là tìm cách **trình bày thông tin governance** (quản trị) và **rủi ro mô hình** (model risks) cho ban lãnh đạo cấp cao trong một cuộc **kiểm toán governance** (governance audit) cho các mô hình được xây dựng trên Amazon SageMaker.\n\n**Use SageMaker Model Cards to build model cards for the models** là giải pháp phù hợp nhất:\n\n• **SageMaker Model Cards** — Là tính năng chuyên biệt trong Amazon SageMaker để **tạo và quản lý tài liệu governance** cho mô hình ML.\n  - Cho phép ghi chép chi tiết:\n    - Intended use case (mục đích sử dụng).\n    - Performance metrics (độ chính xác, bias metrics, v.v.).\n    - Responsible AI practices (fairness, explainability, robustness).\n    - Potential risks (rủi ro tiềm ẩn, limitations, ethical concerns).\n    - Training details, data sources, và mitigation strategies.\n  - Tạo báo cáo có cấu trúc, dễ đọc, dễ chia sẻ với lãnh đạo hoặc auditor.\n  - Hỗ trợ tuân thủ Responsible AI và các quy định (ví dụ: EU AI Act, HIPAA, GDPR).\n\nModel Cards là công cụ lý tưởng để trình bày governance audit một cách chuyên nghiệp và minh bạch cho senior leadership.\n\nCác lựa chọn khác không phù hợp:\n• **Create an Amazon QuickSight dashboard** — Dùng để visualize metrics kinh doanh/operation, không phải tài liệu governance/risks chi tiết.\n• **Use SageMaker Model Dashboard** — Dùng để monitor operational status của mô hình đang chạy (endpoints, metrics real-time), không cung cấp documentation governance.\n• **Use SageMaker AI endpoints** — Chỉ để deploy và serve mô hình, không liên quan đến việc trình bày audit.\n\nDo đó, **SageMaker Model Cards** là cách **tốt nhất** để trình bày thông tin governance và rủi ro mô hình cho lãnh đạo.\n\nNguồn tham khảo: AWS SageMaker Model Cards documentation – Công cụ chính thức để document model governance, risks, và responsible AI practices cho audit và reporting."
            },
            {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A company wants to deploy an ML model that will provide near real-time inference for high-definition images. The images can take up to 3 minutes to process.\nWhich model inference type will meet these requirements?",
                "options": [
                    "Real-time inference",
                    "Serverless inference",
                    "Asynchronous inference",
                    "Batch transform"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm loại inference trong Amazon SageMaker phù hợp cho bài toán **near real-time** trên hình ảnh độ phân giải cao (high-definition images), với thời gian xử lý **lên đến 3 phút** (cần queue request nếu endpoint bận).\n\n**Asynchronous inference** là loại phù hợp nhất:\n\n• **Asynchronous inference** — Được thiết kế cho các workload cần xử lý **gần thời gian thực** (near real-time) nhưng có thể mất thời gian dài hơn (lên đến **1 giờ** cho mỗi request).\n  - Hỗ trợ **queue** request khi endpoint bận, scale tự động theo nhu cầu.\n  - Phù hợp cho **high-definition image processing** (ví dụ: object detection, segmentation, enhancement) vì hình ảnh lớn thường mất nhiều thời gian.\n  - Không yêu cầu endpoint luôn sẵn sàng như real-time, nhưng vẫn cho phép xử lý nhanh khi có request (queue và process theo thứ tự).\n  - Trong SageMaker, asynchronous inference là giải pháp lý tưởng cho các task inference chậm nhưng cần xử lý theo thời gian thực (không phải batch offline).\n\nCác loại khác không đáp ứng:\n• **Real-time inference** — Giới hạn tối đa **60 giây** mỗi request, không phù hợp cho 3 phút.\n• **Serverless inference** — Cũng giới hạn **60 giây**, và dành cho workload spiky/low-latency.\n• **Batch transform** — Dùng cho **batch processing offline** (lớn, có thể mất hàng giờ/ngày), không phải near real-time, không có endpoint persistent.\n\nDo đó, **Asynchronous inference** là loại inference **phù hợp nhất** để đáp ứng yêu cầu near real-time với thời gian xử lý lên đến 3 phút.\n\nNguồn tham khảo: Amazon SageMaker documentation – Asynchronous inference được thiết kế cho workloads có processing time dài (lên đến 1 giờ) và cần queue, lý tưởng cho image processing tasks."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "A company built an AI application by using Amazon Bedrock. The company needs to check if the application is in compliance with regulations.\nWhich AWS service or feature checks if AWS resources comply with regulations?",
                "options": [
                    "Amazon Bedrock Guardrails",
                    "Amazon Bedrock model evaluation",
                    "AWS Audit Manager",
                    "AWS Artifact"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm dịch vụ hoặc tính năng AWS có khả năng **kiểm tra tuân thủ quy định** (compliance check) cho ứng dụng AI xây dựng trên Amazon Bedrock.\n\n**AWS Audit Manager** là giải pháp phù hợp nhất:\n\n• **AWS Audit Manager** — Là dịch vụ chuyên biệt để **tự động hóa kiểm toán tuân thủ** (automated compliance auditing) cho các workload AWS, bao gồm cả ứng dụng generative AI trên Bedrock.\n  - Cung cấp **framework prebuilt** dành riêng cho generative AI (bao gồm Bedrock best practices).\n  - Thu thập evidence liên tục từ các dịch vụ AWS (CloudTrail, Config, Security Hub, v.v.) để đánh giá tuân thủ các quy định như HIPAA, GDPR, PCI DSS, SOC 2, ISO 27001.\n  - Theo dõi việc sử dụng mô hình (model usage), phát hiện dữ liệu nhạy cảm (sensitive data), và gửi cảnh báo khi có vi phạm.\n  - Tạo báo cáo audit-ready, giúp chuẩn bị cho kiểm toán nội bộ hoặc bên ngoài mà không cần thu thập thủ công.\n\nĐây là dịch vụ duy nhất trong các lựa chọn có khả năng **kiểm tra và đánh giá compliance** một cách chủ động và liên tục cho ứng dụng Bedrock.\n\nCác lựa chọn khác không đáp ứng:\n• **Amazon Bedrock Guardrails** — Chỉ lọc/chặn nội dung không phù hợp (harmful content), không kiểm tra tuân thủ quy định tổng thể.\n• **Amazon Bedrock model evaluation** — Đánh giá hiệu suất mô hình (accuracy, coherence), không liên quan đến compliance.\n• **AWS Artifact** — Cung cấp tài liệu tuân thủ của AWS (reports, agreements), nhưng **không tự động kiểm tra** workload của bạn có tuân thủ hay không.\n\nDo đó, **AWS Audit Manager** là dịch vụ **phù hợp nhất** để kiểm tra xem ứng dụng AI trên Bedrock có tuân thủ quy định hay không.\n\nNguồn tham khảo: AWS Audit Manager documentation – Hỗ trợ framework generative AI và Bedrock, giúp automate compliance audits cho AI workloads."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A company uses an AI model to automatically tag customer emails as Complaint, Inquiry, or Feedback. The model is trained on thousands of pre-labeled emails to learn patterns.\nWhat type of NLP is used when an AI learns from labeled data to classify new text?",
                "options": [
                    "Natural language understanding (NLU)",
                    "Natural language generation (NLG)",
                    "Supervised NLP",
                    "Unsupervised NLP"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là xác định loại NLP mà mô hình sử dụng khi **học từ dữ liệu có nhãn** (pre-labeled emails) để **phân loại** (classify) văn bản mới thành các nhãn như Complaint, Inquiry, Feedback.\n\n**Supervised NLP** là loại phù hợp nhất:\n\n• **Supervised NLP** — Đây là phương pháp xử lý ngôn ngữ tự nhiên sử dụng **học có giám sát** (supervised learning): mô hình được huấn luyện trên tập dữ liệu có nhãn (labeled dataset), nơi mỗi email đã được gắn sẵn nhãn (Complaint, Inquiry, Feedback).\n  - Mô hình học các pattern trong văn bản (từ khóa, cấu trúc câu, ngữ điệu, v.v.) để liên kết với nhãn tương ứng.\n  - Sau khi huấn luyện, mô hình có thể dự đoán nhãn cho email mới (unseen data) một cách tự động và chính xác.\n  - Đây là kỹ thuật tiêu chuẩn cho các bài toán **text classification** (phân loại văn bản) như phân loại email, sentiment analysis, spam detection.\n\nTrong AWS, các dịch vụ như **Amazon Comprehend** (custom classification) hoặc **SageMaker** hỗ trợ supervised NLP để train mô hình trên dữ liệu có nhãn.\n\nCác lựa chọn khác không đúng:\n• **Natural language understanding (NLU)** — Là khái niệm rộng về việc hiểu ý nghĩa, ngữ cảnh, intent của văn bản, không chỉ cụ thể phương pháp học (có thể dùng supervised hoặc unsupervised).\n• **Natural language generation (NLG)** — Dùng để **sinh văn bản** (tạo phản hồi, tóm tắt), không phải phân loại.\n• **Unsupervised NLP** — Học từ dữ liệu **không nhãn** (ví dụ: topic modeling, clustering), không phù hợp vì câu hỏi nhấn mạnh \"pre-labeled emails\".\n\nDo đó, **Supervised NLP** là loại NLP chính xác nhất mô tả quá trình học từ dữ liệu có nhãn để phân loại văn bản mới.\n\nNguồn tham khảo: AWS Comprehend & SageMaker documentation – Supervised learning (custom classification) là phương pháp cốt lõi cho text classification tasks với labeled data."
            }, {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A global training provider has developed a system that leverages generative AI. This system is used to translate training manuals via large language models (LLMs) from English into different languages. The training provider now seeks to assess the accuracy of the generated text to ensure it meets quality standards.\nWhat is the most suitable model evaluation strategy to achieve these objectives?",
                "options": [
                    "Bilingual Evaluation Understudy (BLEU)",
                    "Area Under the ROC Curve",
                    "BERTScore",
                    "F1 Score"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là tìm chiến lược **đánh giá mô hình** phù hợp nhất để đo lường **độ chính xác** của bản dịch (translation accuracy) từ tiếng Anh sang các ngôn ngữ khác cho tài liệu đào tạo, khi sử dụng large language models (LLMs) hoặc generative AI.\n\n**Bilingual Evaluation Understudy (BLEU)** là metric phù hợp nhất:\n\n• **BLEU** — Là metric tiêu chuẩn và được sử dụng rộng rãi nhất trong lĩnh vực **machine translation** (dịch máy).\n  - Đo lường mức độ trùng khớp n-gram (chuỗi từ liên tiếp) giữa bản dịch do máy tạo ra và bản dịch tham chiếu (reference translation) do con người thực hiện.\n  - Điểm số BLEU nằm trong khoảng 0–1 (hoặc 0–100), giá trị càng cao càng cho thấy bản dịch máy càng gần với bản dịch chuẩn.\n  - Ưu điểm: Dễ tính toán, khách quan, có thể tự động hóa, và được công nhận trong ngành (dùng trong Google Translate, Amazon Translate, DeepL, v.v.).\n  - Phù hợp để đánh giá chất lượng dịch tài liệu đào tạo, đảm bảo nội dung giữ nguyên ý nghĩa, thuật ngữ chuyên ngành.\n\nTrong AWS, khi dùng Amazon Translate hoặc Bedrock LLMs cho translation, BLEU là metric phổ biến để benchmark và cải thiện chất lượng.\n\nCác lựa chọn khác không phù hợp:\n• **Area Under the ROC Curve (AUC)** — Dùng cho **phân loại nhị phân** (binary classification), không áp dụng cho đánh giá chất lượng dịch.\n• **BERTScore** — Dùng để đo semantic similarity (dựa trên embedding BERT), tốt cho paraphrase/summarization, nhưng **không phải metric chuẩn** cho machine translation (BLEU vẫn được ưu tiên hơn trong lĩnh vực này).\n• **F1 Score** — Dùng cho classification, không liên quan đến đánh giá translation.\n\nDo đó, **Bilingual Evaluation Understudy (BLEU)** là chiến lược đánh giá **phù hợp nhất** để đảm bảo độ chính xác và chất lượng bản dịch từ LLMs.\n\nNguồn tham khảo: AWS Translate & Bedrock documentation – BLEU là metric tiêu chuẩn cho machine translation evaluation."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A cloud engineering team is using large language models (LLMs) to enhance its development workflow. The team wants the AI to convert natural language code comments like 'Add error handling for Amazon S3 uploads' into complete Python functions.\nWhich model evaluation in Amazon Bedrock enables this automatic code creation from plain-text descriptions?",
                "options": [
                    "Question and answer",
                    "Guardrails for Amazon Bedrock",
                    "General text generation",
                    "Text classification"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm tính năng **đánh giá mô hình** trong Amazon Bedrock hỗ trợ **tự động tạo code hoàn chỉnh** (complete Python functions) từ mô tả bằng ngôn ngữ tự nhiên (natural language code comments), ví dụ: chuyển 'Add error handling for Amazon S3 uploads' thành hàm Python với try-except, logging, v.v.\n\n**General text generation** là tính năng phù hợp nhất:\n\n• **General text generation** trong Amazon Bedrock là khả năng đánh giá và sử dụng foundation models (như Claude, Titan, Llama) để sinh ra văn bản tự do, bao gồm **code generation** từ prompt ngôn ngữ tự nhiên.\n  - Đây là nhiệm vụ điển hình của generative AI: hiểu ý định từ text, sau đó sinh ra code Python (hoặc bất kỳ ngôn ngữ nào) một cách mạch lạc, đúng cú pháp.\n  - Bedrock cung cấp evaluation metrics (accuracy, coherence, relevance) để kiểm tra chất lượng code sinh ra từ các prompt như \"Write a Python function to upload file to S3 with error handling\".\n  - Phù hợp cho cloud engineering workflow: tự động hóa viết boilerplate code, thêm error handling, refactor, v.v.\n\nCác lựa chọn khác không phù hợp:\n• **Question and answer** — Tập trung vào trả lời câu hỏi kiến thức/fact-based (QA), không phải sinh code sáng tạo.\n• **Guardrails for Amazon Bedrock** — Chỉ dùng để lọc/chặn nội dung không an toàn, không liên quan đến việc tạo code.\n• **Text classification** — Phân loại văn bản (ví dụ: sentiment, topic), không sinh ra code mới.\n\nDo đó, **General text generation** là tính năng đánh giá và ứng dụng trong Bedrock **phù hợp nhất** để chuyển đổi mô tả tự nhiên thành code Python hoàn chỉnh.\n\nNguồn tham khảo: Amazon Bedrock documentation – General text generation (text generation tasks) hỗ trợ code generation từ natural language prompts, là use case cốt lõi của LLMs trong development workflow."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A data scientist needs the model to break down a complex problem into smaller tasks and solve each sequentially.\nWhich prompt engineering technique does this?",
                "options": [
                    "Directional-stimulus prompting",
                    "Generated knowledge prompting",
                    "Complexity-based prompting",
                    "Least-to-most prompting"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là kỹ thuật prompt engineering giúp mô hình **phân tích vấn đề phức tạp thành các nhiệm vụ nhỏ hơn** (break down into smaller tasks) và **giải quyết từng bước một cách tuần tự** (solve each sequentially).\n\n**Least-to-most prompting** là kỹ thuật phù hợp nhất:\n\n• **Least-to-most prompting** — Đây là phương pháp prompt theo kiểu \"từ đơn giản đến phức tạp\":\n  - Bắt đầu bằng cách yêu cầu mô hình giải quyết một phiên bản **đơn giản nhất** của vấn đề.\n  - Sau đó sử dụng output của bước trước làm context để giải quyết phiên bản **phức tạp hơn** một chút.\n  - Tiếp tục lặp lại, dần dần mở rộng độ khó cho đến khi giải quyết toàn bộ vấn đề phức tạp ban đầu.\n\nKỹ thuật này bắt chước cách con người giải quyết vấn đề lớn: chia nhỏ (decompose), giải từng phần, và tích lũy kiến thức từ các bước trước để giải quyết bước tiếp theo. Nó đặc biệt hiệu quả với các bài toán multi-step reasoning, chain-of-thought nâng cao, hoặc vấn đề cần lập kế hoạch dài hạn.\n\nCác kỹ thuật khác không đáp ứng trực tiếp:\n• **Directional-stimulus prompting** — Chỉ dùng các gợi ý/cue để hướng dẫn mô hình trả lời theo hướng mong muốn, không phân tích vấn đề thành các bước nhỏ.\n• **Generated knowledge prompting** — Yêu cầu mô hình sinh ra kiến thức hoặc thông tin bổ sung trước khi giải quyết vấn đề, không tập trung vào việc chia nhỏ và giải tuần tự.\n• **Complexity-based prompting** — Chọn ví dụ có độ phức tạp tăng dần để huấn luyện hoặc prompt, nhưng không phải là kỹ thuật chia nhỏ vấn đề và giải từng bước.\n\nDo đó, **Least-to-most prompting** là kỹ thuật prompt engineering **phù hợp nhất** để mô hình phân tích và giải quyết vấn đề phức tạp theo cách tuần tự.\n\nNguồn tham khảo: Các nghiên cứu prompt engineering (Zhou et al., 2022) – Least-to-Most Prompting được đề xuất như một phương pháp hiệu quả để xử lý các vấn đề reasoning phức tạp bằng cách decompose và solve sequentially."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A global e-commerce company stores billions of behavioral and transactional events in Amazon S3 to train fraud detection models. The data science team needs to:\n* Run distributed feature extraction with PySpark\n* Perform iterative feature engineering\n* Schedule scalable, fault-tolerant ETL jobs\nWhich AWS service best supports large-scale, distributed feature engineering using open-source tools?",
                "options": [
                    "Amazon Redshift",
                    "AWS Glue DataBrew",
                    "Amazon OpenSearch Service",
                    "Amazon EMR"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là tìm dịch vụ AWS hỗ trợ **xử lý phân tán quy mô lớn** (large-scale distributed processing) với **PySpark**, **feature engineering lặp lại** (iterative), **ETL job có khả năng lập lịch, chịu lỗi cao** (scalable, fault-tolerant) trên dữ liệu hàng tỷ bản ghi lưu trong S3 để huấn luyện mô hình phát hiện gian lận.\n\n**Amazon EMR** (Elastic MapReduce) là dịch vụ phù hợp nhất:\n\n• **Amazon EMR** — Là nền tảng big data cloud-native, hỗ trợ chạy các framework open-source như **Apache Spark (PySpark)**, Hadoop, Hive, Presto ở quy mô lớn.\n  - Cho phép **distributed feature extraction** trên hàng tỷ bản ghi từ S3 một cách hiệu quả.\n  - Hỗ trợ **iterative feature engineering** (chạy nhiều job PySpark để thử nghiệm, tinh chỉnh feature).\n  - Có khả năng **lập lịch** (scheduling) job qua EMR Steps hoặc tích hợp Airflow/Step Functions.\n  - **Scalable** (tự động scale cluster), **fault-tolerant** (tự động retry, checkpointing, spot instances để tiết kiệm chi phí).\n  - Tích hợp chặt chẽ với S3 (đọc/ghi trực tiếp), lý tưởng cho ML pipelines với dữ liệu lớn.\n\nEMR là lựa chọn tiêu chuẩn cho data science team cần PySpark ở quy mô enterprise, đặc biệt trong fraud detection với volume dữ liệu khổng lồ.\n\nCác dịch vụ khác không đáp ứng:\n• **Amazon Redshift** — Data warehouse SQL-based, không hỗ trợ PySpark hay distributed processing open-source.\n• **AWS Glue DataBrew** — Công cụ low-code/visual cho data preparation, không hỗ trợ PySpark hoặc workload distributed lớn.\n• **Amazon OpenSearch Service** — Dùng cho search, log analytics, indexing, không phải cho ETL/feature engineering.\n\nDo đó, **Amazon EMR** là dịch vụ **tốt nhất** hỗ trợ large-scale, distributed feature engineering với open-source tools như PySpark.\n\nNguồn tham khảo: AWS EMR documentation – EMR là nền tảng chính cho PySpark workloads, ETL, và feature engineering trên dữ liệu lớn từ S3 trong ML pipelines."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A tech startup is building a customer support system using Amazon Bedrock and a large language model (LLM) to produce inferences. The startup is using Amazon S3 for data storage and wants to optimize costs while evaluating what affects the overall costs for its generative AI applications.\nWhat primarily affects the inference costs for the system?",
                "options": [
                    "Frequency of model fine-tuning",
                    "Size of training data utilized",
                    "Model batch size",
                    "Amount of tokens processed"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là xác định yếu tố **chủ yếu ảnh hưởng đến chi phí inference** (suy luận) trong hệ thống chatbot hỗ trợ khách hàng sử dụng Amazon Bedrock và LLM.\n\n**Amount of tokens processed** là yếu tố chính quyết định chi phí inference:\n\n• Trong Amazon Bedrock, chi phí inference được tính dựa trên **số token xử lý** (input + output tokens) cho mỗi request.\n  - **Input tokens**: Số token trong prompt (bao gồm lịch sử hội thoại, context, policy documents, v.v.).\n  - **Output tokens**: Số token trong phản hồi mà LLM sinh ra.\n\nMỗi model trên Bedrock (Claude, Titan, Llama, v.v.) có giá tính phí **theo token** (ví dụ: $x.xx per 1,000 input tokens và $y.yy per 1,000 output tokens). Vì vậy:\n  - Câu hỏi dài → nhiều input tokens → chi phí cao hơn.\n  - Phản hồi dài, chi tiết → nhiều output tokens → chi phí cao hơn.\n  - Số lượng request cao → tổng token tăng → chi phí tăng tuyến tính.\n\nĐây là yếu tố **trực tiếp và quan trọng nhất** ảnh hưởng đến inference cost trong generative AI, đặc biệt với ứng dụng customer support có volume tương tác lớn.\n\nCác lựa chọn khác không ảnh hưởng chính đến inference cost:\n• **Frequency of model fine-tuning** — Chỉ ảnh hưởng đến chi phí **training/custom model** (fine-tuning), không liên quan đến inference.\n• **Size of training data utilized** — Ảnh hưởng đến chi phí huấn luyện ban đầu/fine-tuning, không tác động đến chi phí inference sau khi deploy.\n• **Model batch size** — Liên quan đến tối ưu hiệu suất training hoặc batch inference, nhưng trong Bedrock inference (thường real-time), batch size không phải yếu tố tính phí chính (Bedrock charge theo token, không theo batch).\n\nDo đó, **Amount of tokens processed** là yếu tố **chủ yếu** ảnh hưởng đến chi phí inference của hệ thống.\n\nNguồn tham khảo: Amazon Bedrock pricing documentation – Inference costs are primarily driven by the number of input and output tokens processed per request."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A team checks data privacy laws and confirms ethical guidelines for patient data.\nWhich phase of the ML lifecycle is this?",
                "options": [
                    "Business goal identification",
                    "Model development",
                    "Feature engineering",
                    "Data preprocessing"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là xác định **giai đoạn nào** trong quy trình lifecycle machine learning mà đội ngũ **kiểm tra luật bảo vệ dữ liệu (data privacy laws)** và **xác nhận hướng dẫn đạo đức (ethical guidelines)** liên quan đến dữ liệu bệnh nhân (patient data).\n\n**Business goal identification** là giai đoạn phù hợp nhất:\n\n• Trong **ML lifecycle** (theo AWS Well-Architected Framework for Machine Learning), giai đoạn **Business goal identification** là bước đầu tiên và quan trọng nhất.\n  - Tại đây, tổ chức xác định vấn đề kinh doanh cần giải quyết, mục tiêu cụ thể, tiêu chí thành công (success criteria), và **đánh giá tính khả thi** của giải pháp ML.\n  - **Kiểm tra tuân thủ pháp lý** (compliance with data privacy laws như GDPR, HIPAA, CCPA) và **xác nhận đạo đức** (ethical guidelines, bias, fairness, responsible AI) là phần cốt lõi của giai đoạn này.\n  - Trước khi thu thập dữ liệu hoặc bắt đầu bất kỳ công việc kỹ thuật nào, đội ngũ phải đảm bảo việc sử dụng dữ liệu bệnh nhân (PHI – Protected Health Information) được phép theo luật và đạo đức, tránh rủi ro pháp lý và mất lòng tin.\n\nĐây là best practice theo AWS: **xem xét regulatory, ethical, và governance requirements ngay từ giai đoạn đầu** (business understanding) để định hướng toàn bộ dự án.\n\nCác giai đoạn khác không phù hợp:\n• **Model development** — Tập trung vào huấn luyện, tinh chỉnh và đánh giá mô hình, diễn ra sau khi đã xác định mục tiêu và đảm bảo tuân thủ.\n• **Feature engineering** — Tạo/chọn đặc trưng từ dữ liệu, giả định dữ liệu đã được thu thập hợp pháp.\n• **Data preprocessing** — Làm sạch, biến đổi dữ liệu, có thể áp dụng kỹ thuật anonymization, nhưng không phải nơi quyết định pháp lý/đạo đức ban đầu.\n\nDo đó, **Business goal identification** là giai đoạn mà đội ngũ thực hiện kiểm tra luật bảo vệ dữ liệu và xác nhận hướng dẫn đạo đức cho dữ liệu bệnh nhân.\n\nNguồn tham khảo: AWS Well-Architected Machine Learning Lens – Business goal identification bao gồm đánh giá compliance, ethics, và data governance trước khi tiến hành các giai đoạn kỹ thuật."
            }, {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A retail company needs an AI system to automatically scan product images for defects, such as scratches or dents, before listing products online.\nWhich of the following types of AI applications would best suit this need?",
                "options": [
                    "Image processing",
                    "Computer vision",
                    "Image segmentation",
                    "Optical character recognition (OCR)"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính của công ty bán lẻ là xây dựng hệ thống AI **tự động quét hình ảnh sản phẩm** để **phát hiện khuyết điểm** (defects) như vết xước (scratches), vết lõm (dents), nhằm đảm bảo chất lượng trước khi đăng bán online.\n\n**Computer vision** là loại ứng dụng AI phù hợp nhất:\n\n• **Computer vision** — Là lĩnh vực AI chuyên giúp máy tính \"nhìn\" và hiểu nội dung hình ảnh/video một cách thông minh, tương tự như thị giác con người.\n  - Sử dụng các kỹ thuật như object detection, anomaly detection, image classification, semantic segmentation để phát hiện và phân loại khuyết điểm trên sản phẩm.\n  - Có thể huấn luyện mô hình deep learning (CNN như ResNet, YOLO, EfficientNet) để nhận diện vết xước, vết lõm, màu sắc bất thường, hoặc các lỗi khác trên hình ảnh sản phẩm.\n  - Ứng dụng phổ biến trong **quality control** (kiểm soát chất lượng) của bán lẻ và sản xuất: tự động hóa kiểm tra hàng hóa, giảm lỗi con người, tăng tốc độ xử lý.\n\nTrong AWS, các dịch vụ như **Amazon Rekognition Custom Labels** hoặc **SageMaker** với mô hình computer vision được sử dụng rộng rãi cho bài toán defect detection.\n\nCác lựa chọn khác không phù hợp:\n• **Image processing** — Chỉ xử lý cơ bản hình ảnh (lọc nhiễu, điều chỉnh độ sáng/tương phản), không có khả năng \"hiểu\" và phát hiện khuyết điểm một cách thông minh.\n• **Image segmentation** — Là kỹ thuật **phân đoạn hình ảnh** (chia ảnh thành các vùng pixel), thường dùng làm bước hỗ trợ trong computer vision, nhưng không phải là ứng dụng tổng quát để phát hiện khuyết điểm.\n• **Optical character recognition (OCR)** — Chuyên nhận diện và trích xuất **văn bản** từ hình ảnh (như số serial, nhãn mác), không liên quan đến phát hiện khuyết điểm vật lý.\n\nDo đó, **Computer vision** là loại ứng dụng AI **phù hợp nhất** cho việc tự động quét và phát hiện khuyết điểm trên hình ảnh sản phẩm trong bán lẻ.\n\nNguồn tham khảo: AWS Rekognition & SageMaker documentation – Computer vision là lĩnh vực cốt lõi cho visual inspection và defect detection trong retail & manufacturing."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "A company is using Amazon Bedrock for machine learning and AWS Lambda for event-driven workflows. The company must log all requests to the Bedrock API and Lambda invocations, ensuring the logs are securely retained for 3 years with minimal storage costs.\nWhich of the following will meet the given requirements? (Select TWO.)",
                "options": [
                    "AWS Config",
                    "Amazon S3 Glacier Deep Archive",
                    "Amazon S3 Intelligent-Tiering",
                    "Amazon CloudWatch",
                    "AWS CloudTrail"
                ],
                "correct": [2, 4],
                "explanation": "Yêu cầu chính bao gồm hai phần: **ghi log tất cả các request đến Bedrock API** và **Lambda invocations**, đồng thời **lưu trữ log an toàn trong 3 năm** với **chi phí lưu trữ tối thiểu**.\n\nHai giải pháp phù hợp nhất là:\n\n• **AWS CloudTrail** — Dịch vụ ghi log API-level cho toàn bộ tài khoản AWS, bao gồm:\n  - Tất cả các API call đến Amazon Bedrock (InvokeModel, Converse, v.v.).\n  - Các Lambda invocations (qua CloudTrail event source).\n  - Cung cấp lịch sử chi tiết: ai gọi, khi nào, từ IP nào, tham số request/response (không chứa payload nhạy cảm).\n  - CloudTrail là giải pháp **tiêu chuẩn** để audit và log API cho compliance (HIPAA, PCI DSS, SOC 2, GDPR).\n\n• **Amazon S3 Intelligent-Tiering** — Lớp lưu trữ tối ưu chi phí cho log:\n  - Tự động chuyển dữ liệu giữa các tier dựa trên pattern truy cập (frequent → infrequent → archive).\n  - Không có phí retrieval cho các tier thấp (khác với Glacier).\n  - Chi phí lưu trữ thấp hơn nhiều so với S3 Standard sau 30–90 ngày.\n  - Hỗ trợ retention 3 năm dễ dàng qua lifecycle policy.\n  - Đảm bảo an toàn (encryption at rest, versioning, MFA delete).\n\nCloudTrail lưu log vào S3 bucket → kết hợp với Intelligent-Tiering là cách **an toàn, tuân thủ** và **tối ưu chi phí** nhất.\n\nCác lựa chọn khác không phù hợp:\n• **AWS Config** — Theo dõi thay đổi cấu hình tài nguyên, không ghi API call hoặc Lambda invocations.\n• **Amazon S3 Glacier Deep Archive** — Chi phí thấp nhất nhưng retrieval chậm (12 giờ), không phù hợp cho audit log cần truy xuất nhanh khi kiểm toán.\n• **Amazon CloudWatch** — Ghi metrics và application logs, không ghi chi tiết API call Bedrock/Lambda.\n\nDo đó, **AWS CloudTrail** (để log) và **Amazon S3 Intelligent-Tiering** (để lưu trữ chi phí thấp) là hai giải pháp đáp ứng đầy đủ yêu cầu.\n\nNguồn tham khảo: AWS CloudTrail documentation (Bedrock integration) & S3 Intelligent-Tiering best practices – Khuyến nghị cho long-term log retention với minimal cost."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A music streaming service aims to enhance its search engine by recommending songs based on users’ listening history and preferences.\nWhich of the following AWS services is most appropriate for fulfilling the given requirements?",
                "options": [
                    "Amazon Comprehend",
                    "Amazon Personalize",
                    "Amazon Kendra",
                    "Amazon Lex"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính của dịch vụ streaming nhạc là **cá nhân hóa gợi ý bài hát** (song recommendations) dựa trên **lịch sử nghe** (listening history) và **sở thích** (preferences) của người dùng, nhằm nâng cao trải nghiệm tìm kiếm và tăng tương tác.\n\n**Amazon Personalize** là dịch vụ AWS phù hợp nhất:\n\n• **Amazon Personalize** — Là dịch vụ **AI-driven personalization** chuyên biệt, sử dụng machine learning để tạo ra các gợi ý cá nhân hóa thời gian thực (real-time recommendations) dựa trên:\n  - Dữ liệu hành vi người dùng (user interactions): lịch sử nghe, skip, like, playlist, thời gian nghe, v.v.\n  - Thông tin nhân khẩu học (demographics) tùy chọn: tuổi, vị trí, giới tính.\n  - Danh sách bài hát (items) cần gợi ý.\n\nDịch vụ tự động:\n  - Phân tích dữ liệu\n  - Chọn thuật toán phù hợp (matrix factorization, deep learning-based)\n  - Huấn luyện và tối ưu mô hình cá nhân hóa riêng cho từng khách hàng\n  - Cung cấp API để tích hợp vào search engine hoặc giao diện ứng dụng\n\nAmazon Personalize rất lý tưởng cho các nền tảng streaming nhạc (như Spotify, Apple Music, Amazon Music), nơi gợi ý cá nhân hóa là yếu tố cốt lõi để giữ chân người dùng.\n\nCác dịch vụ khác không phù hợp:\n• **Amazon Comprehend** — NLP để phân tích văn bản (sentiment, entity, key phrases), không tạo gợi ý cá nhân hóa dựa trên hành vi.\n• **Amazon Kendra** — Tìm kiếm thông minh cho tài liệu doanh nghiệp, không chuyên về recommendation dựa trên user behavior.\n• **Amazon Lex** — Xây dựng chatbot và giao diện hội thoại, không xử lý logic recommendation.\n\nDo đó, **Amazon Personalize** là dịch vụ **phù hợp nhất** để nâng cao search engine bằng gợi ý bài hát cá nhân hóa dựa trên lịch sử nghe và sở thích người dùng.\n\nNguồn tham khảo: AWS Personalize documentation – Dịch vụ được thiết kế dành riêng cho recommendation systems trong media & entertainment, đặc biệt music streaming."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A financial company has built a binary classification model using Amazon SageMaker AI to detect fraudulent transactions. The model outputs a probability between 0 and 1 for each prediction. Since fraud cases are rare, the team needs to evaluate the model’s performance while accounting for class imbalance.\nWhich metric best measures the model’s ability to distinguish between fraud and non-fraud across all thresholds?",
                "options": [
                    "Precision",
                    "Area Under the ROC Curve (AUC) Score",
                    "F1-Score",
                    "Accuracy"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là tìm metric **tốt nhất** để đánh giá khả năng **phân biệt** (distinguish) giữa giao dịch gian lận (fraud – positive class) và không gian lận (non-fraud – negative class) trong mô hình **phân loại nhị phân** (binary classification) khi **dữ liệu mất cân bằng nghiêm trọng** (fraud cases are rare), và metric phải **xem xét toàn bộ ngưỡng** (across all thresholds).\n\n**Area Under the ROC Curve (AUC) Score** là metric phù hợp nhất:\n\n• **AUC-ROC** — Đo lường khả năng phân biệt tổng thể của mô hình qua đường cong ROC (Receiver Operating Characteristic), trong đó:\n  - Trục X: False Positive Rate (FPR – tỷ lệ dự đoán sai positive).\n  - Trục Y: True Positive Rate (TPR – recall, tỷ lệ phát hiện đúng fraud).\n  - AUC là diện tích dưới đường cong ROC, giá trị từ 0 đến 1.\n    - AUC = 1.0: Phân biệt hoàn hảo.\n    - AUC = 0.5: Không khác gì đoán ngẫu nhiên.\n\nƯu điểm quan trọng:\n  - **Threshold-independent** — Đánh giá khả năng xếp hạng (ranking) dự đoán của mô hình trên toàn bộ các ngưỡng có thể (từ 0 đến 1), không phụ thuộc vào một ngưỡng cố định.\n  - **Rất phù hợp với class imbalance** — Không bị ảnh hưởng bởi tỷ lệ fraud/non-fraud, khác với accuracy (dễ đạt cao chỉ bằng cách luôn dự đoán non-fraud).\n  - Trong fraud detection, AUC giúp so sánh mô hình, chọn ngưỡng tối ưu (ví dụ: ngưỡng thấp để recall cao, ngưỡng cao để precision cao), và đánh giá khả năng phân biệt thực sự giữa fraud/non-fraud.\n\nTrong Amazon SageMaker, AUC là metric mặc định và được khuyến nghị mạnh mẽ cho các bài toán fraud detection binary classification có imbalance.\n\nCác metric khác không phù hợp:\n• **Precision** — Chỉ đo tỷ lệ dự đoán fraud thực sự đúng, phụ thuộc ngưỡng, không đánh giá khả năng phát hiện tất cả fraud.\n• **F1-Score** — Cân bằng precision và recall tại một ngưỡng cố định, không xem xét toàn bộ threshold.\n• **Accuracy** — Dễ bị đánh lừa bởi imbalance (ví dụ: 99.9% non-fraud → accuracy 99.9% dù không phát hiện được fraud nào).\n\nDo đó, **Area Under the ROC Curve (AUC) Score** là metric **tốt nhất** để đánh giá khả năng phân biệt fraud/non-fraud trên toàn bộ ngưỡng trong dataset mất cân bằng.\n\nNguồn tham khảo: AWS SageMaker documentation & ML best practices – AUC-ROC là metric tiêu chuẩn cho binary classification với class imbalance, đặc biệt trong fraud detection."
            },
            {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A research institute is using a foundation model (FM) for real-time data analysis and needs a training strategy that regularly updates the model with new data to maintain its relevance and accuracy.\nWhich of the following will meet the requirements?",
                "options": [
                    "Fine-tuning",
                    "Static training",
                    "Continuous pre-training",
                    "Transfer learning"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm chiến lược huấn luyện cho phép **cập nhật định kỳ** foundation model (FM) bằng **dữ liệu mới** để duy trì **tính liên quan (relevance)** và **độ chính xác (accuracy)** trong phân tích dữ liệu thời gian thực (real-time data analysis).\n\n**Continuous pre-training** là chiến lược phù hợp nhất:\n\n• **Continuous pre-training** (hay còn gọi là Continued Pre-training – CPT) — Là quá trình **tiếp tục huấn luyện** mô hình foundation đã pre-trained trên dữ liệu mới (thường là unlabeled data) bằng các objective unsupervised giống như giai đoạn pre-training ban đầu (masked language modeling, next token prediction, causal LM).\n  - Không thay đổi kiến trúc mô hình.\n  - Giữ nguyên khả năng ngôn ngữ tổng quát (general capabilities) trong khi giúp mô hình thích nghi với sự thay đổi của dữ liệu (data distribution shift), domain mới hoặc thông tin cập nhật.\n  - Cho phép **cập nhật liên tục** khi có dữ liệu mới (ví dụ: dữ liệu thời gian thực hàng ngày/tuần/tháng) mà không cần fine-tune cho task cụ thể.\n  - Rất phù hợp cho các ứng dụng real-time analysis cần model luôn \"fresh\" và chính xác theo thời gian.\n\nTrong AWS, Continuous Pre-training thường được thực hiện qua SageMaker hoặc Bedrock Custom Models, đặc biệt hữu ích cho các research institute xử lý dữ liệu động.\n\nCác lựa chọn khác không đáp ứng:\n• **Fine-tuning** — Thường là quá trình một lần hoặc không thường xuyên để tối ưu cho task cụ thể (downstream task), tốn kém hơn và không hỗ trợ cập nhật liên tục dữ liệu mới một cách tự nhiên.\n• **Static training** — Huấn luyện một lần trên dataset cố định → mô hình nhanh chóng lỗi thời khi dữ liệu thay đổi.\n• **Transfer learning** — Tập trung vào việc chuyển giao kiến thức từ mô hình pre-trained sang task mới với dataset nhỏ → không nhấn mạnh việc cập nhật định kỳ.\n\nDo đó, **Continuous pre-training** là chiến lược **tốt nhất** để duy trì relevance và accuracy của foundation model trong môi trường dữ liệu thời gian thực.\n\nNguồn tham khảo: AWS Bedrock & SageMaker documentation – Continuous/continued pre-training được khuyến nghị cho việc cập nhật foundation models với dữ liệu mới mà không cần fine-tuning task-specific."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "A data science team is training machine learning models using Amazon SageMaker Notebook instances. The datasets reside in Amazon S3. The team must ensure that the data traffic entirely remains within the AWS network due to security and compliance requirements.\nWhich solution provides the best and most cost-effective architecture for this requirement?",
                "options": [
                    "Establish VPC peering between SageMaker Notebook instances’ VPC and an S3-hosting VPC to facilitate data access.",
                    "Launch SageMaker Notebook instances in a VPC that includes a Gateway Endpoint for S3.",
                    "Use AWS PrivateLink to connect SageMaker Notebook instances to S3 securely.",
                    "Archive the datasets into S3 Glacier Deep Archive to streamline SageMaker Notebook instance retrieval."
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là đảm bảo **toàn bộ lưu lượng dữ liệu** giữa SageMaker Notebook instances và Amazon S3 **hoàn toàn nằm trong mạng nội bộ AWS** (không đi qua Internet công cộng), đồng thời phải là giải pháp **tốt nhất và tiết kiệm chi phí nhất** cho việc huấn luyện mô hình ML.\n\n**Launch SageMaker Notebook instances in a VPC that includes a Gateway Endpoint for S3** là giải pháp phù hợp nhất:\n\n• **S3 Gateway Endpoint** (hay còn gọi là VPC Endpoint for S3) là loại endpoint **miễn phí** (no additional cost), cho phép SageMaker Notebook instances trong VPC truy cập S3 **hoàn toàn private** qua mạng backbone của AWS.\n  - Không cần Internet Gateway, NAT Gateway, hay NAT instance.\n  - Traffic không rời khỏi mạng AWS → đáp ứng yêu cầu security & compliance nghiêm ngặt (ví dụ: dữ liệu tài chính, y tế, hoặc dữ liệu nhạy cảm).\n  - Hiệu suất cao, độ trễ thấp, và chi phí chỉ tính theo dung lượng dữ liệu truyền (data transfer) thông thường, không có phí endpoint.\n\nĐây là **best practice** và **cost-effective** được AWS khuyến nghị khi sử dụng SageMaker Notebook trong VPC với dữ liệu S3.\n\nCác lựa chọn khác không tối ưu:\n• **Establish VPC peering between SageMaker Notebook instances’ VPC and an S3-hosting VPC** — Sai hoàn toàn: S3 là dịch vụ global/regional, **không nằm trong VPC nào cả**. VPC peering không áp dụng cho S3.\n• **Use AWS PrivateLink to connect SageMaker Notebook instances to S3 securely** — PrivateLink (Interface Endpoint) cho S3 **tồn tại** nhưng **tốn phí** (có charge theo giờ + data processed), phức tạp hơn và **không cần thiết** khi đã có Gateway Endpoint miễn phí.\n• **Archive the datasets into S3 Glacier Deep Archive** — Glacier Deep Archive chỉ dành cho lưu trữ lạnh dài hạn, truy xuất chậm (giờ đến ngày), chi phí thấp nhưng **không phù hợp** cho dữ liệu huấn luyện cần truy cập nhanh và thường xuyên.\n\nDo đó, **Launch SageMaker Notebook instances in a VPC that includes a Gateway Endpoint for S3** là kiến trúc **tốt nhất, an toàn nhất và tiết kiệm chi phí nhất**.\n\nNguồn tham khảo: AWS documentation – S3 Gateway Endpoints là giải pháp khuyến nghị cho private access đến S3 từ VPC (bao gồm SageMaker Notebook), miễn phí và đảm bảo traffic không rời khỏi AWS network."
            }, {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A technology enterprise plans on leveraging a machine learning (ML) model to detect inappropriate speech in social media comments, filter it out, and ban offending users to maintain a safe environment for its community. The company prefers to train the model without labeled data.\nWhat approach should the company employ to detect inappropriate speech and flag harmful language?",
                "options": [
                    "Use Amazon Comprehend toxicity detection.",
                    "Use Amazon Augmented AI (A2I) content moderation.",
                    "Use Amazon Rekognition content moderation.",
                    "Use Amazon Transcribe toxicity detection."
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là phát hiện **ngôn ngữ không phù hợp (inappropriate speech)** và **ngôn ngữ có hại (harmful language)** trong **bình luận mạng xã hội** (text-based social media comments), đồng thời công ty muốn **huấn luyện mô hình mà không cần dữ liệu có nhãn** (without labeled data).\n\n**Use Amazon Comprehend toxicity detection** là giải pháp phù hợp nhất:\n\n• **Amazon Comprehend** là dịch vụ NLP (Natural Language Processing) managed của AWS, cung cấp tính năng **Toxicity Detection** (phát hiện độc hại) **pre-trained** (không cần huấn luyện thêm dữ liệu có nhãn).\n  - Tự động phân tích văn bản để phát hiện các loại nội dung độc hại như: hate speech (phát ngôn thù địch), threats (đe dọa), insults (xúc phạm), discriminatory (phân biệt đối xử), hoặc malicious intent (ý đồ xấu).\n  - Trả về điểm số toxicity (confidence score) cho từng loại, cho phép công ty dễ dàng lọc, chặn bình luận hoặc ban người dùng dựa trên ngưỡng (threshold).\n  - Hoạt động theo thời gian thực (real-time) hoặc batch, rất phù hợp cho social media moderation.\n\nVì đây là mô hình pre-trained, công ty **không cần dữ liệu có nhãn** để huấn luyện từ đầu – chỉ cần tích hợp API và cấu hình ngưỡng phù hợp.\n\nCác lựa chọn khác không phù hợp:\n• **Use Amazon Augmented AI (A2I) content moderation** — A2I dùng để đưa con người vào vòng lặp kiểm duyệt (human review) cho các trường hợp khó, không phải giải pháp tự động phát hiện độc hại.\n• **Use Amazon Rekognition content moderation** — Rekognition chuyên phân tích **hình ảnh và video** (nudity, violence, text in images), không xử lý bình luận văn bản.\n• **Use Amazon Transcribe toxicity detection** — Transcribe Toxicity Detection chỉ áp dụng cho **âm thanh** (audio), phát hiện ngôn ngữ độc hại trong cuộc gọi thoại, không phù hợp với bình luận văn bản.\n\nDo đó, **Amazon Comprehend toxicity detection** là cách tiếp cận **tự động, pre-trained, không cần labeled data** và phù hợp nhất để phát hiện và lọc ngôn ngữ có hại trong bình luận mạng xã hội.\n\nNguồn tham khảo: AWS Comprehend documentation – Toxicity Detection là tính năng built-in, pre-trained, không cần huấn luyện dữ liệu có nhãn, lý tưởng cho content moderation trong social media."
            }, {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A content streaming service wants to evaluate user behavior and demographic data to deliver personalized recommendations. The service plans to deploy a custom machine learning model in its live environment and track its performance over time to detect any changes in model accuracy.\nTo meet these demands, which AWS feature is the most suitable to use?",
                "options": [
                    "Amazon SageMaker Model Monitor",
                    "Amazon SageMaker Clarify",
                    "Amazon SageMaker Endpoint",
                    "Amazon SageMaker Autopilot"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính của dịch vụ streaming là **triển khai mô hình ML tùy chỉnh** trong môi trường live (production) và **theo dõi hiệu suất theo thời gian** để phát hiện **thay đổi độ chính xác** (model accuracy changes), bao gồm việc đánh giá hành vi người dùng và dữ liệu nhân khẩu học cho gợi ý cá nhân hóa.\n\n**Amazon SageMaker Model Monitor** là tính năng phù hợp nhất:\n\n• **Amazon SageMaker Model Monitor** — Được thiết kế chuyên biệt để **giám sát liên tục** (continuous monitoring) mô hình ML trong production.\n  - Phát hiện **data drift** (thay đổi phân phối dữ liệu đầu vào, ví dụ: hành vi người dùng thay đổi theo mùa, xu hướng mới) và **model drift** (mô hình dự đoán kém dần theo thời gian).\n  - Theo dõi các metric chất lượng như accuracy, precision, recall, F1-score, hoặc custom metrics.\n  - Hỗ trợ cả **real-time monitoring** (qua endpoint) và **batch monitoring** (qua scheduled jobs).\n  - Tự động gửi **cảnh báo** (alerts) qua CloudWatch khi phát hiện vấn đề, giúp đội ngũ chủ động retrain hoặc điều chỉnh mô hình.\n\nĐây là giải pháp lý tưởng cho các hệ thống recommendation như Netflix/Spotify/Amazon Prime, nơi dữ liệu người dùng thay đổi liên tục và cần duy trì độ chính xác cao theo thời gian.\n\nCác lựa chọn khác không đáp ứng:\n• **Amazon SageMaker Clarify** — Tập trung vào **fairness, bias detection** và **explainability** (SHAP, PDPs), không theo dõi drift hoặc accuracy theo thời gian.\n• **Amazon SageMaker Endpoint** — Chỉ dùng để **triển khai** và phục vụ inference thời gian thực, không có chức năng monitoring hoặc tracking performance.\n• **Amazon SageMaker Autopilot** — Công cụ **tự động hóa** xây dựng mô hình (AutoML), không liên quan đến monitoring sau khi deploy.\n\nDo đó, **Amazon SageMaker Model Monitor** là tính năng **phù hợp nhất** để theo dõi hiệu suất mô hình recommendation theo thời gian và phát hiện thay đổi độ chính xác.\n\nNguồn tham khảo: AWS SageMaker documentation – Model Monitor là tính năng cốt lõi cho production monitoring, data/model drift detection trong các workload recommendation systems."
            }, {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "A biotech startup has an ML application on AWS that analyzes real-time patient data to forecast market trends in drug demand. Since the application handles Protected Health Information (PHI), the company must assess compliance requirements under HIPAA and FDA regulations while ensuring secure development.\nWhich AWS services can help the startup continuously monitor compliance while maintaining security best practices? (Select TWO.)",
                "options": [
                    "AWS Config",
                    "AWS Audit Manager",
                    "Amazon Comprehend Medical",
                    "Amazon Macie",
                    "AWS Trusted Advisor"
                ],
                "correct": [0, 1],
                "explanation": "Yêu cầu chính là tìm hai dịch vụ AWS hỗ trợ **giám sát liên tục tuân thủ (continuous compliance monitoring)** cho ứng dụng ML xử lý PHI (Protected Health Information), đảm bảo đáp ứng HIPAA (bảo vệ dữ liệu y tế) và FDA regulations, đồng thời duy trì các best practices bảo mật trong quá trình phát triển.\n\nHai dịch vụ phù hợp nhất là:\n\n• **AWS Config** — Dịch vụ quản lý cấu hình liên tục, ghi lại toàn bộ thay đổi cấu hình của tài nguyên AWS (bao gồm S3 buckets chứa PHI, SageMaker endpoints, IAM roles, encryption settings).\n  - Đánh giá cấu hình theo các **AWS Config rules** được thiết kế sẵn cho HIPAA (ví dụ: kiểm tra bucket S3 có bật encryption, public access bị chặn, logging bật).\n  - Phát hiện configuration drift (thay đổi không mong muốn) và gửi cảnh báo thời gian thực.\n  - Hỗ trợ remediation tự động qua Lambda → đảm bảo tuân thủ liên tục và giảm rủi ro vi phạm bảo mật.\n\n• **AWS Audit Manager** — Dịch vụ chuyên biệt để **tự động hóa thu thập evidence** và chuẩn bị báo cáo tuân thủ.\n  - Hỗ trợ các framework pre-built cho HIPAA, PCI DSS, ISO 27001, SOC 2, v.v.\n  - Liên tục thu thập evidence từ AWS Config, CloudTrail, Security Hub, và các dịch vụ khác.\n  - Tạo báo cáo audit-ready, giúp chuẩn bị cho kiểm toán HIPAA/FDA mà không cần thu thập thủ công.\n  - Giảm thiểu nỗ lực kiểm toán, đảm bảo minh bạch và traceability cho PHI.\n\nKết hợp cả hai: AWS Config giám sát thời gian thực và phát hiện vi phạm, AWS Audit Manager tổng hợp evidence để chứng minh tuân thủ.\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Comprehend Medical** — Dùng để trích xuất thông tin y tế từ văn bản (NLP), không giám sát tuân thủ.\n• **Amazon Macie** — Phát hiện và phân loại PHI trong S3, nhưng không đánh giá tuân thủ cấu hình hay tạo evidence audit.\n• **AWS Trusted Advisor** — Đưa ra khuyến nghị best practices chung (cost, security), không chuyên sâu cho HIPAA/FDA hay continuous monitoring.\n\nDo đó, **AWS Config** và **AWS Audit Manager** là hai dịch vụ tốt nhất để giám sát liên tục tuân thủ và bảo mật khi xử lý PHI trong ứng dụng ML.\n\nNguồn tham khảo: AWS HIPAA Compliance & Audit Manager documentation – Cả hai dịch vụ đều được thiết kế để hỗ trợ continuous compliance monitoring cho workloads y tế và regulated industries."
            }, {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A support team at a global e-commerce business aims to deploy a chatbot powered by a Large Language Model (LLM) to deliver real-time, relevant replies to client questions.\nThe chatbot will leverage internal policy documents, indexed by Amazon Kendra, as the knowledge base to ensure that responses are accurate and aligned with guidelines.\nWhich approach will achieve these objectives in the most cost-efficient way?",
                "options": [
                    "Use Amazon Lex to build conversational interfaces and integrate the chatbot with the policy data.",
                    "Enable Amazon Kendra's query suggestion feature to help refine the chatbot's search results.",
                    "Retrain the LLM using the policy documents to adjust its understanding.",
                    "Employ Retrieval-Augmented Generation (RAG) to retrieve relevant information dynamically for in-context responses."
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là xây dựng chatbot sử dụng LLM để trả lời **thời gian thực**, **chính xác** và **phù hợp** với nội dung tài liệu chính sách nội bộ (được index bởi Amazon Kendra), đồng thời phải là cách **tiết kiệm chi phí nhất** (most cost-efficient).\n\n**Employ Retrieval-Augmented Generation (RAG)** là cách tiếp cận phù hợp và hiệu quả nhất:\n\n• **Retrieval-Augmented Generation (RAG)** — Kỹ thuật kết hợp:\n  - **Retrieval**: Tìm kiếm thông tin liên quan từ knowledge base (ở đây là Amazon Kendra) dựa trên câu hỏi người dùng.\n  - **Augmentation**: Chèn thông tin tìm được vào prompt của LLM (in-context).\n  - **Generation**: LLM sinh câu trả lời dựa trên thông tin chính xác từ tài liệu, thay vì chỉ dựa vào kiến thức nội tại.\n\nƯu điểm nổi bật:\n  - **Không cần retrain/fine-tune LLM** → tiết kiệm chi phí tính toán cực lớn (retraining LLM tốn hàng nghìn đến hàng chục nghìn USD).\n  - **Cập nhật động** — Khi chính sách thay đổi, chỉ cần cập nhật index Kendra là chatbot tự động dùng thông tin mới.\n  - **Độ chính xác cao** — Giảm hallucination (thông tin bịa đặt) vì LLM dựa trên tài liệu thực tế.\n  - **Tích hợp dễ dàng** với Amazon Kendra (dịch vụ enterprise search mạnh mẽ) và các LLM trên Bedrock (Claude, Titan, Llama, v.v.).\n\nĐây là giải pháp **cost-efficient** và **scalable** nhất cho chatbot enterprise dựa trên knowledge base nội bộ.\n\nCác lựa chọn khác không tối ưu:\n• **Use Amazon Lex** — Lex giỏi xây dựng conversational flow (intent, slot), nhưng không mạnh về dynamic retrieval từ knowledge base lớn → không đảm bảo câu trả lời chính xác từ policy.\n• **Enable Amazon Kendra’s query suggestion** — Chỉ gợi ý từ khóa tìm kiếm tốt hơn, không giải quyết việc sinh câu trả lời dựa trên nội dung tài liệu.\n• **Retrain the LLM using the policy documents** — Tốn kém (compute, thời gian), khó cập nhật khi policy thay đổi, và vẫn có nguy cơ hallucination nếu không kết hợp RAG.\n\nDo đó, **Employ Retrieval-Augmented Generation (RAG)** là cách **tốt nhất và tiết kiệm chi phí nhất** để đạt mục tiêu.\n\nNguồn tham khảo: AWS Bedrock & Kendra documentation – RAG là kiến trúc khuyến nghị cho enterprise chatbot sử dụng knowledge base nội bộ, đặc biệt khi cần accuracy cao mà không tốn kém retraining."
            },
            {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A customer support team at a tech company developed a large language model (LLM) to assist with frequently asked questions and troubleshooting. After fine-tuning the model with recent data, the team uses Amazon Comprehend for various natural language understanding tasks.\nTo verify whether the fine-tuning has improved the model’s accuracy, the team must evaluate its performance using benchmark datasets.\nWhich evaluation metric would be most appropriate to measure the model’s effectiveness?",
                "options": [
                    "F1 Score",
                    "Area Under the ROC Curve",
                    "Precision",
                    "Mean Squared Error"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là đánh giá hiệu quả của mô hình ngôn ngữ lớn (LLM) sau khi fine-tuning cho các nhiệm vụ hỗ trợ khách hàng (FAQ và troubleshooting), thường là **phân loại (classification)** hoặc **trả lời câu hỏi** (question answering), sử dụng benchmark datasets.\n\n**F1 Score** là metric phù hợp nhất:\n\n• **F1 Score** — Là trung bình điều hòa (harmonic mean) giữa **Precision** (độ chính xác của các dự đoán positive) và **Recall** (khả năng tìm thấy tất cả các positive thực sự).\n  - Công thức: F1 = 2 × (Precision × Recall) / (Precision + Recall)\n  - Đặc biệt hiệu quả khi dataset **mất cân bằng** (imbalanced) – tình huống rất phổ biến trong hỗ trợ khách hàng (ví dụ: số câu hỏi \"bình thường\" nhiều hơn \"khẩn cấp\" hoặc \"cần can thiệp\").\n  - Cung cấp đánh giá cân bằng giữa việc tránh trả lời sai (false positive – precision) và không bỏ sót câu hỏi quan trọng (false negative – recall).\n\nTrong các benchmark như GLUE, SuperGLUE, hoặc các task customer support (intent classification, sentiment, entity recognition), F1 Score là metric tiêu chuẩn để so sánh hiệu suất trước/sau fine-tuning.\n\nCác lựa chọn khác không phù hợp:\n• **Area Under the ROC Curve (AUC-ROC)** — Tốt cho binary classification, nhưng không cân bằng precision-recall tốt như F1 khi dataset mất cân bằng.\n• **Precision** — Chỉ tập trung vào tỷ lệ positive đúng trong các dự đoán positive, bỏ qua recall → không đầy đủ cho đánh giá tổng thể.\n• **Mean Squared Error (MSE)** — Dùng cho bài toán hồi quy (dự đoán giá trị số liên tục), hoàn toàn không phù hợp với các task NLP/classification của LLM.\n\nDo đó, **F1 Score** là metric **phù hợp nhất** để đo lường và so sánh hiệu quả của LLM sau fine-tuning trong các ứng dụng hỗ trợ khách hàng.\n\nNguồn tham khảo: AWS Comprehend & SageMaker documentation – F1 Score là metric tiêu chuẩn cho classification tasks, đặc biệt khi đánh giá fine-tuned models trên benchmark datasets."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "A business has designed an AI-powered assistant that provides visual responses to user queries. The company seeks to implement a solution to prevent the chatbot from returning harmful or inappropriate images.\nWhich approach will achieve this goal?",
                "options": [
                    "Use content moderation APIs for image filtering.",
                    "Implement automatic language detection to avoid offensive queries.",
                    "Conduct model validation to ensure it meets performance standards and produces reliable outputs.",
                    "Fine-tune the chatbot's response generation algorithm."
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là tìm cách **ngăn chặn** chatbot trả về **hình ảnh có hại hoặc không phù hợp** (harmful or inappropriate images) trong các phản hồi hình ảnh (visual responses).\n\n**Use content moderation APIs for image filtering** là cách tiếp cận phù hợp và hiệu quả nhất:\n\n• **Content moderation APIs** (cụ thể là **Amazon Rekognition Content Moderation**) được thiết kế chuyên biệt để:\n  - Phân tích hình ảnh và phát hiện nội dung không phù hợp như khỏa thân (nudity), bạo lực (violence), biểu tượng gây tranh cãi (offensive symbols), nội dung khiêu dâm, hoặc hình ảnh nhạy cảm khác.\n  - Phân loại mức độ nghiêm trọng (confidence score) và cho phép chặn/ẩn hình ảnh không đạt tiêu chuẩn.\n\nTrong workflow của chatbot:\n  - Sau khi mô hình generative AI (ví dụ: Amazon Titan Image Generator trên Bedrock) sinh ra hình ảnh.\n  - Gọi API Rekognition để kiểm tra nội dung.\n  - Nếu phát hiện nội dung không phù hợp → không trả về cho người dùng, thay bằng thông báo an toàn hoặc hình ảnh thay thế.\n\nĐây là giải pháp **trực tiếp, đáng tin cậy** và được AWS khuyến nghị cho các ứng dụng generative AI cần đảm bảo an toàn nội dung hình ảnh, đặc biệt trong môi trường doanh nghiệp.\n\nCác lựa chọn khác không giải quyết trực tiếp vấn đề:\n• **Implement automatic language detection to avoid offensive queries** — Chỉ xử lý ngôn ngữ truy vấn đầu vào, không kiểm soát được hình ảnh sinh ra.\n• **Conduct model validation to ensure it meets performance standards** — Đánh giá độ chính xác và hiệu suất mô hình, không liên quan đến lọc nội dung không phù hợp.\n• **Fine-tune the chatbot's response generation algorithm** — Tinh chỉnh thuật toán sinh phản hồi (thường là text hoặc prompt), nhưng không đảm bảo kiểm soát được chất lượng hình ảnh sinh ra, đặc biệt với mô hình diffusion/text-to-image.\n\nDo đó, **Use content moderation APIs for image filtering** là giải pháp tốt nhất để ngăn chặn chatbot trả về hình ảnh có hại hoặc không phù hợp.\n\nNguồn tham khảo: AWS Rekognition Content Moderation documentation – Chuyên dùng để lọc nội dung hình ảnh/video không phù hợp trong các ứng dụng generative AI và chatbot."
            },
            {
                domain: "Data Engineering & Ingestion",
                q: "Một công ty muốn xây dựng một Data Lake trên Amazon S3. Dữ liệu mới được tải lên hàng ngày với các định dạng và cấu trúc khác nhau. Họ cần một giải pháp để tự động phát hiện schema của dữ liệu và cập nhật vào một danh mục siêu dữ liệu tập trung để các dịch vụ khác như Amazon Athena có thể truy vấn. Dịch vụ AWS nào là phù hợp nhất cho yêu cầu này?",
                options: [
                    "AWS Glue Crawler",
                    "AWS Data Pipeline",
                    "Amazon Kinesis Data Firehose",
                    "AWS Database Migration Service (DMS)"
                ],
                correct: 0,
                explanation: "AWS Glue Crawler được thiết kế để quét qua dữ liệu trong các kho dữ liệu (như S3) để tự động suy ra schema và tạo hoặc cập nhật các bảng trong AWS Glue Data Catalog. Điều này cho phép các dịch vụ truy vấn như Athena và Redshift Spectrum sử dụng siêu dữ liệu này để truy vấn dữ liệu tại chỗ."
            },
            {
                domain: "Data Preparation",
                q: "Một nhà phân tích dữ liệu (Data Analyst) không có kinh nghiệm lập trình cần làm sạch và chuẩn hóa một tập dữ liệu lớn trong S3 để chuẩn bị cho việc tạo báo cáo trên Amazon QuickSight. Công cụ nào của AWS cung cấp giao diện trực quan (visual interface) với hơn 250 phép biến đổi dựng sẵn cho mục đích này?",
                options: [
                    "Amazon SageMaker Data Wrangler",
                    "AWS Glue DataBrew",
                    "AWS Glue Studio (ETL jobs)",
                    "Amazon SageMaker Processing Jobs"
                ],
                correct: 1,
                explanation: "AWS Glue DataBrew là một công cụ chuẩn bị dữ liệu trực quan được thiết kế cho các nhà phân tích dữ liệu và người dùng nghiệp vụ. Nó cho phép làm sạch và chuẩn hóa dữ liệu mà không cần viết mã, rất phù hợp cho việc chuẩn bị dữ liệu cho mục đích phân tích và báo cáo (Analytics & Reporting)."
            },
            {
                domain: "Feature Engineering & MLOps",
                q: "Trong một tổ chức lớn, nhiều nhóm Khoa học dữ liệu (Data Science) đang xây dựng các mô hình Machine Learning khác nhau. Họ nhận thấy rằng họ đang liên tục tính toán lại cùng một các đặc trưng (features) từ dữ liệu thô. Để tăng hiệu quả, giảm chi phí và đảm bảo tính nhất quán, họ muốn một kho lưu trữ tập trung để lưu trữ, quản lý, chia sẻ và tái sử dụng các features này. Dịch vụ nào của SageMaker được thiết kế đặc biệt cho mục đích này?",
                options: [
                    "Amazon SageMaker Studio",
                    "Amazon S3",
                    "Amazon SageMaker Feature Store",
                    "Amazon SageMaker Model Registry"
                ],
                correct: 2,
                explanation: "Amazon SageMaker Feature Store là một kho lưu trữ được quản lý hoàn toàn, giúp các nhà khoa học dữ liệu lưu trữ, chia sẻ, khám phá và tái sử dụng các feature cho các mô hình ML. Nó giải quyết vấn đề trùng lặp công việc và đảm bảo tính nhất quán của feature trên toàn tổ chức."
            },
            {
                domain: "Data Analytics Pipeline",
                q: "Một công ty muốn phân tích dữ liệu log được lưu trữ trong Amazon S3 bằng cách sử dụng các truy vấn SQL tiêu chuẩn, mà không cần phải tải dữ liệu vào một cơ sở dữ liệu quan hệ truyền thống. Dịch vụ nào cho phép họ truy vấn trực tiếp dữ liệu 'tại chỗ' (in-place) trên S3?",
                options: [
                    "Amazon Redshift",
                    "Amazon RDS",
                    "Amazon DynamoDB",
                    "Amazon Athena"
                ],
                correct: 3,
                explanation: "Amazon Athena là một dịch vụ truy vấn tương tác, serverless, cho phép dễ dàng phân tích dữ liệu trực tiếp trong Amazon S3 bằng SQL tiêu chuẩn. Bạn chỉ cần trỏ Athena vào dữ liệu của mình trên S3 và bắt đầu truy vấn, không cần các quy trình ETL phức tạp để tải dữ liệu."
            },
            {
                domain: "Data Preparation",
                q: "Một nhà khoa học dữ liệu (Data Scientist) đang chuẩn bị dữ liệu phức tạp cho việc huấn luyện mô hình ML. Họ cần một công cụ tích hợp trong môi trường phát triển (IDE) của mình để trực quan hóa, phân tích, và biến đổi dữ liệu, sau đó xuất các bước này thành code có thể tái sử dụng trong SageMaker Pipelines. Công cụ nào là lựa chọn tốt nhất?",
                options: [
                    "AWS Glue DataBrew",
                    "Jupyter Notebook trên SageMaker Studio",
                    "Amazon SageMaker Data Wrangler",
                    "SQL Workbench với Amazon Redshift"
                ],
                correct: 2,
                explanation: "Amazon SageMaker Data Wrangler được thiết kế cho các nhà khoa học dữ liệu để chuẩn bị dữ liệu cho ML. Nó tích hợp chặt chẽ với SageMaker Studio, cung cấp các công cụ trực quan và các phép biến đổi, đồng thời có thể tự động tạo code cho các bước tiền xử lý, giúp dễ dàng tích hợp vào các pipeline MLOps."
            },
            {
                "domain": "Generative AI & Personalization",
                "q": "A retail company wants to improve its customer engagement by providing personalized recommendations to online shoppers. They decide to leverage generative AI to achieve this goal.\nWhich characteristics of a Generative AI system are relevant for creating personalized product recommendations? (Select THREE.)",
                "options": [
                    "Personalization",
                    "Data efficiency",
                    "Simplicity",
                    "Adaptability",
                    "Scalability",
                    "Responsiveness"
                ],
                "correct": [0, 1, 4],
                "explanation": "Ba đặc tính quan trọng nhất của Generative AI trong việc tạo ra các gợi ý sản phẩm cá nhân hóa là:\n\n• **Personalization** — Khả năng tùy chỉnh nội dung/gợi ý dựa trên sở thích, hành vi và đặc điểm riêng của từng người dùng, giúp nâng cao trải nghiệm và mức độ tương tác.\n• **Adaptability** — Khả năng thích nghi và học hỏi từ dữ liệu mới, hành vi người dùng thay đổi theo thời gian để duy trì độ chính xác và phù hợp của các khuyến nghị.\n• **Scalability** — Khả năng xử lý hiệu quả khối lượng lớn người dùng và dữ liệu, rất cần thiết cho các hệ thống thương mại điện tử quy mô lớn với hàng triệu khách hàng.\n\nCác đặc tính còn lại:\n• Data efficiency: Hữu ích nhưng không phải là yếu tố cốt lõi nhất cho bài toán cá nhân hóa ở quy mô lớn.\n• Simplicity: Không phải ưu tiên hàng đầu khi xây dựng hệ thống gợi ý phức tạp.\n• Responsiveness: Quan trọng cho trải nghiệm người dùng nhưng thường được giải quyết ở tầng ứng dụng hơn là đặc tính cốt lõi của mô hình Generative AI."
            },
            {
                "domain": "Responsible AI",
                "q": "An organization plans to implement an artificial intelligence (AI) system to assess and recommend individuals for eligibility in various public health initiatives and social welfare programs. The system analyzes data from multiple sources, including census data, employment records, and financial information. The organization needs to streamline the application process and ensure that eligible individuals receive the support they need.\nConcerns about data quality and model trustworthiness have been raised. To address these, which TWO core dimensions of responsible AI should the organization focus on? (Select TWO)",
                "options": [
                    "Safety",
                    "Veracity and Robustness",
                    "Explainability",
                    "Privacy and Security",
                    "Controllability"
                ],
                "correct": [1, 2],
                "explanation": "Theo khung Responsible AI của AWS, các chiều cốt lõi bao gồm Fairness, Explainability, Privacy and Security, Safety, Controllability, Veracity and Robustness, Governance, Transparency.\n\nTrong tình huống này, các mối quan ngại chính tập trung vào **chất lượng dữ liệu** (data quality) và **độ tin cậy của mô hình** (model trustworthiness).\n\nHai chiều phù hợp nhất là:\n\n• **Veracity and Robustness** — Đảm bảo hệ thống AI tạo ra kết quả chính xác, đáng tin cậy (veracity), đồng thời bền vững trước các đầu vào bất ngờ, đối kháng hoặc dữ liệu chất lượng kém (robustness). Điều này trực tiếp giải quyết vấn đề chất lượng dữ liệu và tính toàn vẹn của mô hình.\n• **Explainability** — Cung cấp khả năng giải thích rõ ràng cách mô hình đưa ra quyết định, giúp xây dựng lòng tin, tăng tính minh bạch và cho phép giám sát con người – rất quan trọng trong các ứng dụng high-stakes như đánh giá hỗ trợ xã hội và y tế công cộng.\n\nCác lựa chọn khác:\n• **Safety**: Tập trung vào việc ngăn chặn hại và hậu quả không mong muốn, không trực tiếp liên quan đến chất lượng dữ liệu.\n• **Privacy and Security**: Liên quan đến bảo vệ dữ liệu khỏi truy cập trái phép, không phải là vấn đề chất lượng hoặc độ tin cậy của dữ liệu.\n• **Controllability**: Liên quan đến việc duy trì sự kiểm soát và giám sát của con người, quan trọng nhưng không phải trọng tâm chính của mối quan ngại về data quality và model trustworthiness.\n\nNguồn tham khảo chính: AWS Responsible AI framework (bao gồm Veracity and Robustness được định nghĩa là 'Achieving correct system outputs, even with unexpected or adversarial inputs')."
            },
            {
                "domain": "Responsible AI",
                "q": "A company is deploying an AI-powered customer support chatbot to handle inquiries and provide responses to users. The application ensures that customer support responses are unbiased and fair, avoiding any form of discrimination or prejudice.\nWhich core dimension of responsible AI is the company primarily addressing with this requirement? (Select ONE)",
                "options": [
                    "Fairness",
                    "Explainability",
                    "Privacy and Security",
                    "Safety",
                    "Controllability",
                    "Veracity and Robustness",
                    "Governance",
                    "Transparency"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là đảm bảo các phản hồi của chatbot **không thiên vị (unbiased)** và **công bằng (fair)**, tránh mọi hình thức phân biệt đối xử hoặc định kiến (discrimination or prejudice).\n\nTheo khung Responsible AI của AWS, **Fairness** là chiều cốt lõi trực tiếp giải quyết vấn đề này:\n\n• **Fairness** — Đảm bảo rằng mô hình AI không tạo ra kết quả thiên vị, phân biệt đối xử hoặc bất lợi đối với bất kỳ cá nhân hay nhóm nào dựa trên các đặc điểm được bảo vệ (giới tính, chủng tộc, tuổi tác, tôn giáo, v.v.). Điều này bao gồm việc giảm thiểu bias trong dữ liệu huấn luyện, mô hình và output.\n\nCác chiều khác không phải là trọng tâm chính ở đây:\n• **Explainability**: Tập trung vào việc giải thích cách mô hình đưa ra quyết định, không trực tiếp liên quan đến việc đảm bảo công bằng.\n• **Privacy and Security**: Bảo vệ dữ liệu cá nhân, không liên quan đến bias.\n• **Safety**: Ngăn chặn nội dung gây hại (harmful content), không phải là vấn đề thiên vị.\n• **Controllability**: Duy trì sự kiểm soát của con người.\n• **Veracity and Robustness**: Đảm bảo độ chính xác và bền vững của output.\n• **Governance**: Xây dựng chính sách và quy trình quản trị.\n• **Transparency**: Minh bạch về khả năng và hạn chế của hệ thống.\n\nDo đó, **Fairness** là chiều phù hợp nhất để đảm bảo các phản hồi hỗ trợ khách hàng công bằng và không phân biệt đối xử.\n\nNguồn tham khảo: AWS Responsible AI framework – Fairness được định nghĩa là 'Ensuring AI models do not discriminate against individuals or groups'."
            },
            {
                "domain": "Responsible AI",
                "q": "The company openly shares information about the AI system’s overall functioning, data sources, and development process used for generating new product design recommendations.\nWhich core dimension of responsible AI is the company primarily addressing with this practice? (Select ONE)",
                "options": [
                    "Fairness",
                    "Explainability",
                    "Privacy and Security",
                    "Safety",
                    "Controllability",
                    "Veracity and Robustness",
                    "Governance",
                    "Transparency"
                ],
                "correct": 7,
                "explanation": "Yêu cầu chính trong tình huống này là công ty **công khai chia sẻ thông tin** về cách hệ thống AI hoạt động tổng thể (overall functioning), nguồn dữ liệu được sử dụng (data sources), và quy trình phát triển (development process).\n\nTheo khung Responsible AI của AWS, **Transparency** là chiều cốt lõi trực tiếp giải quyết vấn đề này:\n\n• **Transparency** — Thúc đẩy việc công khai, minh bạch về khả năng, hạn chế, nguồn dữ liệu, quy trình huấn luyện và cách thức hoạt động của hệ thống AI. Điều này giúp các bên liên quan (người dùng, khách hàng, nhà quản lý) hiểu rõ hơn về hệ thống, xây dựng lòng tin và hỗ trợ trách nhiệm giải trình.\n\nCác chiều khác không phải là trọng tâm chính ở đây:\n• **Fairness**: Đảm bảo không thiên vị và không phân biệt đối xử.\n• **Explainability**: Tập trung vào việc giải thích chi tiết cách mô hình đưa ra từng quyết định cụ thể (ví dụ: tại sao đưa ra gợi ý thiết kế này), chứ không phải chia sẻ thông tin tổng quát về hệ thống.\n• **Privacy and Security**: Bảo vệ dữ liệu cá nhân.\n• **Safety**: Ngăn chặn nội dung gây hại.\n• **Controllability**: Duy trì sự kiểm soát của con người.\n• **Veracity and Robustness**: Đảm bảo độ chính xác và bền vững của output.\n• **Governance**: Xây dựng chính sách và quy trình quản trị nội bộ.\n\nDo đó, **Transparency** là chiều phù hợp nhất khi công ty chủ động công khai thông tin tổng quan về hệ thống AI.\n\nNguồn tham khảo: AWS Responsible AI framework – Transparency được định nghĩa là 'Promoting openness about the capabilities, limitations, and potential biases of AI systems'."
            },
            {
                "domain": "Responsible AI",
                "q": "The application is designed to prevent unauthorized access to sensitive information while generating personalized customer recommendations.\nWhich core dimension of responsible AI is the application primarily addressing with this design? (Select ONE)",
                "options": [
                    "Explainability",
                    "Safety",
                    "Privacy and Security",
                    "Controllability"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính trong tình huống này là ứng dụng được thiết kế để **ngăn chặn truy cập trái phép** vào **thông tin nhạy cảm** (sensitive information) trong quá trình tạo ra các gợi ý cá nhân hóa cho khách hàng.\n\nTheo khung Responsible AI của AWS, **Privacy and Security** là chiều cốt lõi trực tiếp giải quyết vấn đề này:\n\n• **Privacy and Security** — Đảm bảo dữ liệu cá nhân và thông tin nhạy cảm được thu thập, sử dụng và bảo vệ một cách phù hợp, an toàn. Điều này bao gồm ngăn chặn truy cập trái phép, bảo vệ khỏi rò rỉ dữ liệu, mã hóa thông tin, xóa thông tin nhận dạng cá nhân (PII redaction), và tuân thủ các quy định bảo mật như GDPR hoặc CCPA.\n\nCác chiều khác không phải là trọng tâm chính ở đây:\n• **Explainability**: Tập trung vào việc giải thích cách mô hình đưa ra quyết định, không liên quan đến việc bảo vệ dữ liệu khỏi truy cập trái phép.\n• **Safety**: Ngăn chặn việc tạo ra nội dung gây hại hoặc lạm dụng hệ thống, không trực tiếp liên quan đến bảo mật dữ liệu.\n• **Controllability**: Đảm bảo con người có thể kiểm soát và giám sát hành vi của AI, không phải là vấn đề ngăn chặn truy cập trái phép vào thông tin nhạy cảm.\n\nDo đó, **Privacy and Security** là chiều phù hợp nhất để đảm bảo thông tin nhạy cảm của khách hàng được bảo vệ trong quá trình tạo gợi ý cá nhân hóa.\n\nNguồn tham khảo: AWS Responsible AI framework – Privacy and Security được định nghĩa là 'Appropriately obtaining, using, and protecting data and models'."
            },
            {
                "domain": "Generative AI & Personalization",
                "q": "An e-commerce company is designing a chatbot to assist customers with product inquiries, order status updates, and troubleshooting. Which capability of AI is most relevant for ensuring that the chatbot provides real-time responses to customer queries?",
                "options": [
                    "Adaptability",
                    "Data Efficiency",
                    "Simplicity",
                    "Responsiveness"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính trong tình huống này là chatbot phải cung cấp **phản hồi theo thời gian thực** (real-time responses) cho các câu hỏi của khách hàng.\n\nTrong Generative AI, **Responsiveness** là khả năng quan trọng nhất để đáp ứng yêu cầu này:\n\n• **Responsiveness** — Đảm bảo mô hình Generative AI tạo ra nội dung nhanh chóng, gần như tức thì, dẫn đến thời gian phản hồi thấp và tương tác mượt mà. Điều này đặc biệt cần thiết cho chatbot thương mại điện tử, trợ lý ảo, nơi khách hàng mong đợi câu trả lời ngay lập tức để nâng cao trải nghiệm người dùng.\n\nCác khả năng khác không phải là trọng tâm chính:\n• **Adaptability**: Liên quan đến khả năng học hỏi và điều chỉnh phản hồi dựa trên ngữ cảnh hoặc tương tác mới theo thời gian, nhưng không trực tiếp đảm bảo tốc độ phản hồi tức thời.\n• **Data Efficiency**: Tập trung vào việc mô hình học hiệu quả từ ít dữ liệu hơn, quan trọng cho huấn luyện và tối ưu hóa, nhưng không ảnh hưởng trực tiếp đến tốc độ phản hồi trong lúc runtime.\n• **Simplicity**: Đề cập đến khả năng đơn giản hóa các nhiệm vụ phức tạp bằng cách tự động tạo nội dung, nhưng không liên quan đến việc cung cấp phản hồi theo thời gian thực.\n\nDo đó, **Responsiveness** là khả năng phù hợp nhất để đảm bảo chatbot hỗ trợ khách hàng một cách nhanh chóng và hiệu quả trong thương mại điện tử.\n\nNguồn tham khảo: Đặc tính của Generative AI trong các ứng dụng tương tác thời gian thực (real-time interactive applications) như chatbot và virtual assistants."
            },
            {
                "domain": "Generative AI & Personalization",
                "q": "A company uses a generative AI model to automate content creation for its social media posts. The model has been trained on various topics, including technology, fashion, and travel. Recently, the company decided to expand its business into the fitness industry.\nWhich capability of generative AI will be crucial for the model to adjust its output and generate relevant fitness-related content?",
                "options": [
                    "Responsiveness",
                    "Adaptability",
                    "Scalability",
                    "Creativity and exploration"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là mô hình Generative AI cần **điều chỉnh output** để tạo ra nội dung liên quan đến lĩnh vực mới (fitness) mà trước đó chưa được huấn luyện trực tiếp.\n\n**Adaptability** là khả năng quan trọng nhất để đáp ứng yêu cầu này:\n\n• **Adaptability** — Khả năng của mô hình thích nghi và điều chỉnh output dựa trên dữ liệu mới, ngữ cảnh mới hoặc lĩnh vực mới. Generative AI có thể học hỏi từ prompt, few-shot learning, fine-tuning hoặc tiếp tục huấn luyện để tạo nội dung phù hợp với chủ đề fitness, dù ban đầu được huấn luyện chủ yếu trên các lĩnh vực khác.\n\nCác khả năng khác không phải là trọng tâm chính:\n• **Responsiveness**: Tập trung vào việc tạo nội dung nhanh chóng theo thời gian thực, phù hợp cho chatbot tương tác, nhưng không trực tiếp giúp mô hình điều chỉnh nội dung cho lĩnh vực mới.\n• **Scalability**: Liên quan đến khả năng xử lý khối lượng lớn yêu cầu hoặc dữ liệu (ví dụ: phục vụ hàng triệu người dùng), không liên quan đến việc thích nghi với chủ đề mới.\n• **Creativity and exploration**: Đề cập đến việc tạo ra ý tưởng mới lạ, sáng tạo, nhưng không đảm bảo nội dung sẽ phù hợp và liên quan đến lĩnh vực fitness cụ thể.\n\nDo đó, **Adaptability** là khả năng cốt lõi giúp mô hình Generative AI mở rộng sang lĩnh vực fitness một cách hiệu quả và tạo nội dung social media phù hợp.\n\nNguồn tham khảo: Đặc tính cốt lõi của Generative AI trong việc thích nghi với domain mới (domain adaptation) thông qua prompt engineering, fine-tuning hoặc continual learning."
            },
            {
                "domain": "MLOps & Model Lifecycle",
                "q": "A financial company is using an AI model to identify potential loan defaults. To ensure the model works well in production, they must set up processes for capturing real-time data, comparing it with the training set, detecting performance issues, and generating alerts.\nWhich stage of the model development pipeline should the company focus on?",
                "options": [
                    "Model Monitoring",
                    "Model Training",
                    "Data Collection",
                    "Model Evaluation"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là thiết lập quy trình để **thu thập dữ liệu thời gian thực**, **so sánh với tập huấn luyện**, **phát hiện vấn đề hiệu suất** (như data drift, concept drift, bias drift), và **tạo cảnh báo** khi mô hình đang hoạt động trong môi trường production.\n\n**Model Monitoring** là giai đoạn phù hợp nhất trong pipeline MLOps:\n\n• **Model Monitoring** — Giai đoạn liên tục giám sát hiệu suất mô hình sau khi triển khai (post-deployment). Nó bao gồm việc thu thập dữ liệu inference thời gian thực, so sánh phân phối dữ liệu mới với dữ liệu huấn luyện, phát hiện drift (data drift, concept drift, feature drift), theo dõi chất lượng mô hình, bias, và gửi cảnh báo tự động khi có vấn đề. Điều này đảm bảo mô hình duy trì độ chính xác và độ tin cậy trong môi trường sản xuất.\n\nCác giai đoạn khác không phù hợp:\n• **Model Training**: Tập trung vào việc huấn luyện và tinh chỉnh mô hình bằng dữ liệu lịch sử, diễn ra trước khi triển khai, không liên quan đến giám sát liên tục sau production.\n• **Data Collection**: Chỉ tập trung vào việc thu thập dữ liệu ban đầu để huấn luyện, không bao gồm so sánh, phát hiện drift hay cảnh báo trong production.\n• **Model Evaluation**: Thực hiện trong giai đoạn phát triển để đánh giá mô hình trên tập test/validation, không phải giám sát liên tục hiệu suất thực tế sau triển khai.\n\nDo đó, **Model Monitoring** là giai đoạn cốt lõi mà công ty cần tập trung để đảm bảo mô hình dự đoán vỡ nợ vay hoạt động ổn định và đáng tin cậy trong môi trường thực tế.\n\nNguồn tham khảo: MLOps lifecycle (bao gồm Model Monitoring như một phần quan trọng của continuous monitoring trong production, thường sử dụng công cụ như Amazon SageMaker Model Monitor, Evidently AI, hoặc Fiddler)."
            },
            {
                "domain": "Amazon SageMaker Inference",
                "q": "Use for low-latency workloads with predictable traffic patterns that need consistent latency characteristics and are always available.",
                "options": [
                    "Real-time Inference",
                    "Asynchronous Inference",
                    "Batch Inference",
                    "Serverless Inference"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là hỗ trợ **các workload có độ trễ thấp (low-latency)**, **mô hình lưu lượng dự đoán được (predictable traffic patterns)**, cần **độ trễ ổn định (consistent latency)** và **luôn sẵn sàng (always available)**.\n\nTheo các tùy chọn inference của Amazon SageMaker:\n\n• **Real-time Inference** — Là lựa chọn phù hợp nhất. Nó cung cấp endpoint luôn sẵn sàng (always-on), đảm bảo độ trễ thấp và ổn định cho các ứng dụng cần phản hồi tức thì như chatbot, recommendation systems, fraud detection thời gian thực. Phù hợp với lưu lượng dự đoán được và yêu cầu availability cao.\n\nCác tùy chọn khác không phù hợp:\n• **Asynchronous Inference** — Dùng cho workload có độ trễ cao hơn, xử lý hàng đợi (queue), phù hợp với lưu lượng không đều hoặc yêu cầu xử lý lớn, không đảm bảo luôn sẵn sàng hoặc độ trễ cực thấp.\n• **Batch Inference** — Dùng cho xử lý hàng loạt (offline) trên tập dữ liệu lớn, không cung cấp endpoint luôn sẵn sàng, không phù hợp với low-latency hoặc real-time.\n• **Serverless Inference** — Tự động scale theo nhu cầu, phù hợp với lưu lượng đột biến (spiky/unpredictable), nhưng có thể có cold-start latency biến động, không đảm bảo độ trễ nhất quán như Real-time Inference, và không phải lúc nào cũng \"always available\" trong nghĩa endpoint luôn warm.\n\nDo đó, **Real-time Inference** là tùy chọn lý tưởng cho các workload low-latency, predictable traffic, cần consistent latency và always available.\n\nNguồn tham khảo: Amazon SageMaker Inference options documentation – Real-time endpoints are designed for interactive, low-latency applications with predictable traffic."
            },
            {
                "domain": "Amazon SageMaker Inference",
                "q": "Ideal for synchronous workloads with spiky traffic patterns that can tolerate latency variations.",
                "options": [
                    "Serverless Inference",
                    "Asynchronous Inference",
                    "Real-time Inference",
                    "Batch Inference"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là hỗ trợ **các workload đồng bộ (synchronous)**, có **lưu lượng đột biến (spiky traffic patterns)** và **chấp nhận được sự biến động về độ trễ (can tolerate latency variations)**.\n\nTheo các tùy chọn inference của Amazon SageMaker:\n\n• **Serverless Inference** — Là lựa chọn phù hợp nhất. Nó tự động mở rộng theo nhu cầu (auto-scaling), không cần quản lý instance, và chỉ tính phí theo thời gian thực hiện inference. Serverless Inference rất lý tưởng cho các workload có lưu lượng không đều, đột biến (spiky), và không yêu cầu độ trễ cực thấp hoặc nhất quán. Nó vẫn cung cấp endpoint đồng bộ (synchronous), nghĩa là client nhận được kết quả ngay sau khi gửi request, nhưng có thể chịu cold-start latency khi không có traffic trong thời gian dài.\n\nCác tùy chọn khác không phù hợp:\n• **Asynchronous Inference**: Dùng cho workload không đồng bộ, xử lý qua hàng đợi, phù hợp với các tác vụ có thời gian xử lý dài hoặc lưu lượng lớn, không phải là synchronous.\n• **Real-time Inference**: Phù hợp với lưu lượng dự đoán được, yêu cầu độ trễ thấp và ổn định, không tối ưu cho spiky traffic vì chi phí cao khi phải duy trì instance luôn sẵn sàng.\n• **Batch Inference**: Dùng cho xử lý hàng loạt offline trên tập dữ liệu lớn, không cung cấp endpoint đồng bộ và không phù hợp với workload thời gian thực.\n\nDo đó, **Serverless Inference** là tùy chọn lý tưởng cho các synchronous workload có lưu lượng đột biến và chấp nhận được độ trễ biến động.\n\nNguồn tham khảo: Amazon SageMaker Inference options documentation – Serverless Inference is designed for workloads with intermittent or unpredictable traffic that can tolerate some latency variation."
            },
            {
                "domain": "Amazon SageMaker Inference",
                "q": "Choose for processing large sets of data offline without requiring a persistent endpoint.",
                "options": [
                    "Batch Inference",
                    "Real-time Inference",
                    "Asynchronous Inference",
                    "Serverless Inference"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là xử lý **tập dữ liệu lớn một cách offline** (large sets of data offline) và **không yêu cầu endpoint liên tục** (without requiring a persistent endpoint).\n\nTheo các tùy chọn inference của Amazon SageMaker:\n\n• **Batch Inference** — Là lựa chọn phù hợp nhất. Nó được thiết kế dành riêng cho các tác vụ xử lý hàng loạt (batch/offline), cho phép chạy inference trên toàn bộ tập dữ liệu lớn một lần, thường sử dụng để dự đoán trên hàng triệu bản ghi (ví dụ: scoring khách hàng hàng tháng, phân tích log, tạo report). Bạn chỉ trả tiền cho thời gian job chạy (duration of the job), không cần duy trì endpoint luôn sẵn sàng, và không có persistent endpoint.\n\nCác tùy chọn khác không phù hợp:\n• **Real-time Inference**: Yêu cầu endpoint luôn sẵn sàng (persistent), phù hợp với low-latency và predictable traffic, không dành cho offline batch processing.\n• **Asynchronous Inference**: Dùng cho các request không đồng bộ với hàng đợi, vẫn cần endpoint (dù có thể scale down), phù hợp hơn với workload thời gian thực có độ trễ chấp nhận được, không tối ưu cho large-scale offline batch.\n• **Serverless Inference**: Vẫn là endpoint đồng bộ (synchronous), tự động scale cho spiky traffic, nhưng không phải là batch/offline processing và vẫn có persistent-like behavior khi có request.\n\nDo đó, **Batch Inference** là tùy chọn lý tưởng cho việc xử lý dữ liệu lớn offline mà không cần endpoint liên tục.\n\nNguồn tham khảo: Amazon SageMaker Inference options documentation – Batch Transform (Batch Inference) is specifically for offline inference on large datasets without the need for a persistent endpoint."
            },
            {
                "domain": "Amazon SageMaker Autopilot",
                "q": "Một nhóm Data Science muốn xây dựng một mô hình ML để dự đoán rủi ro tín dụng từ một file CSV lớn trên S3. Họ không muốn viết code để thử nghiệm từng thuật toán và hyperparameter, nhưng họ vẫn cần sự minh bạch bằng cách xem được mã nguồn Python đã được sử dụng để tạo ra các mô hình đó. Dịch vụ nào là phù hợp nhất?",
                "options": [
                    "Amazon SageMaker Data Wrangler",
                    "Amazon SageMaker Autopilot",
                    "Amazon SageMaker Canvas",
                    "AWS Glue DataBrew"
                ],
                "correct": 1,
                "explanation": "**Amazon SageMaker Autopilot** là lựa chọn chính xác nhất vì:\n\n• Nó là giải pháp **AutoML** tự động hóa việc chọn thuật toán, tiền xử lý và tinh chỉnh tham số.\n• Điểm nổi bật là nó tự động tạo ra các **Notebook (Candidate Generation & Data Exploration)** chứa mã nguồn Python chi tiết, cho phép người dùng kiểm tra và tùy biến lại nếu cần.\n\nCác lựa chọn khác:\n• **Data Wrangler**: Tập trung vào chuẩn bị dữ liệu trực quan, không tự động xây dựng và tối ưu mô hình.\n• **Canvas**: Là công cụ No-code cho người dùng nghiệp vụ, không cung cấp tính minh bạch qua mã nguồn Python chi tiết như Autopilot.\n• **DataBrew**: Là công cụ làm sạch dữ liệu trực quan cho Data Analyst, không phải công cụ AutoML."
            },
            {
                "domain": "AWS Security & Compliance for Generative AI",
                "q": "An AI startup uses generative AI models to create personalized content. The company develops and deploys these models using Amazon SageMaker, Amazon Bedrock, and Amazon Q Business. Following the AWS Generative AI Security Scoping Matrix to strengthen governance and compliance, the team wants to audit AWS Service API activity related to generative AI workloads due to recent concerns about unauthorized access to sensitive training data and model parameters.\nWhich of the following services can help the startup audit AWS Service API activity related to generative AI workloads?",
                "options": [
                    "AWS CloudTrail",
                    "Amazon Inspector",
                    "AWS Trusted Advisor",
                    "AWS Config"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là **kiểm tra và ghi lại (audit)** các hoạt động API của các dịch vụ AWS liên quan đến workload Generative AI (SageMaker, Bedrock, Q Business), đặc biệt để phát hiện truy cập trái phép vào dữ liệu huấn luyện nhạy cảm và tham số mô hình.\n\n**AWS CloudTrail** là dịch vụ phù hợp nhất:\n\n• **AWS CloudTrail** — Ghi lại toàn bộ hoạt động API (API calls) được thực hiện bởi người dùng, role, hoặc dịch vụ AWS trong tài khoản. Các sự kiện bao gồm mọi hành động qua AWS Management Console, AWS CLI, SDKs và các API trực tiếp. CloudTrail tự động hoạt động khi tạo tài khoản AWS và ghi log các API liên quan đến SageMaker (CreateTrainingJob, InvokeEndpoint,…), Bedrock (InvokeModel, CreateCustomModel,…), Amazon Q Business (các API liên quan đến truy cập knowledge base, chat,…). Bằng cách kích hoạt CloudTrail (và lưu log vào S3/CloudWatch Logs), startup có thể audit, theo dõi truy cập trái phép, phân tích sự kiện để phát hiện hành vi bất thường, và đáp ứng yêu cầu governance/compliance theo AWS Generative AI Security Scoping Matrix.\n\nCác dịch vụ khác không phù hợp:\n• **Amazon Inspector**: Dùng để quét lỗ hổng bảo mật trên EC2, Lambda, ECR container, không phải để audit API activity.\n• **AWS Trusted Advisor**: Cung cấp các best practice recommendations (cost optimization, security, performance), không ghi log hoặc audit API calls.\n• **AWS Config**: Theo dõi và ghi lại thay đổi cấu hình (configuration changes) của tài nguyên AWS, không tập trung vào audit chi tiết các API calls hoặc hành động truy cập dữ liệu/mô hình.\n\nDo đó, **AWS CloudTrail** là dịch vụ cốt lõi để audit AWS Service API activity liên quan đến Generative AI workloads, giúp giải quyết lo ngại về unauthorized access.\n\nNguồn tham khảo: AWS CloudTrail documentation & AWS Generative AI Security Scoping Matrix – CloudTrail là công cụ chính để logging và auditing API activity trong các workload GenAI."
            },
            {
                "domain": "Generative AI Fine-Tuning",
                "q": "A travel agency needs to fine-tune a foundation model (FM) to assist customers by providing detailed trip planning advice, handling multi-turn conversations about travel preferences, and making personalized recommendations.\nWhich method will satisfy these requirements?",
                "options": [
                    "Few-shot learning",
                    "Instruction-based fine-tuning",
                    "Zero-shot learning",
                    "Domain adaptation fine-tuning"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là fine-tune foundation model để:\n- Cung cấp lời khuyên lập kế hoạch chuyến đi chi tiết\n- Xử lý hội thoại nhiều lượt (multi-turn conversations) về sở thích du lịch\n- Đưa ra gợi ý cá nhân hóa dựa trên input của khách hàng\n\n**Instruction-based fine-tuning** (hay còn gọi là Instruction Tuning) là phương pháp phù hợp nhất:\n\n• **Instruction-based fine-tuning** — Đây là quá trình huấn luyện tiếp foundation model bằng các cặp instruction-response (hướng dẫn-đáp ứng) cụ thể, giúp mô hình học cách hiểu và tuân thủ các chỉ dẫn phức tạp. Phương pháp này giúp mô hình trở nên giỏi hơn trong việc xử lý task-oriented dialogue, duy trì ngữ cảnh qua nhiều lượt trò chuyện (multi-turn), và tạo ra output cá nhân hóa, chi tiết theo yêu cầu. Nó tận dụng kiến thức sẵn có của FM đồng thời tinh chỉnh để phù hợp với domain du lịch, đảm bảo phản hồi chính xác, liên quan và thân thiện với khách hàng.\n\nCác phương pháp khác không đáp ứng đầy đủ:\n• **Few-shot learning**: Chỉ cung cấp vài ví dụ trong prompt tại inference time, không thay đổi trọng số mô hình → không đủ để xử lý multi-turn phức tạp hoặc đảm bảo tính nhất quán cao trong domain du lịch.\n• **Zero-shot learning**: Mô hình thực hiện task mà không cần ví dụ hoặc fine-tuning → khả năng hạn chế với multi-turn conversation và personalized recommendation chi tiết.\n• **Domain adaptation fine-tuning**: Tập trung vào việc thích nghi mô hình với domain mới (ví dụ: du lịch) bằng cách tiếp tục huấn luyện trên dữ liệu domain-specific, nhưng không đặc biệt nhấn mạnh vào việc học theo instruction để xử lý multi-turn và task-oriented behavior.\n\nDo đó, **Instruction-based fine-tuning** là phương pháp lý tưởng để tùy chỉnh foundation model cho ứng dụng trợ lý du lịch tương tác, multi-turn và cá nhân hóa.\n\nNguồn tham khảo: AWS SageMaker JumpStart và Bedrock fine-tuning capabilities – Instruction tuning là kỹ thuật phổ biến để customize FM cho conversational AI và task-specific applications."
            },
            {
                "domain": "Generative AI Fine-Tuning",
                "q": "A project involves generating product descriptions for an e-commerce website using a dataset of existing product descriptions from the site.\nWhich fine-tuning approach is most appropriate for adapting a pre-trained language model to generate product descriptions similar to those in the dataset?",
                "options": [
                    "Domain adaptation fine-tuning",
                    "Unsupervised pre-training",
                    "Transfer learning",
                    "Instruction-based fine-tuning"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính trong tình huống này là thích nghi (adapt) một mô hình ngôn ngữ đã được pre-train để **tạo ra mô tả sản phẩm** (product descriptions) **giống với phong cách, ngôn ngữ và đặc trưng** trong tập dữ liệu hiện có của website thương mại điện tử (ví dụ: sử dụng từ ngữ quảng cáo, tính từ mô tả, cấu trúc câu đặc trưng).\n\n**Domain adaptation fine-tuning** là phương pháp phù hợp nhất:\n\n• **Domain adaptation fine-tuning** — Đây là kỹ thuật tiếp tục huấn luyện (fine-tune) mô hình pre-trained trên tập dữ liệu domain-specific (ở đây là các mô tả sản phẩm hiện có). Phương pháp này điều chỉnh trọng số mô hình để học được phong cách ngôn ngữ, thuật ngữ ngành, cấu trúc câu và giọng điệu đặc trưng của mô tả sản phẩm trên website, giúp output sinh ra giống hệt hoặc rất gần với dữ liệu gốc. Nó đặc biệt hiệu quả khi chỉ có dữ liệu không nhãn (unlabeled) hoặc khi cần mô hình bắt chước chính xác style của dataset.\n\nCác phương pháp khác không phù hợp bằng:\n• **Unsupervised pre-training**: Là giai đoạn huấn luyện ban đầu trên dữ liệu lớn không nhãn (như BERT, GPT), đã hoàn thành trước khi có mô hình pre-trained → không phải bước fine-tuning cho task cụ thể.\n• **Transfer learning**: Là khái niệm chung (chuyển giao kiến thức từ mô hình pre-trained sang task mới), bao gồm cả domain adaptation, nhưng không cụ thể bằng domain adaptation fine-tuning cho trường hợp cần thích nghi domain.\n• **Instruction-based fine-tuning**: Tập trung vào việc huấn luyện mô hình theo các cặp instruction-response để thực hiện task theo hướng dẫn (ví dụ: \"Viết mô tả sản phẩm cho chiếc áo này\"), phù hợp hơn khi cần mô hình hiểu và tuân thủ chỉ dẫn, chứ không phải bắt chước chính xác style của dataset mà không cần prompt chi tiết.\n\nDo đó, **Domain adaptation fine-tuning** là cách tiếp cận tối ưu để mô hình ngôn ngữ sinh ra mô tả sản phẩm giống hệt phong cách của website thương mại điện tử.\n\nNguồn tham khảo: AWS SageMaker JumpStart và Bedrock fine-tuning capabilities – Domain adaptation (hay còn gọi là continued pre-training/fine-tuning on domain data) được khuyến nghị cho việc thích nghi mô hình với văn bản chuyên biệt như product descriptions."
            },
            {
                "domain": "Artificial Intelligence Fundamentals",
                "q": "What term refers to a branch of AI that enables systems to learn and make predictions based on data without being explicitly structured?",
                "options": [
                    "Object-oriented programming",
                    "Natural Language Processing (NLP)",
                    "Machine Learning",
                    "Predictive analytics"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính trong câu hỏi là tìm khái niệm chỉ **một nhánh của AI** cho phép hệ thống **tự học** và **dự đoán** dựa trên dữ liệu mà **không cần được lập trình rõ ràng từng bước** (without being explicitly structured).\n\n**Machine Learning** là đáp án chính xác:\n\n• **Machine Learning** — Là một nhánh cốt lõi của trí tuệ nhân tạo (AI), tập trung vào việc phát triển các thuật toán và mô hình toán học/thống kê giúp máy tính **tự học** từ dữ liệu, phát hiện mẫu hình (patterns), và đưa ra dự đoán hoặc quyết định mà không cần được lập trình chi tiết từng trường hợp. Các mô hình ML có thể phân tích dữ liệu lớn, học từ kinh nghiệm lịch sử và áp dụng để dự báo trên dữ liệu mới (ví dụ: phát hiện ung thư từ ảnh X-quang, dự đoán hành vi khách hàng, phân loại văn bản, nhận diện hình ảnh).\n\nCác lựa chọn khác không phù hợp:\n• **Object-oriented programming**: Là một mô hình lập trình (paradigm) trong phát triển phần mềm, không phải nhánh của AI.\n• **Natural Language Processing (NLP)**: Là một lĩnh vực con của AI tập trung vào việc xử lý và hiểu ngôn ngữ tự nhiên, thường sử dụng Machine Learning nhưng không phải là nhánh tổng quát cho việc học và dự đoán từ dữ liệu.\n• **Predictive analytics**: Là ứng dụng thực tiễn sử dụng dữ liệu để dự đoán tương lai, thường dựa trên Machine Learning, nhưng không phải là nhánh AI mà là một phương pháp/kỹ thuật ứng dụng.\n\nDo đó, **Machine Learning** là thuật ngữ chính xác nhất mô tả nhánh AI cho phép hệ thống học và dự đoán từ dữ liệu mà không cần lập trình rõ ràng.\n\nNguồn tham khảo: Định nghĩa cơ bản của Machine Learning trong AI (theo Arthur Samuel, Andrew Ng, và các tài liệu chuẩn của AWS Machine Learning Specialty)."
            },
            {
                "domain": "Machine Learning Evaluation",
                "q": "A Machine Learning Engineer is training a multi-classification model for predicting musical genres. The Specialist wants to evaluate model performance through a visual representation of different metrics.\nWhich visualization technique should the Engineer use?",
                "options": [
                    "Correlation matrix",
                    "Box plot",
                    "Precision-Recall curve",
                    "Confusion matrix"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính trong tình huống này là sử dụng một **kỹ thuật trực quan hóa (visual representation)** để đánh giá hiệu suất của mô hình **phân loại đa lớp (multi-class classification)** dự đoán thể loại âm nhạc, tập trung vào việc hiển thị các metric liên quan đến dự đoán đúng/sai.\n\n**Confusion matrix** là kỹ thuật phù hợp nhất:\n\n• **Confusion matrix** — Là ma trận trực quan hóa hiệu suất phân loại đa lớp một cách rõ ràng và chi tiết. Mỗi hàng đại diện cho lớp thực tế (actual class), mỗi cột đại diện cho lớp dự đoán (predicted class). Các ô trên đường chéo chính cho biết số lượng dự đoán đúng (true positives cho từng lớp), trong khi các ô ngoài đường chéo cho thấy lỗi phân loại (misclassifications). Với bài toán multi-class như dự đoán thể loại nhạc (rock, pop, jazz, classical,...), confusion matrix giúp dễ dàng nhận diện:\n  - Lớp nào mô hình dự đoán tốt\n  - Lớp nào bị nhầm lẫn với nhau (ví dụ: rock thường bị nhầm với metal)\n  - Từ confusion matrix, có thể tính toán các metric như precision, recall, F1-score cho từng lớp, sau đó tính macro-average hoặc weighted-average để đánh giá tổng thể.\n\nCác lựa chọn khác không phù hợp:\n• **Correlation matrix**: Dùng để hiển thị mối tương quan giữa các biến số (features), không phải để đánh giá hiệu suất mô hình phân loại.\n• **Box plot**: Dùng để hiển thị phân phối của dữ liệu số (như outlier, median), không liên quan đến việc đánh giá dự đoán phân loại.\n• **Precision-Recall curve**: Rất hữu ích cho binary classification hoặc khi dữ liệu mất cân bằng, nhưng không phải là cách trực quan hóa tổng quát và chi tiết nhất cho multi-class (dù có thể vẽ PR curve cho từng lớp, nhưng khó đọc khi có nhiều lớp).\n\nDo đó, **Confusion matrix** là kỹ thuật trực quan hóa tiêu chuẩn và hiệu quả nhất để đánh giá mô hình multi-class classification trong bài toán dự đoán thể loại âm nhạc, đặc biệt khi cần xem xét chi tiết các lỗi phân loại giữa các lớp.\n\nNguồn tham khảo: AWS Machine Learning Specialty – Confusion matrix được sử dụng rộng rãi để visualize performance của multiclass classifiers, và Amazon SageMaker cung cấp công cụ built-in để tạo confusion matrix."
            },
            {
                "domain": "Machine Learning Evaluation",
                "q": "An ML engineer is tasked with forecasting the monthly revenue for a subscription-based service.\nWhich evaluation metrics should be used to assess the model’s performance? (Select TWO.)",
                "options": [
                    "Accuracy",
                    "Inference Latency",
                    "Mean absolute error (MAE)",
                    "F1 score",
                    "Mean absolute percentage error (MAPE)"
                ],
                "correct": [2, 4],
                "explanation": "Yêu cầu chính trong tình huống này là đánh giá hiệu suất mô hình **dự báo (forecasting)** doanh thu hàng tháng – một bài toán **hồi quy (regression)** với giá trị đầu ra là số liên tục (continuous numerical value).\n\nHai metric phù hợp nhất để đánh giá mô hình dự báo là:\n\n• **Mean Absolute Error (MAE)** — Tính trung bình tuyệt đối của sai số giữa giá trị dự báo và giá trị thực tế. MAE dễ hiểu, có cùng đơn vị với doanh thu (ví dụ: USD), và cho biết trung bình mỗi tháng mô hình sai lệch bao nhiêu. Giá trị MAE càng thấp càng tốt, không bị ảnh hưởng bởi outlier như một số metric khác.\n• **Mean Absolute Percentage Error (MAPE)** — Tính trung bình phần trăm sai số tuyệt đối so với giá trị thực tế (|(actual - predicted)/actual| × 100%). MAPE rất hữu ích trong dự báo doanh thu vì nó cho biết mức độ sai lệch theo phần trăm, giúp dễ so sánh giữa các tháng có doanh thu khác nhau (ví dụ: tháng cao điểm và tháng thấp điểm). Giá trị MAPE càng thấp càng tốt.\n\nCác metric còn lại không phù hợp:\n• **Accuracy**: Dùng cho bài toán phân loại (classification), không áp dụng cho dự báo giá trị liên tục.\n• **Inference Latency**: Đo thời gian suy luận của mô hình, liên quan đến hiệu suất triển khai chứ không phải chất lượng dự báo.\n• **F1 score**: Dùng cho phân loại (đặc biệt khi mất cân bằng lớp), không phù hợp với bài toán hồi quy/dự báo.\n\nDo đó, **MAE** và **MAPE** là hai metric tiêu chuẩn và phù hợp nhất để đánh giá mô hình dự báo doanh thu hàng tháng trong dịch vụ subscription.\n\nNguồn tham khảo: AWS Machine Learning Specialty & best practices trong time-series forecasting – MAE và MAPE là các metric phổ biến nhất cho regression/forecasting tasks."
            },
            {
                "domain": "AWS ML Services & Human-in-the-Loop",
                "q": "An AI specialist is developing a system to detect vehicles in street images using machine learning. The goal is to create labels for a large dataset of street images and utilize Reinforcement Learning from Human Feedback (RLHF) to improve the model over time.\nWhich of the following options would be the most suitable for this task?",
                "options": [
                    "Amazon Rekognition Custom Labels",
                    "Amazon SageMaker built-in algorithms",
                    "Amazon Comprehend",
                    "Amazon SageMaker Ground Truth"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính trong tình huống này bao gồm hai phần:\n1. **Tạo nhãn (labels)** cho tập dữ liệu lớn các ảnh đường phố (street images) để huấn luyện mô hình phát hiện xe cộ (vehicle detection) – một bài toán object detection.\n2. **Sử dụng Reinforcement Learning from Human Feedback (RLHF)** để cải thiện mô hình theo thời gian thông qua phản hồi của con người (human-in-the-loop).\n\n**Amazon SageMaker Ground Truth** là dịch vụ phù hợp nhất:\n\n• **Amazon SageMaker Ground Truth** — Cung cấp khả năng **human-in-the-loop** toàn diện để tạo nhãn dữ liệu chất lượng cao. Dịch vụ hỗ trợ các task type built-in cho object detection như **Bounding Box** (vẽ hộp bao quanh xe), Image Semantic Segmentation, Image Classification, Label Verification, v.v. Bạn có thể tạo labeling job quy mô lớn, sử dụng workforce nội bộ hoặc qua Amazon Mechanical Turk/AWS-managed vendors. Đặc biệt, Ground Truth hỗ trợ **iterative human review** và **active learning** – cho phép con người xem xét và chỉnh sửa nhãn, cung cấp feedback liên tục để retrain mô hình. Điều này rất gần với nguyên lý RLHF (dù RLHF thường dùng cho LLMs, nhưng human feedback loop trong Ground Truth có thể áp dụng để cải thiện mô hình object detection theo thời gian).\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Rekognition Custom Labels**: Dùng để train mô hình custom object detection bằng cách cung cấp nhãn sẵn (hoặc auto-labeling), nhưng không tập trung vào việc tạo nhãn quy mô lớn hoặc human feedback loop để cải thiện liên tục.\n• **Amazon SageMaker built-in algorithms**: Cung cấp các thuật toán có sẵn (như Object Detection với SSD/MXNet), nhưng không hỗ trợ tạo nhãn hoặc human-in-the-loop.\n• **Amazon Comprehend**: Là dịch vụ NLP (xử lý văn bản), không liên quan đến computer vision hoặc phát hiện vật thể trong ảnh.\n\nDo đó, **Amazon SageMaker Ground Truth** là lựa chọn tối ưu để tạo nhãn dữ liệu lớn cho object detection và tích hợp human feedback để cải thiện mô hình theo thời gian.\n\nNguồn tham khảo: AWS SageMaker Ground Truth documentation – Hỗ trợ task types cho object detection (Bounding Box) và human-in-the-loop workflows (active learning, iterative labeling) để nâng cao chất lượng mô hình."
            },
            {
                "domain": "Responsible AI & Fairness in AWS",
                "q": "A team is working on a machine learning project. They have developed a model for predicting whether an email is spam or not. Before deploying the model, the team wants to ensure fairness and transparency.\nWhich options would be the most suitable for this use case?",
                "options": [
                    "Amazon Comprehend",
                    "Amazon SageMaker Clarify",
                    "Amazon Personalize",
                    "Amazon SageMaker Ground Truth"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là đảm bảo **tính công bằng (fairness)** và **tính minh bạch (transparency)** cho mô hình phân loại email spam/not spam trước khi triển khai, bao gồm việc phát hiện bias, đánh giá fairness và tạo báo cáo minh bạch.\n\n**Amazon SageMaker Clarify** là dịch vụ phù hợp nhất:\n\n• **Amazon SageMaker Clarify** — Cung cấp bộ công cụ toàn diện để **phát hiện và giảm thiểu bias** (bias detection & mitigation), **đánh giá fairness** của mô hình, và **tăng tính minh bạch** thông qua explainability (giải thích quyết định mô hình). Clarify hỗ trợ:\n  - Pre-training bias metrics (ví dụ: Class Imbalance, Difference in Positive Proportions)\n  - Post-training bias metrics (ví dụ: Equalized Odds, Disparate Impact)\n  - Feature importance và model explainability (SHAP values)\n  - Bias monitoring sau triển khai (bias drift detection)\n  - Báo cáo fairness xuất được (exportable reports) và tích hợp cảnh báo CloudWatch\n\nĐiều này rất quan trọng cho mô hình spam detection – một ứng dụng nhạy cảm, nơi bias có thể dẫn đến phân biệt đối xử (ví dụ: nhầm lẫn email từ một số ngôn ngữ, nhóm người dùng cụ thể là spam).\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Comprehend**: Dịch vụ NLP cho phân tích văn bản (sentiment, entity recognition, topic modeling), không chuyên về fairness hoặc bias detection.\n• **Amazon Personalize**: Dùng để xây dựng hệ thống gợi ý cá nhân hóa, không liên quan đến fairness hoặc transparency của mô hình phân loại.\n• **Amazon SageMaker Ground Truth**: Tập trung vào việc tạo nhãn dữ liệu (data labeling) với human-in-the-loop, không phải công cụ để đánh giá fairness hoặc explainability sau khi huấn luyện.\n\nDo đó, **Amazon SageMaker Clarify** là lựa chọn tối ưu để đảm bảo mô hình spam prediction công bằng và minh bạch trước khi deploy.\n\nNguồn tham khảo: AWS SageMaker Clarify documentation – Designed specifically for bias detection, fairness evaluation, and model explainability in ML workflows."
            },
            {
                "domain": "AIF – Fundamentals of Generative AI",
                "q": "A machine learning engineer is evaluating the performance of a generative model system used for customer support. The engineer needs to identify key performance metrics and optimize the model for better response accuracy and efficiency.\nWhich business metric would best evaluate the model’s performance?",
                "options": [
                    "AWS Customer Reviews",
                    "Average response time",
                    "Customer satisfaction",
                    "Conversion rate"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính trong tình huống này là tìm **business metric** tốt nhất để đánh giá hiệu suất tổng thể của hệ thống generative model dùng cho **hỗ trợ khách hàng** (customer support), nơi mục tiêu là cung cấp phản hồi chính xác, hữu ích và nâng cao trải nghiệm người dùng.\n\n**Customer satisfaction (CSAT)** là metric kinh doanh phù hợp nhất:\n\n• **Customer satisfaction** (thường đo bằng CSAT score qua khảo sát sau tương tác: 'Bạn hài lòng với phản hồi này đến mức nào?') — Đây là chỉ số trực tiếp phản ánh mức độ khách hàng hài lòng với chất lượng, độ chính xác, hữu ích và phong cách của phản hồi từ generative AI. CSAT cao cho thấy mô hình đang đáp ứng tốt nhu cầu khách hàng, xây dựng lòng tin và lòng trung thành. Đây là metric kinh doanh cốt lõi (business outcome) trong customer support, vì mục đích cuối cùng của hệ thống AI là cải thiện trải nghiệm và sự hài lòng của khách hàng.\n\nCác lựa chọn khác không phải là metric kinh doanh tốt nhất để đánh giá hiệu suất tổng thể:\n• **AWS Customer Reviews**: Liên quan đến đánh giá dịch vụ AWS trên marketplace hoặc review của đối tác, không phải metric đánh giá hiệu suất mô hình customer support nội bộ.\n• **Average response time**: Là technical metric (độ trễ phản hồi), quan trọng cho trải nghiệm người dùng nhưng chỉ đo hiệu quả (efficiency), không đo chất lượng nội dung hay mức độ hài lòng.\n• **Conversion rate**: Thường dùng trong e-commerce/marketing (tỷ lệ chuyển đổi từ khách hàng tiềm năng thành mua hàng), không trực tiếp liên quan đến chất lượng hỗ trợ khách hàng trừ khi hệ thống AI được dùng trong sales support.\n\nDo đó, **Customer satisfaction** là business metric quan trọng nhất để đánh giá và tối ưu hóa generative model trong customer support, vì nó phản ánh trực tiếp giá trị kinh doanh mà mô hình mang lại.\n\nNguồn tham khảo: Best practices trong Generative AI for customer support (AWS, OpenAI, Anthropic) – CSAT là KPI chính để đo lường thành công của chatbot/conversational AI."
            },
            {
                "domain": "Responsible AI & AWS Services",
                "q": "A financial organization is planning to integrate generative artificial intelligence (generative AI) services into its workflow to improve customer support with natural language processing capabilities. The company is keen on ensuring that its AI models are transparent, fair, and accountable. They are looking for resources to understand the ethical implications and responsible use of AI services.\nWhich AWS service would be appropriate for this task?",
                "options": [
                    "AWS AI Service Cards",
                    "Amazon Comprehend",
                    "AWS Marketplace",
                    "Amazon Polly"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính của tổ chức tài chính là tìm kiếm **tài liệu và nguồn thông tin** để hiểu rõ **hàm ý đạo đức (ethical implications)**, đảm bảo tính **minh bạch (transparency)**, **công bằng (fairness)**, **trách nhiệm giải trình (accountability)** khi sử dụng các dịch vụ generative AI cho hỗ trợ khách hàng.\n\n**AWS AI Service Cards** là tài nguyên phù hợp nhất:\n\n• **AWS AI Service Cards** — Đây là tài liệu Responsible AI chính thức của AWS, cung cấp một nguồn thông tin tập trung (single source) về:\n  - Các trường hợp sử dụng dự kiến (intended use cases)\n  - Các ràng buộc và hạn chế (limitations & constraints)\n  - Các lựa chọn thiết kế Responsible AI (fairness, bias mitigation, explainability, robustness, governance, transparency, privacy, security)\n  - Best practices để triển khai và tối ưu hóa an toàn\n\nCác Service Cards này giúp các tổ chức (đặc biệt trong lĩnh vực tài chính – ngành được quy định nghiêm ngặt) đánh giá rủi ro đạo đức, hiểu rõ cách AWS xây dựng dịch vụ AI một cách có trách nhiệm, và áp dụng đúng cách để tránh các vấn đề như bias, thiếu minh bạch hoặc lạm dụng. Chúng là công cụ quan trọng trong quá trình ra quyết định và tuân thủ khi tích hợp generative AI.\n\nCác lựa chọn khác không phù hợp:\n• **Amazon Comprehend**: Là dịch vụ NLP thực tế (phân tích văn bản, sentiment, entity recognition), không phải tài liệu về Responsible AI.\n• **AWS Marketplace**: Nền tảng mua/bán giải pháp AI/ML của bên thứ ba, không cung cấp tài liệu đạo đức hoặc hướng dẫn Responsible AI của AWS.\n• **Amazon Polly**: Dịch vụ text-to-speech, không liên quan đến tài liệu đạo đức hoặc đánh giá tính công bằng/minh bạch của AI.\n\nDo đó, **AWS AI Service Cards** là tài nguyên lý tưởng để tổ chức tài chính tìm hiểu và áp dụng các nguyên tắc Responsible AI khi tích hợp generative AI vào customer support.\n\nNguồn tham khảo: AWS Responsible AI – AWS AI Service Cards (có sẵn cho các dịch vụ như Amazon Bedrock, SageMaker, Comprehend, v.v.)."
            },
            {
                "domain": "Machine Learning Fundamentals",
                "q": "To estimate how users’ preferences are spread across different genres.",
                "options": [
                    "Linear regression",
                    "Probability density",
                    "Neural network",
                    "Probability density (Neural network)"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là **ước lượng cách sở thích của người dùng phân bố (spread)** trên các thể loại khác nhau (genres), ví dụ: tỷ lệ người dùng thích nhạc pop, rock, jazz, classical,... trong tập dữ liệu.\n\n**Probability density** là khái niệm/phương pháp phù hợp nhất:\n\n• **Probability density** — Dùng để mô tả **phân bố xác suất** (distribution) của một biến liên tục hoặc rời rạc. Trong bài toán này, sở thích theo thể loại (genres) thường là biến phân loại (categorical), và ta có thể ước lượng **xác suất** hoặc **mật độ xác suất** (probability mass/density) cho từng genre bằng cách:\n  - Tính tỷ lệ phần trăm (empirical probability)\n  - Vẽ histogram hoặc kernel density estimation (nếu coi genres là biến liên tục hóa)\n  - Sử dụng distribution fitting (ví dụ: multinomial distribution)\n\nĐiều này giúp hình dung rõ ràng \"sở thích người dùng phân bố như thế nào\" – thể loại nào phổ biến nhất, thể loại nào ít được ưa chuộng, v.v.\n\nCác lựa chọn khác không phù hợp:\n• **Linear regression**: Dùng để dự đoán giá trị liên tục (continuous target), không dùng để ước lượng phân bố xác suất của sở thích theo thể loại.\n• **Neural network**: Là mô hình học sâu tổng quát, có thể dùng để ước lượng density (ví dụ: normalizing flows, VAEs), nhưng không phải là khái niệm cốt lõi hoặc trực tiếp nhất cho bài toán đơn giản này.\n• **Probability density (Neural network)**: Là một cách nâng cao (sử dụng neural network để ước lượng probability density, như trong density estimation models), nhưng phức tạp hơn và không cần thiết khi chỉ cần ước lượng phân bố cơ bản trên các genres.\n\nDo đó, **Probability density** là khái niệm cơ bản và phù hợp nhất để ước lượng cách sở thích người dùng phân bố trên các thể loại khác nhau.\n\nNguồn tham khảo: Khái niệm cơ bản trong Machine Learning và Statistics – Probability density/mass function dùng để mô tả distribution của biến phân loại hoặc liên tục."
            },
            {
                "domain": "Machine Learning Fundamentals",
                "q": "To identify common patterns in the types of shows watched together.",
                "options": [
                    "Logistic regression",
                    "Association rule learning",
                    "Clustering",
                    "Decision tree"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là **xác định các mẫu phổ biến (common patterns)** trong việc người dùng xem **các loại chương trình (shows) cùng nhau** (ví dụ: ai xem phim hành động thường xem phim khoa học viễn tưởng cùng, hoặc 'người xem drama Hàn Quốc thường xem phim tình cảm cùng lúc').\n\n**Association rule learning** (Học luật kết hợp) là kỹ thuật phù hợp nhất:\n\n• **Association rule learning** — Là phương pháp khai phá dữ liệu (data mining) dùng để tìm ra các **luật kết hợp** (association rules) trong tập dữ liệu giao dịch lớn. Trong ngữ cảnh xem phim/streaming:\n  - Mỗi \"giao dịch\" là tập hợp các show mà một người dùng đã xem.\n  - Các luật kết hợp như: {Drama Hàn Quốc} → {Phim tình cảm} (support = 30%, confidence = 75%) nghĩa là 30% người dùng xem Drama Hàn Quốc, trong đó 75% cũng xem phim tình cảm.\n  - Thuật toán phổ biến: Apriori, FP-Growth.\n  - Ứng dụng thực tế: Netflix, Amazon Prime dùng association rules để gợi ý \"Frequently bought together\" hoặc \"Customers who watched this also watched…\".\n\nCác lựa chọn khác không phù hợp:\n• **Logistic regression**: Dùng để phân loại nhị phân (ví dụ: dự đoán người dùng có xem show X hay không), không tìm mẫu kết hợp giữa nhiều items.\n• **Clustering**: Nhóm người dùng tương đồng dựa trên sở thích, nhưng không trực tiếp tìm ra các cặp/tập show hay xem cùng nhau.\n• **Decision tree**: Dùng cho phân loại hoặc hồi quy, không chuyên khai phá luật kết hợp.\n\nDo đó, **Association rule learning** là kỹ thuật tiêu chuẩn và hiệu quả nhất để phát hiện các mẫu phổ biến về việc xem các loại show cùng nhau trong hệ thống gợi ý nội dung.\n\nNguồn tham khảo: Market basket analysis & recommendation systems – Association rule learning (Apriori algorithm) là nền tảng cho \"frequently watched together\" patterns trong streaming platforms."
            },
            {
                "domain": "Machine Learning Fundamentals",
                "q": "To group users with similar viewing habits.",
                "options": [
                    "Probability density",
                    "Clustering",
                    "Dimensionality reduction",
                    "Association rule learning"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính trong tình huống này là **nhóm (group)** các người dùng có **thói quen xem phim tương tự nhau** (similar viewing habits), ví dụ: nhóm người dùng thích phim hành động + khoa học viễn tưởng, nhóm thích drama Hàn Quốc + phim tình cảm, v.v.\n\n**Clustering** là kỹ thuật phù hợp nhất:\n\n• **Clustering** (Phân cụm) — Là phương pháp học không giám sát (unsupervised learning) dùng để phân nhóm dữ liệu mà không cần nhãn trước. Các thuật toán clustering sẽ tự động nhóm các người dùng dựa trên sự tương đồng trong thói quen xem phim (ví dụ: số lượng phim hành động xem, thời gian xem, thể loại ưa thích, v.v.).\n  - Các thuật toán phổ biến: K-Means, DBSCAN, Hierarchical Clustering.\n  - Ứng dụng thực tế: Netflix, YouTube, Disney+ dùng clustering để phân đoạn người dùng (user segmentation), từ đó cá nhân hóa gợi ý, chiến dịch marketing, hoặc phát hiện nhóm người dùng đặc biệt (power users, casual viewers).\n\nCác lựa chọn khác không phù hợp trực tiếp:\n• **Probability density**: Dùng để ước lượng phân bố xác suất (ví dụ: mật độ sở thích theo thể loại), không phải để nhóm người dùng.\n• **Dimensionality reduction**: Giảm số chiều dữ liệu (ví dụ: PCA, t-SNE) để dễ trực quan hóa hoặc tăng tốc độ tính toán, thường là bước tiền xử lý trước clustering, nhưng không phải là kỹ thuật phân nhóm.\n• **Association rule learning**: Tìm luật kết hợp (ví dụ: ai xem phim A thường xem phim B), không nhóm người dùng mà chỉ tìm pattern giữa các item.\n\nDo đó, **Clustering** là kỹ thuật tiêu chuẩn và hiệu quả nhất để nhóm người dùng có thói quen xem phim tương tự nhau trong hệ thống gợi ý nội dung.\n\nNguồn tham khảo: User segmentation trong recommendation systems – Clustering là phương pháp cốt lõi để phân nhóm người dùng dựa trên hành vi xem (viewing patterns)."
            },
            {
                "domain": "Generative AI Inference Performance",
                "q": "Which factors can directly influence the latency of a machine learning model’s inference? (Select TWO.)",
                "options": [
                    "Complexity of the model architecture",
                    "Length of the generated output sequence",
                    "Length of the input data sequence",
                    "Batch size used during inference",
                    "Configuration of the inference parameter"
                ],
                "correct": [1, 2],
                "explanation": "Trong quá trình inference của các mô hình foundation model (đặc biệt là large language models như trên Amazon Bedrock), latency (độ trễ) là thời gian từ lúc nhận input đến khi hoàn thành output.\n\nHai yếu tố trực tiếp ảnh hưởng lớn nhất đến latency là:\n\n• **Length of the input data sequence** — Độ dài chuỗi input (số token đầu vào). Input càng dài, mô hình phải xử lý càng nhiều token ban đầu (self-attention complexity O(n²) trong transformer), dẫn đến thời gian tính toán tăng đáng kể.\n• **Length of the generated output sequence** — Độ dài chuỗi output sinh ra (số token được generate). Trong autoregressive generation, mô hình phải dự đoán từng token một cách tuần tự (sequential decoding), nên output càng dài thì thời gian inference càng tăng tuyến tính theo số token output.\n\nCác yếu tố khác cũng có ảnh hưởng nhưng không phải là yếu tố trực tiếp và lớn nhất trong ngữ cảnh này:\n• **Complexity of the model architecture** — Ảnh hưởng đến latency cơ bản (model lớn hơn thì chậm hơn), nhưng là yếu tố cố định sau khi chọn model, không thay đổi trong quá trình inference của cùng một model.\n• **Batch size used during inference** — Batch size lớn thường giảm latency per request (tăng throughput), nhưng trong hầu hết các ứng dụng real-time (chatbot, customer support), inference thường dùng batch size = 1 → không phải yếu tố trực tiếp thay đổi latency.\n• **Configuration of the inference parameter** — Các tham số như temperature, top-p, max_tokens có thể gián tiếp ảnh hưởng (max_tokens giới hạn độ dài output), nhưng không trực tiếp như độ dài thực tế của input/output.\n\nDo đó, **Length of the input data sequence** và **Length of the generated output sequence** là hai yếu tố trực tiếp và quan trọng nhất ảnh hưởng đến inference latency trong các mô hình generative AI.\n\nNguồn tham khảo: Amazon Bedrock inference documentation & Transformer inference characteristics – Latency chủ yếu phụ thuộc vào input length (prefill phase) và output length (decode phase)."
            },
            {
                "domain": "Challenges of Generative AI",
                "q": "A content creator uses generative AI to produce marketing material that closely resembles existing text without proper attribution.\nWhat challenges of generative AI does this situation highlight?",
                "options": [
                    "Toxicity",
                    "Hallucinations",
                    "Intellectual Property",
                    "Disruption of the nature of work"
                ],
                "correct": 2,
                "explanation": "Tình huống mô tả một content creator sử dụng generative AI để tạo ra nội dung marketing **gần giống hệt** với văn bản hiện có mà **không ghi nguồn (without proper attribution)**.\n\n**Intellectual Property** (Quyền sở hữu trí tuệ) là thách thức chính mà tình huống này làm nổi bật:\n\n• **Intellectual Property** — Các mô hình generative AI được huấn luyện trên lượng dữ liệu khổng lồ từ internet, sách, bài viết, v.v., bao gồm nhiều nội dung có bản quyền. Khi mô hình sinh ra output **gần giống** hoặc **tái tạo lại** các đoạn văn bản từ dữ liệu huấn luyện mà không ghi nguồn, điều này có thể vi phạm bản quyền (copyright infringement), dẫn đến tranh chấp pháp lý về quyền sở hữu trí tuệ. Vấn đề này càng nghiêm trọng khi nội dung được sử dụng thương mại (như marketing material) mà không có sự cho phép hoặc attribution phù hợp.\n\nCác lựa chọn khác không phù hợp trực tiếp:\n• **Toxicity**: Liên quan đến việc mô hình sinh ra nội dung độc hại, thù địch, phân biệt đối xử – không liên quan đến việc sao chép nội dung.\n• **Hallucinations**: Chỉ việc mô hình tạo ra thông tin sai lệch, bịa đặt – không phải vấn đề sao chép nội dung có thật.\n• **Disruption of the nature of work**: Đề cập đến việc AI thay đổi công việc, làm mất việc làm hoặc thay đổi vai trò – không trực tiếp liên quan đến việc vi phạm bản quyền.\n\nDo đó, **Intellectual Property** là thách thức cốt lõi mà tình huống này nhấn mạnh, đặc biệt trong bối cảnh sử dụng generative AI cho nội dung thương mại mà không ghi nhận nguồn gốc.\n\nNguồn tham khảo: Các vấn đề Responsible AI trong Generative AI (AWS, OpenAI, Anthropic) – Intellectual Property và plagiarism là một trong những rủi ro pháp lý lớn nhất hiện nay."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "An e-commerce company has implemented an AI model to categorize products based on images uploaded by sellers. The company must determine how well the model correctly classifies the product categories.\nWhat is the most appropriate metric to assess the effectiveness of the image classification model?",
                "options": [
                    "Recall",
                    "Accuracy",
                    "Precision",
                    "Root mean squared error (RMSE)"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là đánh giá **hiệu quả tổng thể** của mô hình phân loại hình ảnh sản phẩm (image classification) trong thương mại điện tử, tức là xác định **mô hình phân loại đúng bao nhiêu phần trăm** các sản phẩm vào danh mục chính xác.\n\n**Accuracy** là metric phù hợp nhất trong trường hợp này:\n\n• **Accuracy** — Đo lường tỷ lệ dự đoán đúng trên tổng số dự đoán: (số instance đúng / tổng số instance). Đây là metric đơn giản, trực quan và được sử dụng rộng rãi để đánh giá hiệu suất tổng thể của mô hình phân loại đa lớp (multi-class classification) như phân loại danh mục sản phẩm (áo thun, giày dép, điện thoại, sách, v.v.). Khi tập dữ liệu có phân bố lớp tương đối cân bằng (balanced classes) – điều thường thấy trong các hệ thống e-commerce lớn – accuracy cung cấp cái nhìn tổng quát và dễ hiểu về độ chính xác của mô hình.\n\nCác metric khác không phải là lựa chọn tốt nhất cho yêu cầu \"đánh giá tổng thể hiệu quả\":\n• **Recall**: Đo tỷ lệ tìm thấy đúng các instance positive cho một lớp cụ thể, hữu ích khi cần giảm thiểu false negative (ví dụ: không bỏ sót sản phẩm quan trọng), nhưng không phản ánh hiệu suất tổng thể của tất cả các lớp.\n• **Precision**: Đo tỷ lệ dự đoán positive thực sự đúng, hữu ích khi cần giảm thiểu false positive (ví dụ: tránh gắn nhãn sai làm ảnh hưởng trải nghiệm người mua), nhưng cũng chỉ tập trung vào một khía cạnh.\n• **Root mean squared error (RMSE)**: Là metric cho bài toán hồi quy (dự đoán giá trị số liên tục), hoàn toàn không áp dụng cho bài toán phân loại danh mục (classification).\n\nTrong Amazon SageMaker, accuracy là metric mặc định và được sử dụng phổ biến để đánh giá các mô hình image classification (ví dụ: built-in algorithms như Image Classification hoặc custom models với ResNet, EfficientNet). Khi dữ liệu cân bằng, accuracy là chỉ số trực quan và đáng tin cậy nhất để xác định \"mô hình phân loại đúng bao nhiêu\".\n\nDo đó, **Accuracy** là metric phù hợp nhất để đánh giá hiệu quả tổng thể của mô hình phân loại sản phẩm dựa trên hình ảnh trong thương mại điện tử.\n\nNguồn tham khảo: AWS SageMaker documentation – Accuracy là metric chính cho multi-class image classification tasks khi classes tương đối cân bằng."
            },
            {
                "domain": "AIF – Guidelines for Responsible AI",
                "q": "A finance company uses Amazon Bedrock to deploy a generative AI-based chatbot that provides personalized financial advice and answers related queries. As part of its governance framework outlined in the AWS Generative AI Security Scoping Matrix, the company needs a solution to control and evaluate the chatbot’s generated content to ensure accuracy, appropriateness, and adherence to regulatory standards.\nWhich AWS tool will help ensure that the chatbot’s advice meets accuracy and regulatory compliance standards?",
                "options": [
                    "Bedrock Agents",
                    "Guardrails for Bedrock",
                    "Amazon Comprehend",
                    "Amazon Lex"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính của công ty tài chính là cần một công cụ để **kiểm soát và đánh giá** nội dung do chatbot generative AI tạo ra, đảm bảo **độ chính xác (accuracy)**, **tính phù hợp (appropriateness)** và **tuân thủ quy định pháp lý (regulatory compliance)** trong lĩnh vực tài chính – một ngành nhạy cảm với rủi ro cao nếu đưa ra lời khuyên sai lệch.\n\n**Guardrails for Amazon Bedrock** là công cụ phù hợp nhất:\n\n• **Guardrails for Bedrock** — Đây là tính năng chuyên dụng trong Amazon Bedrock, cho phép thiết lập các **rào chắn nội dung (content filters)** tùy chỉnh để:\n  - Chặn hoặc sửa đổi output chứa thông tin nhạy cảm, không chính xác, độc hại, hoặc vi phạm quy định.\n  - Áp dụng các chính sách nội dung cụ thể (content policies) như cấm đưa ra lời khuyên đầu tư cụ thể mà không có disclaimer, ngăn chặn thông tin sai lệch về sản phẩm tài chính.\n  - Kiểm tra contextual grounding (đảm bảo output dựa trên dữ liệu đáng tin cậy, tránh hallucination).\n  - Phát hiện và chặn PII (Personally Identifiable Information) nếu cần.\n  - Hỗ trợ các danh mục như Hate, Insults, Sexual, Violence, Prompt attacks, và các policy tùy chỉnh.\n\nGuardrails tích hợp trực tiếp vào Bedrock API, giúp kiểm soát output thời gian thực mà không cần thay đổi mô hình gốc, rất phù hợp với AWS Generative AI Security Scoping Matrix (nhấn mạnh governance, safety, và compliance).\n\nCác lựa chọn khác không đáp ứng trực tiếp:\n• **Bedrock Agents**: Dùng để xây dựng agent tự động thực hiện tác vụ đa bước (multi-step tasks) với tools, không tập trung vào kiểm soát nội dung output.\n• **Amazon Comprehend**: Dịch vụ NLP để phân tích văn bản (sentiment, entity, topic), không dùng để kiểm soát hoặc lọc output generative trong thời gian thực.\n• **Amazon Lex**: Dịch vụ xây dựng chatbot truyền thống (intent-based), không phải cho generative AI và không có guardrails nâng cao như Bedrock.\n\nDo đó, **Guardrails for Bedrock** là giải pháp lý tưởng để đảm bảo chatbot tài chính cung cấp lời khuyên chính xác, phù hợp và tuân thủ quy định.\n\nNguồn tham khảo: AWS Bedrock documentation – Guardrails for Amazon Bedrock (content filtering, PII redaction, contextual grounding, custom policies) được thiết kế dành riêng cho responsible generative AI trong các ngành regulated như finance."
            }, {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A logistics company wants to forecast delivery times based on traffic conditions, weather data, and route information. The company also plans to use these insights for future forecast predictions of delivery performance. A set of ML algorithms is being evaluated to identify one that produces interpretable results with a clear breakdown of how each factor influences the predicted delivery time through a hierarchical decision-making process.\nWhich machine learning (ML) algorithm satisfies the company’s needs?",
                "options": [
                    "Decision Trees",
                    "K-Nearest Neighbors (KNN)",
                    "Logistic Regression",
                    "Support Vector Machine (SVM)"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính của công ty logistics là tìm một thuật toán ML có khả năng **dự báo thời gian giao hàng** (regression task) dựa trên các yếu tố như điều kiện giao thông, thời tiết và thông tin tuyến đường, đồng thời phải **dễ giải thích (interpretable)** và cung cấp **cách phân tích rõ ràng, theo thứ bậc (hierarchical decision-making)** về cách từng yếu tố ảnh hưởng đến kết quả dự đoán.\n\n**Decision Trees** là thuật toán phù hợp nhất:\n\n• **Decision Trees** — Hoạt động bằng cách chia nhỏ dữ liệu theo từng điều kiện (split) dựa trên các đặc trưng (features) như thời gian tắc đường, mưa lớn, khoảng cách tuyến đường, v.v. Cấu trúc cây quyết định tạo ra một quy trình ra quyết định **theo thứ bậc rõ ràng** (hierarchical), trong đó:\n  - Mỗi nút (node) đại diện cho một quyết định dựa trên một yếu tố cụ thể.\n  - Mỗi nhánh cho thấy tác động của điều kiện đó.\n  - Đường đi từ gốc đến lá thể hiện chính xác cách các yếu tố kết hợp để đưa ra dự đoán thời gian giao hàng.\n\nĐiều này cho phép công ty dễ dàng **hiểu và giải thích** tại sao mô hình dự đoán một thời gian giao hàng cụ thể (ví dụ: \"Nếu mưa > 10mm → thời gian tăng 45 phút → nếu tuyến đường cao tốc → giảm 20 phút\"). Decision Trees rất trực quan, dễ visualize (có thể vẽ cây), và là một trong những thuật toán **interpretable nhất** trong ML.\n\nCác lựa chọn khác không đáp ứng tốt yêu cầu về tính giải thích theo thứ bậc:\n• **K-Nearest Neighbors (KNN)**: Dự đoán dựa trên sự tương đồng với các điểm dữ liệu gần nhất, không cung cấp cấu trúc thứ bậc hay giải thích rõ ràng cách các yếu tố ảnh hưởng.\n• **Logistic Regression**: Dùng cho phân loại (classification), không phù hợp cho dự báo thời gian (regression); dù có thể dùng Linear Regression cho regression nhưng vẫn thiếu cấu trúc hierarchical.\n• **Support Vector Machine (SVM)**: Tạo ra siêu phẳng phân cách, rất khó giải thích cách các yếu tố ảnh hưởng (black-box hơn so với Decision Trees), đặc biệt trong regression (SVR).\n\nDo đó, **Decision Trees** là thuật toán đáp ứng tốt nhất nhu cầu về tính dự báo, giải thích rõ ràng và phân tích thứ bậc ảnh hưởng của các yếu tố trong bài toán dự báo thời gian giao hàng.\n\nNguồn tham khảo: Các thuật toán ML cơ bản (AWS Machine Learning Specialty) – Decision Trees được khuyến nghị khi cần high interpretability và feature importance hierarchy trong regression tasks."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A financial services company needs to analyze customer feedback from survey responses to understand the overall sentiment. The solution must automatically detect positive, negative, or neutral sentiments in the text data.\nWhat are the most suitable AWS services for this solution? (Select TWO.)",
                "options": [
                    "Amazon Comprehend",
                    "Amazon Bedrock",
                    "Amazon Translate",
                    "Amazon Textract",
                    "Amazon Polly"
                ],
                "correct": [0, 1],
                "explanation": "Yêu cầu chính là phân tích **phản hồi khách hàng** (customer feedback) từ khảo sát để tự động **phát hiện cảm xúc (sentiment)**: tích cực (positive), tiêu cực (negative), trung lập (neutral) trong dữ liệu văn bản.\n\nHai dịch vụ AWS phù hợp nhất là:\n\n• **Amazon Comprehend** — Đây là dịch vụ NLP (Natural Language Processing) chuyên dụng của AWS, sử dụng machine learning để phân tích văn bản và thực hiện **sentiment analysis** một cách trực tiếp và dễ dàng. Comprehend tự động trả về điểm số sentiment (positive, negative, neutral, mixed) kèm theo confidence score cho từng đoạn văn bản. Dịch vụ này được thiết kế sẵn cho các bài toán như phân tích phản hồi khách hàng, đánh giá khảo sát, review sản phẩm – rất phù hợp và dễ tích hợp cho công ty tài chính.\n• **Amazon Bedrock** — Là nền tảng managed cung cấp truy cập vào các foundation models (FMs) lớn từ Amazon và bên thứ ba (như Anthropic Claude, Meta Llama, v.v.). Bedrock hỗ trợ **sentiment analysis** thông qua prompt engineering hoặc fine-tuning, cho phép xử lý văn bản phức tạp, hiểu ngữ cảnh sâu hơn, và tùy chỉnh theo nhu cầu cụ thể của ngành tài chính (ví dụ: phát hiện cảm xúc liên quan đến sản phẩm tài chính, khiếu nại dịch vụ). Bedrock mang lại tính linh hoạt cao hơn cho các kịch bản advanced NLP.\n\nCác dịch vụ khác không phù hợp:\n• **Amazon Translate**: Dùng để dịch văn bản giữa các ngôn ngữ, không hỗ trợ phân tích sentiment.\n• **Amazon Textract**: Trích xuất văn bản và dữ liệu có cấu trúc từ hình ảnh/PDF (OCR + form/table extraction), không phân tích cảm xúc.\n• **Amazon Polly**: Chuyển văn bản thành giọng nói (text-to-speech), không liên quan đến phân tích sentiment.\n\nDo đó, **Amazon Comprehend** (dịch vụ chuyên biệt, dễ dùng) và **Amazon Bedrock** (linh hoạt với foundation models) là hai lựa chọn phù hợp nhất để tự động phát hiện sentiment trong phản hồi khách hàng.\n\nNguồn tham khảo: AWS documentation – Amazon Comprehend Sentiment Analysis & Amazon Bedrock for custom NLP tasks including sentiment detection."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A financial company is optimizing its AI fraud detection system powered by an AI model to reduce transaction processing delays. The company must measure the system’s runtime efficiency for analyzing and approving transactions.\nWhich metric is most suitable for this purpose?",
                "options": [
                    "Average response time",
                    "Model accuracy",
                    "Model training time",
                    "Training duration per epoch"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính của công ty tài chính là đo lường **hiệu quả thời gian chạy (runtime efficiency)** của hệ thống AI phát hiện gian lận trong quá trình **phân tích và phê duyệt giao dịch thời gian thực** (real-time transaction processing), nhằm giảm thiểu độ trễ (delays).\n\n**Average response time** là metric phù hợp nhất:\n\n• **Average response time** — Đo thời gian trung bình từ lúc hệ thống nhận yêu cầu giao dịch đến khi trả về quyết định (phê duyệt hoặc từ chối). Metric này bao gồm thời gian inference của mô hình (model inference latency) và các bước xử lý hệ thống khác. Trong phát hiện gian lận tài chính, response time thấp là yếu tố cực kỳ quan trọng để:\n  - Không làm gián đoạn trải nghiệm người dùng (user experience)\n  - Đáp ứng yêu cầu tuân thủ thời gian xử lý giao dịch\n  - Xử lý hàng triệu giao dịch mỗi ngày mà không gây bottleneck\n\nTrong môi trường AWS, metric này thường được giám sát qua **Amazon SageMaker Endpoints** (cho real-time inference) và **Amazon CloudWatch** (đo latency, visualize biểu đồ response time theo thời gian). Các tổ chức tài chính thường đặt SLA (Service Level Agreement) nghiêm ngặt cho average response time (ví dụ: dưới 100ms hoặc 200ms).\n\nCác lựa chọn khác không phù hợp:\n• **Model accuracy**: Đo độ chính xác dự đoán (true positive, false negative, v.v.), quan trọng cho hiệu quả phát hiện gian lận nhưng không liên quan đến tốc độ xử lý thời gian thực.\n• **Model training time**: Thời gian huấn luyện toàn bộ mô hình, diễn ra trong giai đoạn phát triển, không ảnh hưởng đến runtime efficiency khi hệ thống đang hoạt động.\n• **Training duration per epoch**: Thời gian hoàn thành một vòng lặp huấn luyện, cũng chỉ liên quan đến giai đoạn training, không đo lường hiệu suất inference.\n\nDo đó, **Average response time** là metric cốt lõi để tối ưu hóa và đo lường hiệu quả thời gian chạy của hệ thống AI fraud detection trong môi trường sản xuất.\n\nNguồn tham khảo: AWS SageMaker & CloudWatch documentation – Average response time (latency) là metric chính để giám sát real-time endpoints trong các ứng dụng high-throughput như fraud detection."
            },
            {
                "domain": "AIF – Applications of Foundation Models",
                "q": "A retail company leverages machine learning models to predict quarterly sales and optimize inventory management using AI agents via Amazon Bedrock AgentCore. In response to stakeholder requests, the data science team has been tasked with providing a comprehensive report that ensures transparency and explains the rationale behind the models’ decisions.\nWhat should the data science team present to clearly explain the model’s recommendation process?",
                "options": [
                    "Feature engineering scripts",
                    "Hyperparameter tuning results",
                    "Model convergence tables",
                    "Partial dependence plots (PDPs)"
                ],
                "correct": 3,
                "explanation": "Yêu cầu chính là cung cấp một báo cáo **minh bạch (transparency)** và **giải thích rõ ràng lý do (rationale)** đằng sau các quyết định/recommendation của mô hình dự báo doanh số quý và tối ưu hóa hàng tồn kho, đặc biệt khi sử dụng AI agents trên Amazon Bedrock AgentCore.\n\n**Partial Dependence Plots (PDPs)** là công cụ phù hợp nhất để trình bày:\n\n• **Partial Dependence Plots (PDPs)** — Là biểu đồ trực quan hóa **tác động biên (marginal effect)** của từng đặc trưng (feature) lên kết quả dự đoán của mô hình, trong khi giữ các đặc trưng khác cố định. PDPs cho thấy:\n  - Khi một yếu tố (ví dụ: giá khuyến mãi, thời tiết, mùa vụ, chi phí vận chuyển) thay đổi, dự báo doanh số sẽ thay đổi như thế nào.\n  - Mối quan hệ tuyến tính hay phi tuyến tính giữa feature và output.\n  - Hướng ảnh hưởng (tăng/giảm) và mức độ mạnh yếu.\n\nPDPs rất trực quan, dễ hiểu cho stakeholder không chuyên kỹ thuật, giúp họ nắm được \"tại sao mô hình đưa ra recommendation này\" (ví dụ: \"Khi giá giảm 10%, doanh số dự kiến tăng 15–20%\"). Trong AWS, PDPs được hỗ trợ mạnh mẽ qua **Amazon SageMaker Clarify**, công cụ chuyên về explainability, và có thể áp dụng cho các mô hình tabular, computer vision, NLP – phù hợp với workload retail đa dạng.\n\nCác lựa chọn khác không đáp ứng tốt yêu cầu minh bạch và giải thích quyết định:\n• **Feature engineering scripts**: Chỉ là code kỹ thuật, khó hiểu cho stakeholder, không trực quan hóa tác động.\n• **Hyperparameter tuning results**: Liên quan đến quá trình tối ưu mô hình (grid search, Bayesian optimization), không giải thích cách feature ảnh hưởng đến output.\n• **Model convergence tables**: Hiển thị loss giảm dần theo epoch, chỉ liên quan đến quá trình huấn luyện, không giải thích recommendation.\n\nDo đó, **Partial Dependence Plots (PDPs)** là lựa chọn tối ưu để báo cáo minh bạch, dễ hiểu và trực quan về quá trình ra quyết định của mô hình trong ứng dụng retail forecasting và inventory optimization.\n\nNguồn tham khảo: AWS SageMaker Clarify documentation – PDPs là một trong những công cụ explainability chính để visualize feature impact và tăng transparency cho stakeholder."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "You are tasked with reducing the dimensionality of a dataset before training a machine learning model. Which technique is MOST appropriate for this?",
                "options": [
                    "Data augmentation",
                    "Feature scaling",
                    "Principal Component Analysis (PCA)",
                    "One-hot encoding"
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là **giảm chiều dữ liệu (dimensionality reduction)** trước khi huấn luyện mô hình machine learning, nhằm giảm số lượng đặc trưng (features) trong khi vẫn giữ được phần lớn thông tin quan trọng, giúp:\n- Giảm thời gian huấn luyện\n- Giảm nguy cơ overfitting\n- Loại bỏ multicollinearity\n- Tăng tốc độ inference\n- Cải thiện hiệu suất tổng thể của mô hình\n\n**Principal Component Analysis (PCA)** là kỹ thuật phù hợp nhất:\n\n• **Principal Component Analysis (PCA)** — Là phương pháp giảm chiều không giám sát (unsupervised) phổ biến và hiệu quả nhất. PCA:\n  - Tìm ra các thành phần chính (principal components) – các hướng biến thiên lớn nhất trong dữ liệu.\n  - Chuyển đổi dữ liệu gốc sang không gian mới với số chiều ít hơn, nhưng giữ lại phần lớn phương sai (variance).\n  - Loại bỏ các chiều dư thừa, không tương quan với nhau (orthogonal components).\n  - Thường được dùng trước khi train các mô hình như KNN, SVM, Neural Networks hoặc trong các bài toán có số feature lớn (high-dimensional data).\n\nTrong AWS SageMaker, PCA là built-in algorithm dành riêng cho dimensionality reduction, rất phổ biến và được khuyến nghị cho các workload cần giảm chiều dữ liệu.\n\nCác lựa chọn khác không phù hợp:\n• **Data augmentation**: Tăng số lượng dữ liệu huấn luyện bằng cách tạo biến thể (flip, rotate, noise,...), thường dùng cho image data, không giảm chiều.\n• **Feature scaling**: Chuẩn hóa giá trị feature (StandardScaler, MinMaxScaler), cần thiết cho nhiều thuật toán (như SVM, KNN, Neural Nets), nhưng không giảm số lượng feature.\n• **One-hot encoding**: Chuyển đổi feature categorical sang dạng nhị phân, thường **tăng** chiều dữ liệu (curse of dimensionality) chứ không giảm.\n\nDo đó, **Principal Component Analysis (PCA)** là kỹ thuật phù hợp nhất và được khuyến nghị theo nguyên tắc AWS AI/ML để giảm chiều dữ liệu trước khi huấn luyện mô hình.\n\nNguồn tham khảo: AWS SageMaker built-in algorithms – PCA được thiết kế chuyên biệt cho dimensionality reduction tasks."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A manufacturing company wants to use machine learning to predict equipment failures. They have sensor data from various machines. Before building a model, what is the MOST important first step?",
                "options": [
                    "Deploy the model to production to gather real-time data.",
                    "Select the most complex machine learning algorithm available.",
                    "Clean and preprocess the sensor data to handle missing values and outliers.",
                    "Immediately start training the model with the raw sensor data."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là xác định **bước quan trọng nhất đầu tiên** trước khi xây dựng mô hình machine learning dự đoán hỏng hóc thiết bị (predictive maintenance) dựa trên dữ liệu cảm biến từ các máy móc.\n\n**Clean and preprocess the sensor data to handle missing values and outliers** là bước quan trọng nhất:\n\n• Dữ liệu cảm biến thực tế (IoT/sensor data) trong môi trường sản xuất thường chứa:\n  - Giá trị thiếu (missing values) do lỗi cảm biến, mất kết nối.\n  - Outliers (giá trị bất thường) do nhiễu, lỗi đo, hoặc sự kiện bất ngờ.\n  - Inconsistencies (dữ liệu không đồng nhất) về tần suất lấy mẫu, đơn vị đo lường, v.v.\n\nNếu không làm sạch và tiền xử lý dữ liệu (data cleaning & preprocessing), mô hình sẽ học từ nhiễu (noise), dẫn đến:\n  - Độ chính xác thấp\n  - Overfitting hoặc underfitting nghiêm trọng\n  - Dự đoán sai lệch (false positive/negative cao) → gây lãng phí hoặc bỏ sót sự cố thiết bị.\n\nĐây là nguyên tắc cơ bản trong pipeline machine learning (CRISP-DM, AWS ML best practices): **Data Preparation** chiếm 60–80% thời gian dự án và là bước đầu tiên quan trọng nhất trước khi huấn luyện mô hình.\n\nCác lựa chọn khác không phù hợp:\n• **Deploy the model to production to gather real-time data**: Đây là bước cuối cùng sau khi đã có mô hình tốt, không phải bước đầu.\n• **Select the most complex machine learning algorithm available**: \"No free lunch\" – thuật toán phức tạp không đảm bảo hiệu quả nếu dữ liệu kém chất lượng. Nên ưu tiên data quality trước model complexity.\n• **Immediately start training the model with the raw sensor data**: Đây là sai lầm phổ biến (garbage in, garbage out). Raw data thường không phù hợp để huấn luyện trực tiếp.\n\nDo đó, **Clean and preprocess the sensor data to handle missing values and outliers** là bước đầu tiên quan trọng nhất theo nguyên tắc AWS AI/ML và thực tiễn predictive maintenance.\n\nNguồn tham khảo: AWS Machine Learning Specialty & SageMaker best practices – Data preparation (cleaning, handling missing values, outlier detection) là bước nền tảng trước khi train model."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "You have a dataset with a large number of missing values. Which of the following is a common technique to handle missing data?",
                "options": [
                    "Always remove the rows with missing values.",
                    "Always replace missing values with zero.",
                    "Impute missing values using the mean or median.",
                    "Ignore the missing values during model training."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là xác định **kỹ thuật phổ biến** để xử lý **dữ liệu thiếu (missing values)** trong dataset, đặc biệt khi số lượng giá trị thiếu lớn, nhằm đảm bảo mô hình machine learning hoạt động hiệu quả mà không bị lỗi hoặc bias nghiêm trọng.\n\n**Impute missing values using the mean or median** là kỹ thuật phù hợp và phổ biến nhất:\n\n• **Imputation bằng mean (trung bình) hoặc median (trung vị)** — Đây là phương pháp đơn giản, hiệu quả và được sử dụng rộng rãi trong thực tế:\n  - **Mean imputation**: Thay giá trị thiếu bằng giá trị trung bình của cột (phù hợp với dữ liệu phân phối chuẩn, không nhiều outlier).\n  - **Median imputation**: Thay bằng giá trị trung vị (phù hợp hơn khi dữ liệu có outlier hoặc phân phối lệch).\n\nƯu điểm:\n  - Giữ nguyên số lượng mẫu (không mất dữ liệu như khi xóa hàng).\n  - Đơn giản, nhanh, và ít làm thay đổi phân phối tổng thể nếu tỷ lệ missing không quá cao.\n  - Được hỗ trợ sẵn trong các thư viện như scikit-learn (SimpleImputer), pandas (fillna), và AWS SageMaker (built-in data processing).\n\nCác lựa chọn khác không phải là kỹ thuật tốt hoặc phổ biến:\n• **Always remove the rows with missing values**: Có thể chấp nhận được nếu missing values rất ít (<5%), nhưng khi missing values lớn sẽ dẫn đến mất quá nhiều dữ liệu → giảm chất lượng mô hình và tăng bias.\n• **Always replace missing values with zero**: Có thể gây sai lệch nghiêm trọng (ví dụ: thay lương = 0 cho nhân viên thiếu dữ liệu → mô hình học sai).\n• **Ignore the missing values during model training**: Hầu hết các thuật toán ML (như Linear Regression, SVM, Neural Networks) không thể xử lý NaN/missing values trực tiếp → sẽ gây lỗi hoặc kết quả không đáng tin cậy.\n\nDo đó, **Impute missing values using the mean or median** là kỹ thuật xử lý missing data phổ biến, hiệu quả và được khuyến nghị theo nguyên tắc AWS AI/ML cho các dataset thực tế.\n\nNguồn tham khảo: AWS Machine Learning Specialty & SageMaker best practices – Imputation (mean/median) là bước tiền xử lý dữ liệu cơ bản và quan trọng trước khi huấn luyện mô hình."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A company has collected data on customer satisfaction scores and the features of the products they purchased. They want to understand which product features are MOST strongly correlated with high customer satisfaction. What type of analysis should they perform?",
                "options": [
                    "Sentiment Analysis",
                    "Regression Analysis",
                    "Classification Analysis",
                    "Clustering Analysis"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính của công ty là xác định **tính tương quan mạnh nhất** giữa các đặc trưng sản phẩm (product features – biến độc lập) và **điểm hài lòng khách hàng** (customer satisfaction scores – biến phụ thuộc), tức là muốn biết đặc trưng nào ảnh hưởng lớn nhất (mạnh mẽ nhất) đến mức độ hài lòng.\n\n**Regression Analysis** là loại phân tích phù hợp nhất:\n\n• **Regression Analysis** (Phân tích hồi quy) — Được thiết kế để mô hình hóa mối quan hệ giữa một biến phụ thuộc liên tục (customer satisfaction score – thường là số từ 1–10) và một hoặc nhiều biến độc lập (product features như chất lượng, giá cả, thiết kế, độ bền, v.v.).\n  - Trong hồi quy tuyến tính (Linear Regression) hoặc hồi quy đa biến (Multiple Regression), hệ số hồi quy (coefficients) cho biết **mức độ và hướng ảnh hưởng** của từng feature.\n  - Ví dụ: Hệ số của \"chất lượng\" = +2.5 nghĩa là khi chất lượng tăng 1 đơn vị, điểm hài lòng trung bình tăng 2.5 điểm (tương quan mạnh dương).\n  - Có thể sử dụng các chỉ số như R-squared, p-value để đánh giá độ mạnh và ý nghĩa thống kê của từng feature.\n\nTrong AWS SageMaker, Regression Analysis (như Linear Learner, XGBoost Regression) là lựa chọn tiêu chuẩn để phân tích mối quan hệ này và xác định feature quan trọng nhất.\n\nCác lựa chọn khác không phù hợp:\n• **Sentiment Analysis**: Dùng để phân tích cảm xúc trong văn bản (positive/negative), không áp dụng cho dữ liệu số (satisfaction scores + features).\n• **Classification Analysis**: Dùng để dự đoán nhãn phân loại (ví dụ: hài lòng/không hài lòng), không cho biết mức độ tương quan mạnh yếu của từng feature.\n• **Clustering Analysis**: Dùng để nhóm khách hàng tương đồng, không xác định mối quan hệ giữa feature và satisfaction score.\n\nDo đó, **Regression Analysis** là loại phân tích phù hợp nhất để hiểu rõ đặc trưng sản phẩm nào có **tương quan mạnh nhất** với điểm hài lòng khách hàng theo nguyên tắc AWS AI/ML.\n\nNguồn tham khảo: AWS Machine Learning Specialty – Regression là kỹ thuật cốt lõi để phân tích mối quan hệ giữa biến liên tục và xác định feature importance trong các bài toán như customer satisfaction modeling."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "You are tasked with building a model to predict customer satisfaction based on text reviews. Which of the following techniques is most commonly used for processing text data in NLP tasks?",
                "options": [
                    "Principal Component Analysis (PCA)",
                    "One-Hot Encoding",
                    "Regression",
                    "Support Vector Machine (SVM)"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là xác định **kỹ thuật phổ biến nhất** để xử lý dữ liệu văn bản (text data) trong các nhiệm vụ NLP khi xây dựng mô hình dự đoán mức độ hài lòng khách hàng (customer satisfaction) dựa trên đánh giá bằng văn bản (text reviews).\n\n**One-Hot Encoding** là kỹ thuật phù hợp nhất trong các lựa chọn:\n\n• **One-Hot Encoding** — Là một kỹ thuật tiền xử lý dữ liệu văn bản cơ bản và rất phổ biến trong NLP truyền thống:\n  - Chuyển đổi từ/categorical token thành vector nhị phân (0/1) với độ dài bằng số lượng từ vựng (vocabulary size).\n  - Ví dụ: Từ \"good\" → [0, 0, 1, 0, ...], từ \"bad\" → [0, 1, 0, 0, ...]\n  - Đây là cách phổ biến để biểu diễn văn bản dưới dạng số để các mô hình machine learning (như Logistic Regression, Naive Bayes, SVM) có thể xử lý.\n  - Trong nhiều pipeline NLP cơ bản (trước thời đại deep learning), one-hot encoding kết hợp với Bag-of-Words (BoW) hoặc TF-IDF là bước đầu tiên tiêu chuẩn.\n\nTrong AWS SageMaker và các công cụ ML cơ bản, one-hot encoding thường được sử dụng khi làm việc với text features trong các mô hình tabular hoặc khi cần biểu diễn từ vựng đơn giản.\n\nCác lựa chọn khác không phù hợp:\n• **Principal Component Analysis (PCA)**: Dùng để giảm chiều dữ liệu sau khi đã có vector biểu diễn (ví dụ: sau TF-IDF), không phải kỹ thuật xử lý text trực tiếp.\n• **Regression**: Là loại mô hình (dự đoán giá trị liên tục như satisfaction score), không phải kỹ thuật xử lý/preprocessing text.\n• **Support Vector Machine (SVM)**: Là thuật toán phân loại/hồi quy, không phải kỹ thuật xử lý dữ liệu văn bản.\n\n**Lưu ý quan trọng**: Trong NLP hiện đại (sau 2018), các kỹ thuật tiên tiến hơn như Word Embeddings (Word2Vec, GloVe), Contextual Embeddings (BERT, RoBERTa), hoặc tokenization của Transformer đã thay thế one-hot encoding cho hầu hết các nhiệm vụ. Tuy nhiên, trong các lựa chọn được đưa ra và theo ngữ cảnh \"fundamentals of AI and ML\", **One-Hot Encoding** là kỹ thuật cơ bản và phổ biến nhất được coi là đúng.\n\nDo đó, **One-Hot Encoding** là câu trả lời phù hợp nhất theo nguyên tắc AWS AI/ML fundamentals.\n\nNguồn tham khảo: AWS Machine Learning Specialty – One-hot encoding là kỹ thuật cơ bản trong text preprocessing cho các mô hình truyền thống."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "Which of the following is the MOST common reason for using a validation dataset in machine learning?",
                "options": [
                    "To train the machine learning model.",
                    "To evaluate the final performance of the model after deployment.",
                    "To tune the hyperparameters of the machine learning model.",
                    "To ensure the training data is balanced."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là xác định **lý do phổ biến nhất** để sử dụng **tập validation (validation dataset)** trong quy trình machine learning.\n\n**To tune the hyperparameters of the machine learning model** là lý do chính xác và phổ biến nhất:\n\n• Trong pipeline machine learning chuẩn, dữ liệu được chia thành 3 tập chính:\n  - **Training set** — Dùng để huấn luyện mô hình (fit weights/parameters).\n  - **Validation set** — Dùng để **tinh chỉnh siêu tham số (hyperparameter tuning)**, lựa chọn mô hình tốt nhất trong quá trình phát triển (ví dụ: điều chỉnh learning rate, số layer, regularization strength, max_depth trong cây quyết định, v.v.). Validation set giúp đánh giá hiệu suất mô hình trên dữ liệu chưa thấy (unseen data) trong giai đoạn tuning, tránh overfitting trên training set.\n  - **Test set** — Dùng để đánh giá hiệu suất cuối cùng (final performance) sau khi đã chọn mô hình và siêu tham số, mô phỏng hiệu suất thực tế khi deploy.\n\nValidation set đóng vai trò trung gian quan trọng trong quá trình phát triển: giúp chọn cấu hình mô hình tốt nhất mà không \"làm rò rỉ\" thông tin từ test set.\n\nCác lựa chọn khác không đúng:\n• **To train the machine learning model** — Đây là vai trò của **training set**, không phải validation.\n• **To evaluate the final performance of the model after deployment** — Đây là vai trò của **test set** (hoặc hold-out set cuối cùng), không phải validation.\n• **To ensure the training data is balanced** — Việc cân bằng dữ liệu (data balancing) là bước tiền xử lý trên training set (oversampling, undersampling, SMOTE), không phải mục đích chính của validation set.\n\nDo đó, **To tune the hyperparameters of the machine learning model** là lý do phổ biến nhất để sử dụng validation dataset theo nguyên tắc AWS AI/ML và best practices tiêu chuẩn.\n\nNguồn tham khảo: AWS Machine Learning Specialty & SageMaker documentation – Validation set được sử dụng chủ yếu cho hyperparameter tuning, model selection, và early stopping trong quá trình phát triển mô hình."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A data scientist discovers high bias in their machine learning model. Which of the following actions would be MOST effective in addressing this issue?",
                "options": [
                    "Decrease the complexity of the model.",
                    "Add more features to the model.",
                    "Increase the amount of training data.",
                    "Apply regularization techniques."
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là tìm hành động **hiệu quả nhất** để khắc phục tình trạng **high bias** (độ chệch cao) trong mô hình machine learning, tức là mô hình đang **underfitting** – quá đơn giản, không nắm bắt được các pattern phức tạp trong dữ liệu.\n\n**Add more features to the model** là hành động phù hợp và hiệu quả nhất:\n\n• **High bias** xảy ra khi mô hình có độ phức tạp thấp, dẫn đến underfitting (dự đoán kém trên cả training và validation set).\n  - Để giảm bias, cần **tăng khả năng biểu diễn (model capacity)** của mô hình.\n  - **Thêm nhiều features** (feature engineering hoặc thu thập thêm đặc trưng) giúp mô hình nắm bắt được nhiều thông tin và mối quan hệ phức tạp hơn trong dữ liệu, từ đó tăng khả năng fit tốt hơn với dữ liệu thực tế.\n  - Ví dụ: Trong dự đoán giá nhà, thêm features như \"số phòng ngủ\", \"diện tích sân vườn\", \"khoảng cách đến trung tâm\" sẽ giúp mô hình phức tạp hơn và giảm bias.\n\nCác lựa chọn khác không phù hợp hoặc làm tình trạng tệ hơn:\n• **Decrease the complexity of the model** → Làm mô hình đơn giản hơn → tăng bias (underfitting nặng hơn).\n• **Increase the amount of training data** → Chủ yếu giúp giảm **high variance** (overfitting), không hiệu quả trực tiếp với high bias (dù có thể giúp nhẹ trong một số trường hợp).\n• **Apply regularization techniques** → Như L1/L2 regularization, dropout → thường dùng để giảm **variance** (overfitting), có thể làm tăng bias nếu áp dụng quá mạnh.\n\nDo đó, **Add more features to the model** là hành động **hiệu quả nhất** để khắc phục high bias theo nguyên tắc AWS AI/ML và bias-variance tradeoff.\n\nNguồn tham khảo: AWS Machine Learning Specialty – Để giảm high bias (underfitting): tăng model complexity (thêm features, dùng mô hình phức tạp hơn), trong khi high variance (overfitting) thì dùng regularization và thêm data."
            },
            {
                "domain": "Fundamentals of Generative AI",
                "q": "A data scientist wants to use a generative AI model to create realistic images of damaged goods for quality control training. They need a model that can generate images from text descriptions and also handle specific constraints (e.g., type of damage, location of damage). Which approach is MOST suitable?",
                "options": [
                    "Using a pre-trained large language model (LLM) directly for image generation.",
                    "Fine-tuning a text-to-image diffusion model with a dataset of damaged goods images and corresponding text descriptions.",
                    "Employing a simple image classification model to categorize existing images of damaged goods.",
                    "Utilizing a recommendation engine to suggest similar images of damaged goods from a database."
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là tạo ra **hình ảnh thực tế mới** (generate new realistic images) của hàng hóa bị hư hỏng dựa trên **mô tả văn bản** (text descriptions), đồng thời cần **kiểm soát chi tiết** (specific constraints) như loại hư hỏng (vỡ, rách, móp méo), vị trí hư hỏng (trên nắp, thân, cạnh), để sử dụng trong huấn luyện mô hình kiểm soát chất lượng (quality control training).\n\n**Fine-tuning a text-to-image diffusion model with a dataset of damaged goods images and corresponding text descriptions** là cách tiếp cận phù hợp nhất:\n\n• **Text-to-image diffusion models** (như Stable Diffusion, DALL·E, Imagen, hoặc các mô hình trên Amazon Bedrock/Titan Image Generator) là công nghệ generative AI tiên tiến nhất hiện nay để tạo hình ảnh chất lượng cao từ văn bản.\n• **Fine-tuning** trên dataset riêng (hình ảnh hàng hỏng thật + caption mô tả chi tiết) giúp mô hình:\n  - Học đặc trưng cụ thể của hàng hóa bị hư hỏng trong ngành nghề của công ty.\n  - Tạo ra hình ảnh đa dạng nhưng vẫn đúng phong cách thực tế.\n  - Hiểu và tuân thủ các ràng buộc cụ thể (ví dụ: prompt \"máy tính xách tay vỡ màn hình góc trên bên phải, vết nứt hình mạng nhện\").\n\nĐây là cách hiệu quả nhất để tạo dữ liệu tổng hợp (synthetic data) chất lượng cao, đa dạng, giúp tăng cường dataset huấn luyện mà không cần thu thập thêm hàng ngàn ảnh thực tế tốn kém.\n\nCác lựa chọn khác không phù hợp:\n• **Using a pre-trained large language model (LLM) directly for image generation** — LLM (như GPT-4, Claude) chỉ giỏi xử lý văn bản, không tạo được hình ảnh trực tiếp.\n• **Employing a simple image classification model** — Chỉ phân loại ảnh hiện có, không tạo ra ảnh mới.\n• **Utilizing a recommendation engine** — Chỉ tìm/gợi ý ảnh tương tự từ database sẵn có, không sinh ra ảnh mới và không kiểm soát được chi tiết hư hỏng.\n\nDo đó, **Fine-tuning a text-to-image diffusion model** là cách tiếp cận tối ưu, phù hợp với nguyên tắc AWS Generative AI để tạo dữ liệu tổng hợp có kiểm soát cho các bài toán computer vision.\n\nNguồn tham khảo: AWS Bedrock (Titan Image Generator) và Stable Diffusion fine-tuning – Fine-tuning text-to-image models là phương pháp chuẩn để tùy chỉnh generation cho domain-specific tasks như quality inspection."
            },
            {
                "domain": "Fundamentals of Generative AI",
                "q": "A startup is building a chatbot powered by a large language model (LLM). They want to ensure the chatbot provides accurate and relevant responses while avoiding hallucinations (generating incorrect or nonsensical information). Which technique would be MOST effective for mitigating hallucinations?",
                "options": [
                    "Increasing the model size (number of parameters).",
                    "Decreasing the temperature parameter during text generation.",
                    "Using a simpler, less powerful LLM.",
                    "Removing all training data related to controversial topics."
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là tìm kỹ thuật **hiệu quả nhất** để giảm thiểu **hallucinations** (hiện tượng mô hình tạo ra thông tin sai lệch, bịa đặt hoặc không chính xác) trong chatbot sử dụng large language model (LLM).\n\n**Decreasing the temperature parameter during text generation** là kỹ thuật phù hợp và hiệu quả nhất trong các lựa chọn:\n\n• **Temperature** là một tham số quan trọng trong quá trình sinh text (text generation) của LLM (như GPT, Claude, Llama, Titan, v.v.).\n  - Temperature cao (ví dụ: 1.0 hoặc cao hơn) → tăng tính ngẫu nhiên (randomness), sáng tạo → dễ dẫn đến hallucinations, câu trả lời lan man, sai sự thật.\n  - **Giảm temperature** (ví dụ: xuống 0.0–0.5, thậm chí 0.2) → làm cho mô hình chọn token có xác suất cao nhất một cách quyết đoán hơn → output trở nên **dự đoán được, nhất quán, chính xác** hơn và giảm đáng kể khả năng bịa đặt thông tin.\n\nĐây là kỹ thuật **đơn giản, tức thời, không cần retrain mô hình**, và được khuyến nghị hàng đầu trong các best practices của AWS Bedrock, OpenAI, Anthropic khi triển khai chatbot cần độ tin cậy cao (ví dụ: customer support, financial advice, legal Q&A).\n\nCác lựa chọn khác không hiệu quả hoặc không trực tiếp:\n• **Increasing the model size (number of parameters)** → Mô hình lớn hơn (như GPT-4 so với GPT-3.5) thường **giảm** hallucinations nhờ học được nhiều kiến thức hơn, nhưng không phải cách hiệu quả nhất (và tốn kém rất nhiều tài nguyên).\n• **Using a simpler, less powerful LLM** → Mô hình nhỏ hơn thường **ít sáng tạo hơn**, nhưng đồng thời **khả năng hiểu ngữ cảnh kém** → có thể tăng hallucinations ở các câu hỏi phức tạp.\n• **Removing all training data related to controversial topics** → Có thể giảm bias hoặc output nhạy cảm, nhưng **không giải quyết gốc rễ** của hallucinations (mô hình vẫn có thể bịa thông tin ở các chủ đề khác).\n\nDo đó, **Decreasing the temperature parameter during text generation** là kỹ thuật **hiệu quả nhất, nhanh chóng và được khuyến nghị** để giảm hallucinations trong chatbot LLM theo nguyên tắc AWS Generative AI fundamentals.\n\nNguồn tham khảo: AWS Bedrock documentation & LLM inference best practices – Lower temperature (0.0–0.5) là cách phổ biến nhất để tăng factual accuracy và giảm hallucinations trong production chatbot."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "Which of the following is a key benefit of using pre-trained models in machine learning?",
                "options": [
                    "They always provide perfect accuracy.",
                    "They require significantly less training data and time.",
                    "They can only be used for image recognition tasks.",
                    "They eliminate the need for feature engineering."
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính là xác định **lợi ích chính** khi sử dụng **pre-trained models** (mô hình đã được huấn luyện sẵn) trong machine learning.\n\n**They require significantly less training data and time** là lợi ích quan trọng và đúng nhất:\n\n• **Pre-trained models** (như BERT, ResNet, GPT, CLIP, hoặc các mô hình trên Amazon SageMaker JumpStart/Bedrock) đã được huấn luyện trước trên tập dữ liệu rất lớn (hàng triệu đến hàng tỷ mẫu), giúp học được các đặc trưng chung (general features) của dữ liệu (ví dụ: đặc trưng hình ảnh, ngữ nghĩa văn bản, ngữ cảnh ngôn ngữ).\n• Khi sử dụng trong bài toán cụ thể (transfer learning/fine-tuning), bạn chỉ cần:\n  - Một lượng dữ liệu nhỏ hơn nhiều (thay vì hàng triệu mẫu).\n  - Thời gian huấn luyện ngắn hơn đáng kể (thường chỉ fine-tune vài epoch thay vì huấn luyện từ đầu).\n\nĐiều này giúp:\n  - Tiết kiệm chi phí tính toán\n  - Rút ngắn thời gian phát triển mô hình\n  - Đạt hiệu suất cao ngay cả khi dữ liệu hạn chế (rất phổ biến trong thực tế doanh nghiệp)\n\nĐây là lợi ích cốt lõi của **transfer learning** và **pre-trained foundation models** theo nguyên tắc AWS AI/ML.\n\nCác lựa chọn khác không đúng:\n• **They always provide perfect accuracy** — Không có mô hình nào đảm bảo độ chính xác hoàn hảo 100%, kể cả pre-trained.\n• **They can only be used for image recognition tasks** — Sai hoàn toàn: pre-trained models áp dụng rộng rãi cho NLP (BERT), vision (ResNet), multimodal (CLIP), speech, v.v.\n• **They eliminate the need for feature engineering** — Pre-trained models giảm nhu cầu feature engineering thủ công (vì đã học được feature tự động), nhưng không loại bỏ hoàn toàn – vẫn có thể cần điều chỉnh hoặc thêm feature domain-specific.\n\nDo đó, **They require significantly less training data and time** là lợi ích then chốt khi sử dụng pre-trained models trong machine learning.\n\nNguồn tham khảo: AWS Machine Learning Specialty & SageMaker JumpStart documentation – Pre-trained models và transfer learning giúp giảm đáng kể lượng dữ liệu và thời gian huấn luyện, đặc biệt hiệu quả cho các doanh nghiệp có dữ liệu hạn chế."
            },
            {
                "domain": "AIF – Fundamentals of AI and ML",
                "q": "A model is showing high variance. Which of the following techniques could help reduce variance and improve generalization?",
                "options": [
                    "Adding more features to the model.",
                    "Increasing the complexity of the model.",
                    "Using more training data.",
                    "Decreasing the amount of regularization."
                ],
                "correct": 2,
                "explanation": "Yêu cầu chính là tìm kỹ thuật **hiệu quả** để **giảm variance** (độ biến thiên cao) trong mô hình machine learning, giúp mô hình **tổng quát hóa tốt hơn** (improve generalization) trên dữ liệu mới, tránh tình trạng **overfitting** (học quá kỹ trên training data nhưng kém trên validation/test).\n\n**Using more training data** là kỹ thuật phù hợp và hiệu quả nhất:\n\n• **High variance** xảy ra khi mô hình quá phức tạp so với lượng dữ liệu hiện có, dẫn đến overfitting: mô hình ghi nhớ nhiễu (noise) thay vì học pattern chung.\n  - Khi **tăng lượng dữ liệu huấn luyện** (more training data), mô hình có cơ hội học được pattern đại diện (representative patterns) của toàn bộ phân phối dữ liệu thực tế.\n  - Điều này làm giảm sự phụ thuộc vào các điểm dữ liệu cụ thể → giảm variance, tăng khả năng tổng quát hóa.\n  - Đây là một trong những cách **trực tiếp và hiệu quả nhất** để khắc phục high variance theo bias-variance tradeoff.\n\nCác lựa chọn khác không phù hợp hoặc làm tình trạng tệ hơn:\n• **Adding more features to the model** → Tăng số đặc trưng → tăng độ phức tạp → thường **tăng variance** (overfitting nặng hơn).\n• **Increasing the complexity of the model** → Làm mô hình phức tạp hơn (thêm layer, cây sâu hơn) → **tăng variance**.\n• **Decreasing the amount of regularization** → Giảm regularization (L1/L2, dropout) → cho phép mô hình fit chặt hơn vào training data → **tăng variance**.\n\nDo đó, **Using more training data** là kỹ thuật **hiệu quả nhất** để giảm high variance và cải thiện khả năng tổng quát hóa của mô hình theo nguyên tắc AWS AI/ML.\n\nNguồn tham khảo: AWS Machine Learning Specialty – Để giảm high variance (overfitting): thu thập thêm dữ liệu huấn luyện, tăng regularization, giảm độ phức tạp mô hình."
            },
            {
                "domain": "Security, Compliance, and Governance for AI Solutions",
                "q": "Your company is developing a predictive maintenance AI model for industrial equipment using sensor data stored in Amazon S3. They want to audit access to this data to ensure compliance with internal security policies. Which AWS service BEST facilitates this?",
                "options": [
                    "AWS CloudTrail",
                    "Amazon GuardDuty",
                    "AWS Config",
                    "Amazon Inspector"
                ],
                "correct": 0,
                "explanation": "Yêu cầu chính là **kiểm tra (audit)** việc truy cập dữ liệu cảm biến (sensor data) lưu trữ trong Amazon S3 để đảm bảo tuân thủ chính sách bảo mật nội bộ trong quá trình phát triển mô hình predictive maintenance.\n\n**AWS CloudTrail** là dịch vụ phù hợp nhất:\n\n• **AWS CloudTrail** — Ghi lại toàn bộ **API calls** được thực hiện trong tài khoản AWS, bao gồm mọi hành động liên quan đến S3 như:\n  - GetObject (đọc dữ liệu)\n  - PutObject (ghi dữ liệu)\n  - ListBucket (liệt kê bucket)\n  - DeleteObject, v.v.\n\nCloudTrail cung cấp nhật ký chi tiết (audit trail) bao gồm:\n  - Ai (user/role) đã truy cập\n  - Khi nào (thời gian)\n  - Từ đâu (IP address)\n  - Hành động cụ thể nào\n\nDữ liệu này có thể được lưu vào S3, gửi đến CloudWatch Logs, hoặc phân tích bằng Athena/QuickSight để kiểm tra tuân thủ (compliance auditing). Đây là công cụ tiêu chuẩn cho audit access log và đáp ứng các yêu cầu compliance (ví dụ: SOC 2, ISO 27001, GDPR) trong các dự án AI/ML sử dụng dữ liệu nhạy cảm.\n\nCác lựa chọn khác không phù hợp:\n• **Amazon GuardDuty** — Phát hiện mối đe dọa bảo mật (threat detection) dựa trên phân tích log và hành vi bất thường, không phải công cụ audit chi tiết API calls.\n• **AWS Config** — Theo dõi và ghi lại **thay đổi cấu hình** của tài nguyên AWS (ví dụ: bucket S3 có public hay không), không ghi lại chi tiết ai đã truy cập dữ liệu bên trong.\n• **Amazon Inspector** — Quét lỗ hổng bảo mật trên EC2, Lambda, container, không liên quan đến audit access dữ liệu S3.\n\nDo đó, **AWS CloudTrail** là dịch vụ **tốt nhất** để audit truy cập dữ liệu S3 trong dự án predictive maintenance theo nguyên tắc AWS Security, Compliance, and Governance for AI Solutions.\n\nNguồn tham khảo: AWS CloudTrail documentation – Core service for auditing API activity, including all S3 data access events, essential for compliance in AI/ML workloads."
            },
            {
                "domain": "Applications of Foundation Models",
                "q": "A financial institution wants to automate the process of extracting key information from complex financial documents such as contracts and reports. They need a solution that can accurately identify and categorize different types of data, such as dates, amounts, and clauses. Which foundation model application is BEST suited for this use case?",
                "options": [
                    "Text-to-speech conversion",
                    "Question answering",
                    "Image classification",
                    "Machine translation"
                ],
                "correct": 1,
                "explanation": "Yêu cầu chính của tổ chức tài chính là **tự động trích xuất thông tin quan trọng** (key information extraction) từ các tài liệu tài chính phức tạp (hợp đồng, báo cáo), bao gồm việc nhận diện và phân loại chính xác các loại dữ liệu như ngày tháng (dates), số tiền (amounts), điều khoản (clauses).\n\n**Question answering** (Trả lời câu hỏi) là ứng dụng foundation model phù hợp nhất:\n\n• **Question answering (QA)** — Đặc biệt là **extractive QA** hoặc **generative QA** trên các foundation models lớn (như BERT, RoBERTa, Llama, Claude, hoặc Amazon Titan trên Bedrock) cho phép:\n  - Đặt các câu hỏi có cấu trúc (structured queries) lên tài liệu: \"Ngày ký hợp đồng là khi nào?\", \"Số tiền thanh toán là bao nhiêu?\", \"Điều khoản phạt chậm là gì?\"\n  - Mô hình tự động tìm và trích xuất chính xác đoạn văn bản chứa thông tin cần thiết (span extraction) hoặc sinh ra câu trả lời ngắn gọn.\n  - Có thể fine-tune trên dataset tài liệu tài chính để tăng độ chính xác cao trong domain-specific (financial domain).\n\nĐây là cách tiếp cận phổ biến và hiệu quả cho **Named Entity Recognition (NER)** nâng cao, **information extraction**, và **document understanding** trong ngành tài chính, nơi cần độ chính xác cao và khả năng xử lý văn bản dài, phức tạp.\n\nCác lựa chọn khác không phù hợp:\n• **Text-to-speech conversion**: Chuyển văn bản thành giọng nói, không liên quan đến trích xuất thông tin.\n• **Image classification**: Phân loại hình ảnh, không xử lý được nội dung văn bản trong tài liệu.\n• **Machine translation**: Dịch ngôn ngữ, không dùng để trích xuất hoặc phân loại thông tin cụ thể.\n\nDo đó, **Question answering** là ứng dụng foundation model **phù hợp nhất** để tự động hóa việc trích xuất và phân loại thông tin quan trọng từ hợp đồng và báo cáo tài chính.\n\nNguồn tham khảo: AWS Bedrock & Amazon SageMaker JumpStart – Question answering và document understanding (dựa trên QA models) là ứng dụng cốt lõi cho information extraction trong các tài liệu tài chính phức tạp."
            },

        ];

        // Configure marked to handle single line breaks
        marked.setOptions({
            breaks: true,
            gfm: true
        });

        const container = document.getElementById('qa-container');

        questions.forEach((item, index) => {
            const card = document.createElement('div');
            card.className = 'qa-card';

            let optionsHtml = '';
            const isMultiChoice = Array.isArray(item.correct);
            item.options.forEach((opt, oIdx) => {
                const inputType = isMultiChoice ? 'checkbox' : 'radio';
                optionsHtml += `<div class="option" data-qidx="${index}" data-oidx="${oIdx}" onclick="selectOption(this)">
                    <input type="${inputType}" name="question-${index}" value="${oIdx}" style="margin-right:8px;">
                    <strong>${String.fromCharCode(65 + oIdx)}.</strong> ${opt}
                </div>`;
            });

            let correctAnswersText;
            if (Array.isArray(item.correct)) {
                correctAnswersText = item.correct.map(c => String.fromCharCode(65 + c)).join(', ');
            } else {
                correctAnswersText = String.fromCharCode(65 + item.correct);
            }

            card.innerHTML = `
                <div class="domain-tag">${item.domain}</div>
                <div class="question">${index + 1}. ${item.q}</div>
                <div class="options" id="options-${index}">
                    ${optionsHtml}
                </div>
                <button class="check-btn" onclick="checkAnswer(${index})">Kiểm tra</button>
                <button class="show-btn" onclick="toggleAnswer(${index})">Giải thích</button>
                <div id="ans-${index}" class="answer-box">
                    <span class="ans-label">Đáp án đúng: ${correctAnswersText}</span>
                    <div class="explanation">${marked.parse(item.explanation)}</div>
                </div>
            `;
            container.appendChild(card);
        });

        function selectOption(el) {
            const qIdx = parseInt(el.dataset.qidx);
            const oIdx = parseInt(el.dataset.oidx);
            const question = questions[qIdx];
            const inputElement = el.querySelector('input');

            // For single-choice questions (radio buttons)
            if (inputElement.type === 'radio') {
                // Deselect all other options for this question
                const siblings = el.parentElement.querySelectorAll('.option');
                siblings.forEach(s => {
                    s.classList.remove('selected');
                    s.querySelector('input').checked = false;
                });
                // Select the clicked option
                el.classList.add('selected');
                inputElement.checked = true;
            }
            // For multiple-choice questions (checkboxes)
            else if (inputElement.type === 'checkbox') {
                // Toggle selection for the clicked option
                el.classList.toggle('selected');
                inputElement.checked = !inputElement.checked;
            }
        }

        function checkAnswer(qIdx) {
            const question = questions[qIdx];
            const optionsContainer = document.getElementById(`options-${qIdx}`);
            const allOptions = optionsContainer.querySelectorAll('.option');

            const correctIndices = Array.isArray(question.correct) ? question.correct : [question.correct];
            const selectedIndices = [];

            allOptions.forEach(optionEl => {
                const oIdx = parseInt(optionEl.dataset.oidx);
                optionEl.classList.remove('correct', 'wrong'); // Clear previous feedback

                if (optionEl.classList.contains('selected')) {
                    selectedIndices.push(oIdx);
                }
            });

            let allSelectedCorrect = true;
            let allCorrectSelected = true;

            // Check selected options
            selectedIndices.forEach(sIdx => {
                if (!correctIndices.includes(sIdx)) {
                    allOptions[sIdx].classList.add('wrong');
                    allSelectedCorrect = false;
                } else {
                    allOptions[sIdx].classList.add('correct');
                }
            });

            // Check if all correct options were selected
            correctIndices.forEach(cIdx => {
                if (!selectedIndices.includes(cIdx)) {
                    allOptions[cIdx].classList.add('correct'); // Highlight correct but unselected
                    allCorrectSelected = false;
                }
            });

            // If all selected are correct AND all correct are selected, then it's fully correct
            // Otherwise, it's partially correct or wrong.
            // The current logic highlights wrong selections and all correct answers.
        }

        function toggleAnswer(idx) {
            const box = document.getElementById(`ans-${idx}`);
            box.classList.toggle('visible');
        }
    </script>
</body>

</html>
```